{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Files\" data-toc-modified-id=\"Files-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Files</a></span></li><li><span><a href=\"#Regular-Expressions\" data-toc-modified-id=\"Regular-Expressions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Regular Expressions</a></span></li><li><span><a href=\"#Project-–-The-Invoices\" data-toc-modified-id=\"Project-–-The-Invoices-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Project – The Invoices</a></span></li><li><span><a href=\"#Web-Scraping\" data-toc-modified-id=\"Web-Scraping-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Web Scraping</a></span></li><li><span><a href=\"#Data-Alteration-Techniques\" data-toc-modified-id=\"Data-Alteration-Techniques-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Data Alteration Techniques</a></span></li><li><span><a href=\"#Pandas\" data-toc-modified-id=\"Pandas-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Pandas</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2.3 File creator function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so a function that creates a plaintext file! There are a bunch of ways to do this. But this is how I would do it. As always, I try to base the solutions of what has been taught so far in the course.\n",
    "\n",
    "First, we import the `Path` class from the `pathlib` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will use the `Path` class in our function, we must convert the first parameter to a path object. Why? Because some users may pass a string value as the path, and strings don't have the method `.is_absolute()`. It would crash!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_creator(path, content):\n",
    "    path = Path(path)\n",
    "    if not path.is_absolute():\n",
    "        print(\"The path you provided isn't working.\",\n",
    "              \"It should be an absolute path, try again!\")\n",
    "        return\n",
    "    else:\n",
    "        if not \".txt\" in str(path):\n",
    "            print(\"You must include a textfile in your path!\")\n",
    "            return\n",
    "        else:\n",
    "            with path.open(\"w\") as file:\n",
    "                file.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also included the if-statement `if not \".txt\" in str(path):`. If the user forgets to include a filename in their path, the function will crash. Else, the context manager pattern with a `with`-statement will create a new file.\n",
    "\n",
    "The if-statement checks to see _\"if there isn't a file extension in the path, print a warning!\"_ It does so by checking if the string \".txt\" isn't in the path. But this will only work if we convert the path into a string value, hence the `str(path)`. Path objects can't be looped over (they aren't iterable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pass something that isn't an absolute path, such as an empty string, the function will warn us and abort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path you provided isn't working. It should be an absolute path, try again!\n"
     ]
    }
   ],
   "source": [
    "file_creator(\"\",\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an absolute path to try on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd() / \"new_file.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_creator(path,\"This is a new file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file!\n"
     ]
    }
   ],
   "source": [
    "with path.open(\"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if you wan't to delete the file:\n",
    "path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Exercise – move the textfiles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! First we run the provided code to create all the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "from random import randint, seed\n",
    "\n",
    "seed(30)\n",
    "\n",
    "# First, create tree of directories\n",
    "path = Path('exercise')\n",
    "if os.path.isdir(path):\n",
    "    shutil.rmtree(path)\n",
    "    os.mkdir(path)\n",
    "    os.mkdir(path / 'old_location')\n",
    "    os.mkdir(path / 'new_location')\n",
    "else:\n",
    "    os.mkdir(path)\n",
    "    os.mkdir(path / 'old_location')\n",
    "    os.mkdir(path / 'new_location')\n",
    "\n",
    "# This following code randomly creates 500 files\n",
    "file_path = Path('exercise/old_location')\n",
    "for i in range(500):\n",
    "    # random number to decide file extension of present sequence\n",
    "    num = randint(0,1)\n",
    "    # if 'num' equals 0 -> plaintext, otherwise pythonfile\n",
    "    file_ext = \".txt\" if num == 0 else \".py\"\n",
    "    \n",
    "    # Here to decide file content\n",
    "    if file_ext == '.txt':\n",
    "        text = \"This is a plaintext file!\"\n",
    "    else:\n",
    "        text = \"# this is a python file\"\n",
    "        \n",
    "    # finally, writing and closing the file\n",
    "    file = open(file_path / f\"file_{randint(500,10000)}{file_ext}\",\"w\")\n",
    "    file.write(text)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Righty!\n",
    "\n",
    "So, in this exercise, we need to copy and move a whole bunch of files, using a function, from \"old_location\" to \"new_location\". We should also include code that add the current date as part of each files name when moved. Let's do a small TODO schematic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO – define function\n",
    "\n",
    "# TODO – convert potential path strings into path objects\n",
    "\n",
    "# TODO – find all files in old_location, save to list\n",
    "\n",
    "# TODO – filter all text files\n",
    "\n",
    "# TODO – loop over our text files\n",
    "\n",
    "# TODO – rename each file with date\n",
    "\n",
    "# TODO – create file paths for each file\n",
    "\n",
    "# TODO – copy each file\n",
    "\n",
    "# TODO – move each copy to 'new_location'\n",
    "\n",
    "# TODO – create path variables for the two locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pretty scary long list, right? Well, it's actually not that bad, since alot of these TODOs will be done together in one go. Let's start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO – define function\n",
    "def move_files(location_A, location_B, date):\n",
    "    # TODO – convert potential path strings into path objects\n",
    "    location_A, location_B = Path(location_A), Path(location_B)\n",
    "    \n",
    "    # TODO – find all files in old_location, save to list\n",
    "    all_files = os.listdir(location_A)\n",
    "\n",
    "    # TODO – filter all text files\n",
    "    all_txt_files = []\n",
    "    \n",
    "    for file in all_files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            all_txt_files.append(file)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "    # TODO – loop over our text files\n",
    "    for file_name in all_txt_files:\n",
    "        \n",
    "        # TODO – rename each file with date\n",
    "        new_file_name = f\"{date}_{file_name}\"\n",
    "        \n",
    "        # TODO – create file paths for each file\n",
    "        file_path_1 = old_loc / file_name\n",
    "        file_path_2 = new_loc / new_file_name\n",
    "        \n",
    "        # TODO – copy each file\n",
    "        # TODO – move each copy to 'new_location'\n",
    "        shutil.copy(file_path_1,file_path_2)\n",
    "    \n",
    "    print(f\"All {len(all_txt_files)} text files copied and moved!\")\n",
    "        \n",
    "# TODO – create path variables for the two locations\n",
    "old_loc = Path(\"exercise/old_location\")\n",
    "new_loc = Path(\"exercise/new_location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 262 text files copied and moved!\n"
     ]
    }
   ],
   "source": [
    "move_files(old_loc, new_loc, \"2020-10-15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look in the \"new_location\" to see if it worked (only showing 10 here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-10-15_file_4286.txt',\n",
       " '2020-10-15_file_7200.txt',\n",
       " '2020-10-15_file_3099.txt',\n",
       " '2020-10-15_file_2387.txt',\n",
       " '2020-10-15_file_2556.txt',\n",
       " '2020-10-15_file_6042.txt',\n",
       " '2020-10-15_file_8709.txt',\n",
       " '2020-10-15_file_6081.txt',\n",
       " '2020-10-15_file_1513.txt',\n",
       " '2020-10-15_file_6254.txt']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(new_loc)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates are now added to the files' name! All in all there are 262 text files, which means there are more text files than python files. \n",
    "\n",
    "Remember, if you just change the file extension in our function. This would work for any type of file you have, anywhere on your computer! Maybe you can find som use out of it somewhere? Have fun!\n",
    "\n",
    "(run this following code if you want to remove all exercise folders and files:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"exercise/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5 Exercise – pdf to text function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! To be able to get this done we need to first import the `PyPDF2` module and the `Path` class from the `pathlib` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a TODO list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO – define a function with two parameters\n",
    "\n",
    "# TODO – make sure that the two arguments are path objects\n",
    "\n",
    "# TODO – using the pdf's path parameter, open the file in \"rb\" mode\n",
    "\n",
    "# TODO – pass the opened file object to the PyPDF2's PdfFileReader class\n",
    "\n",
    "# TODO – create empty string variable to add pdf text to\n",
    "\n",
    "# TODO – create for-loop: loop over all the pdf's pages\n",
    "\n",
    "# TODO – get page data\n",
    "\n",
    "# TODO – add each page's text to the string variable\n",
    "\n",
    "# TODO – save the string variable to a plaintext file object\n",
    "\n",
    "# TODO – create two path objects to test our function on\n",
    "\n",
    "# TODO – test the function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, quite a list! Let's get to work with our function. I'll just name it the same as in the course notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO – define a function with two parameters\n",
    "def pdf_converter(pdf_path, results_path):\n",
    "    \n",
    "    # TODO – make sure that the two arguments are path objects\n",
    "    pdf_path, results_path = Path(pdf_path), Path(results_path)\n",
    "\n",
    "    # TODO – using the pdf's path parameter, open the file in \"rb\" mode\n",
    "    file_object = open(pdf_path, \"rb\")\n",
    "    \n",
    "    # TODO – pass the opened file object to the PyPDF2's PdfFileReader class\n",
    "    pdf_file = PyPDF2.PdfFileReader(file_object)\n",
    "\n",
    "    # TODO – create empty string variable to add pdf text to\n",
    "    pdf_content = \"\"\n",
    "\n",
    "    # TODO – create for-loop: loop over all the pdf's pages\n",
    "    for i in range(pdf_file.getNumPages()):\n",
    "        # TODO – get page data\n",
    "        page = pdf_file.getPage(i)\n",
    "        \n",
    "        # TODO – add each page's text to the string variable\n",
    "        pdf_content += page.extractText()\n",
    "        \n",
    "    # TODO – save the string variable to a plaintext file object\n",
    "    text_file = open(results_path,\"w\")\n",
    "    \n",
    "    text_file.write(pdf_content)\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's our function! Pretty straight forward actually, at least I think so. Hope you're still with me :)\n",
    "\n",
    "Now, let's test the function to see if it works! I'll just try it on the same pdf file as in the course notebook. It is found in the \"course_material\" directory. I'll save the results in a plaintext file in the current working directory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO – create two path objects to test our function on\n",
    "path_to_pdf = Path(\"../course_material/report.pdf\")\n",
    "results_path = Path(\"report.txt\") # important with file extension!\n",
    "\n",
    "\n",
    "# TODO – test the function!\n",
    "pdf_converter(path_to_pdf, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the newly created \"report.txt\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(results_path,\"r\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long is the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55344"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 1000 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corporate governance report 2019\\nH & M Hennes\\n & Mauritz AB\\nH & M Hennes & Mauritz AB is a Swedish public limited company. H&M™s \\nclass B share is listed on Nasdaq Stockholm. H&M applies the Swedish \\nCorporate Governance Code (the Code) and has prepared this corporate \\ngovernance report in accordance with the Annual Accounts Act and the \\nCode. H&M has applied the Code since 2005. The report, which covers \\n\\ndirectors and has been reviewed by the company™s auditors.\\nH&M is governed by both external regulations and internal \\n control documents.\\n\\n ŠThe Swedish Companies Act\\n ŠAccounting legislation including the Swedish Bookkeeping Act \\n and Annual Accounts Act\\n ŠMAR, EU Market Abuse Regulation (596/2014/EU)\\n ŠNasdaq Stockholm Rules for Issuers\\n ŠThe General Data Protection Regulation (GDPR)\\n ŠSwedish Corporate Governance Code (the Code), which is available \\n\\n\\nmay deviate from individual rules provided they give an explanation of \\nthe deviation, describe the chosen alternative and provide '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to have worked! Yey!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you want to remove the results file:\n",
    "#results_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Exercise – matching phone numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../course_material/phone_list.txt\",\"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant, Phone number\n",
      "Bolsvik Jurgen, 0703-1901XX\n",
      "Brumm,  Mats, 0707-2321XX\n",
      "Carlsson,  Yngve, 0735-4474XX\n",
      "Svensson,  Jan, 0730-2868XX\n",
      "Ekstrom,  Torbjorn, 018-5115XX\n",
      "Ekgren,  Stig, 0706-4084XX\n",
      "Engdahl,  Jan, 0703-6826XX\n",
      "Gripe,  Mats, 0735-6226XX\n",
      "H\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cellphone numbers all start with \"07\", then more number digits, followed by a dash, then more numbers, and finally two \"X\" letters. Let's try and type a regex based on this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"07\\d+-\\d+XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_list = re.findall(p,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(number_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 31 Swedish cellphone numbers in the list!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6 Exercise – can you find the number?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the re module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to get the speach and save it into a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../course_material/speach.txt\",\"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the number we need to find comes _before_ the quote \"refugees\". This means that we can include this in our regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"refugees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['refugees', 'refugees']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so Trump mentions the word \"refugees\" two times in the speach. Let's check what he sais just before the word \"refugees\". We can du this by including a blank space and the word character `\\w`. The word character matches both alphabetical letters _and_ numerical digits! \n",
    "\n",
    "Since we want the _word_ in front of \"refugees\", we'll add the plus sign `+`, which means we want `\\w` once or more times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\w+ refugees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['become refugees', '000 refugees']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! So the second match is the one we're interested in. But he obviously didn't say \"000 refugees\", there's more to it. However, how is numbers formatted in this speach? If Trump said \"one hundred thousand refugees\", is it typed:\n",
    "```\n",
    "\"100.000\"?\n",
    "\"100,000\"?\n",
    "\"100 000\"?\n",
    "\"100'000\"?\n",
    "```\n",
    "They are all probable. To be certain, we'll not use any of them Instead, we're going to use the \"not a word character\"-special character `\\W`. This matches all of the options above. Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', ',', ' ', \"'\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"\\W\"\n",
    "test = \"., '\"\n",
    "\n",
    "re.findall(p, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's include it in our search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\W\\w+ refugees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' become refugees', ',000 refugees']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's exchange the word special character to digits `\\d`, and then see the amount in front of the comma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['620,000 refugees']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"\\d+\\W\\d+ refugees\"\n",
    "\n",
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, is there more? Is he, for example, saying \"1,620,000 refugees\"? Let's have a look by duplicating `\\d+\\W`, so the entire expression will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\d+\\W\\d+\\W\\d+ refugees\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should match on \"1,620,000 refugees\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"1,620,000 refugees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,620,000 refugees']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check in Trump's speach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hits! This means that the number president Trump is talking about, must be 620,000! Let's change the first `\\d` into a word character instead and have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\w+\\W\\d+\\W\\d+ refugees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimated 620,000 refugees']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilá!\n",
    "\n",
    "One problem still remain though. This regular expression won't match any number, as was part of the exercise. This is, however, easily fixed! Let's go back to the expression just matching on the number, and the word \"refugees\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\d+\\W\\d+ refugees\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually add a group over the first two characters in our expression, and then attach a repetition qualifier to this group. So instead of `\\d+\\W`, we'll type `(\\d+\\W)*`. This means that this pattern can occur zero, or more times. Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"((\\d+\\W)*\\d+ refugees)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(I've also added a group that encloses the entire expression. This is just so that all hits will be displayed when I use the `.findall()` method here below)_\n",
    "\n",
    "This pattern will now match any number we give it, if it's followed by the string \" refugees\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1,123,032 refugees', '123,')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"1,123,032 refugees\"\n",
    "re.findall(p,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('32 refugees', '')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"32 refugees\"\n",
    "re.findall(p,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('54,654,721,321 refugees', '721,')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"54,654,721,321 refugees\"\n",
    "re.findall(p,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go! It now matches any number!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.9 Exercise – Who has landlines?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "file = open(\"../course_material/phone_list.txt\",\"r\")\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I will try to write a regex that captures each row in the list, and then use a group to catch peoples' names. Each row in the list ends with a newline character. That will be our breaking point. SOmetimes, I find it easier if you try to divide the string into parts that you then can deconstruct!\n",
    "\n",
    "Let's write a regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \",\\s\\w+-\\w+\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', 0703-1901XX\\n',\n",
       " ', 0707-2321XX\\n',\n",
       " ', 0735-4474XX\\n',\n",
       " ', 0730-2868XX\\n',\n",
       " ', 018-5115XX\\n',\n",
       " ', 0706-4084XX\\n',\n",
       " ', 0703-6826XX\\n',\n",
       " ', 0735-6226XX\\n',\n",
       " ', 018-2066XX\\n',\n",
       " ', 0738-2149XX\\n']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this regex catches all phone numbers in the list (plus the comma and the blank space that preceds the number). Let's see if we can capture all numbers where the second digit isn't a seven – since \"07\" is phone numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \",\\s0[^7]\\d+-\\w+\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', 018-5115XX\\n',\n",
       " ', 018-2066XX\\n',\n",
       " ', 018-4611XX\\n',\n",
       " ', 018-5007XX\\n',\n",
       " ', 018-3213XX\\n',\n",
       " ', 018-3005XX\\n']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! So to recap, I'll go through the regex character per character: \n",
    "1. the above regex will capture all strings that start with a comma `,`\n",
    "2. any type of whitespace character `\\s` (whitespace characters are blankspace, newlines, tabs etc…)\n",
    "3. the digit zero `0`\n",
    "4. NOT the number seven – `[^7]`\n",
    "5. one or more numerical digits `\\d+`\n",
    "6. a literal dash character `-`\n",
    "7. one or more word characters `\\w+` (remember that these captures numerical digits as well)\n",
    "8. a newline character `\\n`\n",
    "\n",
    "Now, we just need to add regex syntax to capture the names on these rows. Let's type a name finding regex by itself first, then combining it with the landline finding regex above later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each name is separated by a comma and a space, so let's use that in the regex. However, looking at the top of the list, the comma doesn't seem to be included in all rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant, Phone number\n",
      "Bolsvik Jurgen, 0703-1901XX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:54])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there may or may not be a comma. We'll include a comma with a star to cover our bases `,*`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now looking for each name\n",
    "p = \"[A-Z][a-z]+,*\\s[A-Z][a-z]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Participant, Phone', 'Bolsvik Jurgen']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh? Only catching first two rows, why is that? Maybe there's more than one blankspace inbetween each surname and name? Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[A-Z][a-z]+,*\\s+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Participant, ', 'Phone ', 'Bolsvik ', 'Jurgen, ', 'Brumm,  ']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to be the issue. Let's modify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[A-Z][a-z]+,*\\s+[A-Z][a-z]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Participant, Phone',\n",
       " 'Bolsvik Jurgen',\n",
       " 'Brumm,  Mats',\n",
       " 'Carlsson,  Yngve',\n",
       " 'Svensson,  Jan',\n",
       " 'Ekstrom,  Torbjorn',\n",
       " 'Ekgren,  Stig',\n",
       " 'Engdahl,  Jan',\n",
       " 'Gripe,  Mats',\n",
       " 'Hakku,  Tommy']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to have worked great! Now let's combine the two regex's. Since a regex pattern is such an eye soar, if I'm writing a longer regex, I sometimes save parts of the patterns in variables. Then, use the variables in a f-string that I use as my final regex pattern. It makes it a little bit more readable, in my opinion. I'll show you what I mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = \"[A-Z][a-z]+,*\\s+[A-Z][a-z]+\"\n",
    "all_landlines = \",\\s0[^7]\\d+-\\w+\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = f\"{all_names}{all_landlines}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ekstrom,  Torbjorn, 018-5115XX\\n',\n",
       " 'Hakku,  Tommy, 018-2066XX\\n',\n",
       " 'Harrysson,  Peder, 018-4611XX\\n',\n",
       " 'Helgsson,  Kurt, 018-5007XX\\n',\n",
       " 'Langefors,  Arvid, 018-3213XX\\n',\n",
       " 'Roos,  Anne, 018-3005XX\\n']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tada! Since we only want the names, let's group that part of the regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = f\"({all_names}){all_landlines}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ekstrom,  Torbjorn',\n",
       " 'Hakku,  Tommy',\n",
       " 'Harrysson,  Peder',\n",
       " 'Helgsson,  Kurt',\n",
       " 'Langefors,  Arvid',\n",
       " 'Roos,  Anne']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those six people have landlines!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project – The Invoices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's standard practice to always start with all your imports. Here's what we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first get a list of all pdf-files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('project')\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need check out what the pdf-files look like as strings. Knowing this, we can write regular expressions to extract the information we're interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invoice date: 2020-01-24\n",
      "\n",
      "Invoice for services in accordance with #T542AA1, Chap 3\n",
      "--------------------------------------------------------\n",
      "\n",
      "\n",
      "Total expenditure: SEK 72,846\n",
      "\n",
      "------\n",
      "Our contact: Fredrik Månsson (841012-8668)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(path / files[0],\"rb\") as file:\n",
    "    pdf_file = PyPDF2.PdfFileReader(file)\n",
    "    page = pdf_file.getPage(0)\n",
    "    print(page.extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_example = page.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInvoice date: 2020-01-24\\n\\nInvoice for services in accordance with #T542AA1, Chap 3\\n--------------------------------------------------------\\n\\n\\nTotal expenditure: SEK 72,846\\n\\n------\\nOur contact: Fredrik Månsson (841012-8668)\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! But to make things a bit more clean, let's put this code in a function that we can just simply call in each sequence when we loop over all the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    \n",
    "        page = pdf_file.getPage(0)\n",
    "        return page.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInvoice date: 2020-01-24\\n\\nInvoice for services in accordance with #T542AA1, Chap 3\\n--------------------------------------------------------\\n\\n\\nTotal expenditure: SEK 72,846\\n\\n------\\nOur contact: Fredrik Månsson (841012-8668)\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_pdf(path/files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a small problem though. What if there is an invoice with more than one page? Let's do a loop in the function to be on the safe side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_file.getNumPages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    with open(file_path,\"rb\") as file:\n",
    "        pdf_file = PyPDF2.PdfFileReader(file)\n",
    "    \n",
    "        text = \"\"\n",
    "        for i in range(pdf_file.getNumPages()):\n",
    "            page = pdf_file.getPage(i)\n",
    "            text += page.extractText()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_example = read_pdf(path/files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInvoice date: 2020-01-24\\n\\nInvoice for services in accordance with #T542AA1, Chap 3\\n--------------------------------------------------------\\n\\n\\nTotal expenditure: SEK 72,846\\n\\n------\\nOur contact: Fredrik Månsson (841012-8668)\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Let's move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking through a sample of the files, they all seem to have the same layout. \n",
    "\n",
    "The text within the files is pretty straight forward. Let's make a todo-list of the regexes we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO – get date\n",
    "\n",
    "# TODO – get name of contact\n",
    "\n",
    "# TODO – get social security number of contact\n",
    "\n",
    "# TODO – get charged amount "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through them one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-01-24'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO – get date\n",
    "date_p = \"Invoice date: (\\d+-\\d+-\\d+)\"\n",
    "re.search(date_p, text_example).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked fine! Let's move on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fredrik Månsson\n"
     ]
    }
   ],
   "source": [
    "# TODO – get name of contact\n",
    "name_p = \"Our contact: (\\w+\\s*\\w+) \\(\\d+-\\d+\\)\"\n",
    "mo = re.search(name_p, text_example)\n",
    "print(mo.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swedish names (or, rather, names in general) are notoriously hard to pin point with regular expressions. Some people have double first names (like \"Ann Charlotte\", or \"Ann-Charlotte\", or even \"AnnCharlotte\"), some have double surnames (\"Larsson Nilsson\", or \"Larsson-Nilsson\", or \"L Nilsson\"). So the name regex is to consider a bonus info. Best to get it just in case some invoice don't include any social security number.\n",
    "\n",
    "But, if we shall use above regex, we're gonna need a try/except-statement. It may not find any groups, and if so, the `.search()` method will return `None`. Let's check which error will be produced if we try to call a group that doesn't exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "no such group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-63c58db31733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# there isn't any group 45\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: no such group"
     ]
    }
   ],
   "source": [
    "re.search(name_p, text_example).group(45) # there isn't any group 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Let's build our regex again, but with a try/except-statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fredrik Månsson\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    name_p = \"Our contact: (\\w+\\s*\\w+) \\(\\d+-\\d+\\)\"\n",
    "    mo = re.search(name_p, text_example)\n",
    "    print(mo.group(1))\n",
    "except IndexError:\n",
    "    print(\"Name not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's move on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInvoice date: 2020-01-24\\n\\nInvoice for services in accordance with #T542AA1, Chap 3\\n--------------------------------------------------------\\n\\n\\nTotal expenditure: SEK 72,846\\n\\n------\\nOur contact: Fredrik Månsson (841012-8668)\\n\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841012-8668\n"
     ]
    }
   ],
   "source": [
    "# TODO – get social security number of invoices' contacts\n",
    "soc_num_p = \"\\((\\d{6}-*\\d{4})\\)\"\n",
    "mo = re.search(soc_num_p, text_example)\n",
    "print(mo.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked fine, but just in case, let's include try/except-clauses in all our regexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841012-8668\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    soc_num_p = \"\\((\\d{6}-*\\d{4})\\)\"\n",
    "    mo = re.search(soc_num_p, text_example)\n",
    "    print(mo.group(1))\n",
    "except IndexError:\n",
    "    print(\"Social security number not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above pattern, there should be parenthesis around the social security number. To include parenthesis in our regex, we need to cancel them out – `\\(` and `\\)` – since a bracket otherwise symbolises regex groups. I also put a star `*` after the dash, in case it isn't included in some invoices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72,846\n"
     ]
    }
   ],
   "source": [
    "# TODO – get charged amount \n",
    "try:\n",
    "    exp_p = \"SEK\\s*((\\d+,)*\\d+)\"\n",
    "    mo = re.search(exp_p, text_example)\n",
    "    print(mo.group(1))\n",
    "except IndexError:\n",
    "    print(\"Charged amount not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the regex pattern was also pretty straight forward. However, we will need to do something about the number format. Since we want to calculate sums on the charged amount later on, we're going to need to convert it into an integer. That won't work if there is commas in the string. \n",
    "\n",
    "Let's use the string method `.replace()` on the returned matched string to replace the comma. Then convert the charged amount to an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72846\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    exp_p = \"SEK\\s*((\\d+,)*\\d+)\"\n",
    "    mo = re.search(exp_p, text_example)\n",
    "    amount = mo.group(1)\n",
    "    # replace string's commas to empty strings and convert number to integer\n",
    "    amount = int(amount.replace(\",\",\"\"))\n",
    "    print(amount)\n",
    "except IndexError:\n",
    "    print(\"Charged amount not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have code that can gather all information we need from the files. But since we want as little duplicated code as possible, let's put the regex matching in a function that we can reuse, and the patterns by themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_matching(pattern, text, group):\n",
    "    try:\n",
    "        mo = re.search(pattern, text)\n",
    "        return mo.group(group)\n",
    "    except IndexError:\n",
    "        return \"No match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's save all regex patterns into a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Invoice date: (\\\\d+-\\\\d+-\\\\d+)'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    'date': date_p,\n",
    "    'name': name_p,\n",
    "    'soc_num': soc_num_p,\n",
    "    'exp': exp_p\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with the matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = {\n",
    "    'date': pattern_matching(patterns['date'], text_example, 1),\n",
    "    'name': pattern_matching(patterns['name'], text_example, 1),\n",
    "    'soc_num': pattern_matching(patterns['soc_num'], text_example, 1),\n",
    "    'exp': pattern_matching(patterns['exp'], text_example, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this build of our matching dictionary in a function as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_matching(file_text, patterns):\n",
    "    return {\n",
    "    'date': pattern_matching(patterns['date'], file_text, 1),\n",
    "    'name': pattern_matching(patterns['name'], file_text, 1),\n",
    "    'soc_num': pattern_matching(patterns['soc_num'], file_text, 1),\n",
    "    'exp': pattern_matching(patterns['exp'], file_text, 1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = file_matching(text_example,patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we need to change the charged amount into an integer? Let's put that code in a function as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_charged_amount(string_amount):\n",
    "    amount = string_amount.replace(\",\",\"\")\n",
    "    return int(amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fix that string in our `matches` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2020-01-24',\n",
       " 'name': 'Fredrik Månsson',\n",
       " 'soc_num': '841012-8668',\n",
       " 'exp': 72846}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches['exp'] = convert_charged_amount(matches['exp'])\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! This code can now be used over and over when we loop over all files. We can save each `matches` dictionary as an item in a list! Then we have all information collected in a tidy and clean data structure!\n",
    "\n",
    "Let's build our loop, and then run it over the 10 first files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('project')\n",
    "all_matches = []\n",
    "for file in files[:5]:\n",
    "    \n",
    "    file_text = read_pdf(path / file)\n",
    "    \n",
    "    matches = file_matching(file_text,patterns)\n",
    "    \n",
    "    # let's also add the file name to the dictionary\n",
    "    matches['file'] = file\n",
    "    \n",
    "    all_matches.append(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2020-01-24',\n",
       "  'name': 'Fredrik Månsson',\n",
       "  'soc_num': '841012-8668',\n",
       "  'exp': '72,846',\n",
       "  'file': '1483488000.pdf'},\n",
       " {'date': '2016-03-28',\n",
       "  'name': 'Kjell Månsson',\n",
       "  'soc_num': '700307-6956',\n",
       "  'exp': '45,470',\n",
       "  'file': '1171065600.pdf'},\n",
       " {'date': '2018-02-16',\n",
       "  'name': 'Adam Olofsson',\n",
       "  'soc_num': '730118-9448',\n",
       "  'exp': '59,511',\n",
       "  'file': '1473379200.pdf'},\n",
       " {'date': '2019-04-20',\n",
       "  'name': 'Fredrik Månsson',\n",
       "  'soc_num': '841012-8668',\n",
       "  'exp': '191,871',\n",
       "  'file': '1469145600.pdf'},\n",
       " {'date': '2017-07-16',\n",
       "  'name': 'Kristina Strömberg',\n",
       "  'soc_num': '680515-8461',\n",
       "  'exp': '36,390',\n",
       "  'file': '1402099200.pdf'}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops! We forgot to convert the charged amount to integers! Let's include that into the loop and then run all files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('project')\n",
    "all_matches = []\n",
    "for file in files:\n",
    "    \n",
    "    file_text = read_pdf(path / file)\n",
    "    \n",
    "    matches = file_matching(file_text,patterns)\n",
    "    matches['exp'] = convert_charged_amount(matches['exp'])\n",
    "    \n",
    "    # let's also add the file name to the dictionary\n",
    "    matches['file'] = file\n",
    "    \n",
    "    all_matches.append(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2020-01-24',\n",
       "  'name': 'Fredrik Månsson',\n",
       "  'soc_num': '841012-8668',\n",
       "  'exp': 72846,\n",
       "  'file': '1483488000.pdf'},\n",
       " {'date': '2016-03-28',\n",
       "  'name': 'Kjell Månsson',\n",
       "  'soc_num': '700307-6956',\n",
       "  'exp': 45470,\n",
       "  'file': '1171065600.pdf'},\n",
       " {'date': '2018-02-16',\n",
       "  'name': 'Adam Olofsson',\n",
       "  'soc_num': '730118-9448',\n",
       "  'exp': 59511,\n",
       "  'file': '1473379200.pdf'},\n",
       " {'date': '2019-04-20',\n",
       "  'name': 'Fredrik Månsson',\n",
       "  'soc_num': '841012-8668',\n",
       "  'exp': 191871,\n",
       "  'file': '1469145600.pdf'},\n",
       " {'date': '2017-07-16',\n",
       "  'name': 'Kristina Strömberg',\n",
       "  'soc_num': '680515-8461',\n",
       "  'exp': 36390,\n",
       "  'file': '1402099200.pdf'}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems to be in order! Now to the tricky part. The calculations! \n",
    "\n",
    "We'll start with calculating how big each persons total charged amount is. First, a todo-list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO – unique list of all social security numbers\n",
    "\n",
    "# TODO – sum up all charges per social security number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get each unique social security number, we can create an empty dictionary and then use the dictionary method `.setdefault()`. Let me show you what I mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO – unique list of all social security numbers\n",
    "unique_soc_nums = {}\n",
    "\n",
    "for match in all_matches:\n",
    "    sequence_number = match['soc_num']\n",
    "    \n",
    "    unique_soc_nums.setdefault(sequence_number, {'invoice_nums':0})\n",
    "    unique_soc_nums[sequence_number]['invoice_nums'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('841012-8668', {'invoice_nums': 46}),\n",
       " ('700307-6956', {'invoice_nums': 45}),\n",
       " ('730118-9448', {'invoice_nums': 39}),\n",
       " ('680515-8461', {'invoice_nums': 43}),\n",
       " ('720806-7526', {'invoice_nums': 49})]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unique_soc_nums.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each loop begins with an assignment statement where we save the present sequence social security number to the variable `sequence_number`. So in the first loop that is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2020-01-24',\n",
       " 'name': 'Fredrik Månsson',\n",
       " 'soc_num': '841012-8668',\n",
       " 'exp': 72846,\n",
       " 'file': '1483488000.pdf'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...'841012-8668'. This string is then passed as an argument to the `.setdefault()` method. In the first loop, since the dictionary `unique_soc_nums` is empty, the string is added to the empty dictionary as a key. To this key, a dictionary is added as its value. This nested dictionary has a key called `'invoice_nums'` with the value 0. Then the value is increased by 1. If the social security number already exists as a key in `unique_soc_nums`, the nested dictionary's `'invoice_nums'` is increased by 1. The resulting `unique_soc_nums` dictionary shows us two things:\n",
    "1. All its keys are the unique social security numbers in all the invoice files\n",
    "2. The value in each key/value pair is in how many invoices each social security number is the contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we now know all individual social security numbers that are presented as \"Contact\" in the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['841012-8668', '700307-6956', '730118-9448', '680515-8461', '720806-7526', '901019-8775', '840513-6554', '600818-7143', '770314-2749', '540911-0133', '780810-5782', '760831-3479', '770323-7384', '640330-2804', '520213-8895', '540823-9269', '740821-1817', '671112-3502', '900730-9469', '531030-3629', '810305-7056', '911027-0938', '670909-3033', '700903-4314', '890724-4379', '700225-0042', '750703-8558', '570629-9445', '660927-8714', '940103-3868', '640503-1311', '920920-6187', '541019-1859', '920130-6937', '550701-4881', '600829-5255', '620720-6124', '901013-3361', '670627-4033', '680926-0301', '600805-6177', '700214-5706', '930522-9678', '611110-9558', '541106-8358', '690406-7234', '650404-1414', '850426-9791', '730414-7637', '851202-0536', '880822-4785', '800209-5827', '550124-2383', '931224-6674', '770108-8024', '630723-0537', '610202-3691', '580819-0639', '551215-6433', '891116-0796', '800405-4607', '570710-4152', '830213-3176', '601115-1721', '531126-8762', '611206-6034', '591122-5204', '920902-6791', '950420-8754', '820911-7826', '760523-8245', '760715-9482', '510909-6498', '750501-9309', '721015-0866', '820213-5074', '521015-2284', '610213-9525', '611230-9128', '700713-9947', '840803-2839', '520226-0171', '950407-0683', '920712-5845', '820111-5266', '800502-8061', '520925-1354', '871002-7574', '951111-9062', '781209-8978', '731215-0492', '581120-1923', '570322-7928', '840620-4753', '811115-8358', '840904-3166', '911208-0021', '810111-0007', '620614-2739', '640928-9004'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO – unique list of all social security numbers\n",
    "unique_soc_nums.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate how much each person has charged the agency. We can actually continue using this `unique_soc_nums` dictionary. If we loop over `all_matches` we can simply add the value of `all_matches[i]['exp']` to each social security number in `unique_soc_nums`. Let me show you what I mean:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, if we loop over `all_matches`, in each sequence – `all_matches[i]` – the sequence item is a dictionary with each file's scraped info saved in a dictionary. Each sequence's dictionary has one key called `soc_num` with info on who is the invoice's contact person. We can use this to match with our `unique_soc_nums` dictionary. Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO – sum up all charges per social security number\n",
    "for invoice_info in all_matches:\n",
    "    soc_num = invoice_info[\"soc_num\"]\n",
    "    unique_soc_nums[soc_num].setdefault('amount',0)\n",
    "    unique_soc_nums[soc_num]['amount'] += invoice_info['exp']\n",
    "    \n",
    "    # I'll also add the name for convience\n",
    "    unique_soc_nums[soc_num].setdefault('name','')\n",
    "    unique_soc_nums[soc_num]['name'] = invoice_info['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's find the top 10 biggest debitors. This is tricky. I will first show you a method based on what we've learned so far in the course. Then, I'll show you how to do it with `pandas` – a fantastic module when working with data. \n",
    "\n",
    "We can first extract the top 10 values from the dictionary by using the `.values()` method, and then looping over each resulting dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'invoice_nums': 46, 'amount': 4911278, 'name': 'Fredrik Månsson'},\n",
       " {'invoice_nums': 45, 'amount': 5627908, 'name': 'Kjell Månsson'},\n",
       " {'invoice_nums': 39, 'amount': 3509020, 'name': 'Adam Olofsson'},\n",
       " {'invoice_nums': 43, 'amount': 4158780, 'name': 'Kristina Strömberg'},\n",
       " {'invoice_nums': 49, 'amount': 4904589, 'name': 'Christoffer Eliasson'}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amounts = list(unique_soc_nums.values())\n",
    "amounts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_amounts = []\n",
    "for dictionary in amounts:\n",
    "    all_amounts.append(dictionary['amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start, though, by checking the mean debitor's charged amount. Just so have something to compare to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5632636.45"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_amounts) / len(all_amounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's sort  `all_amounts` with the `sorted()` function. This function has the parameter `reverse` which we can set to `reverse=True` to get the top-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36674240,\n",
       " 15880560,\n",
       " 12930381,\n",
       " 12276813,\n",
       " 7531604,\n",
       " 6462500,\n",
       " 6448339,\n",
       " 6439463,\n",
       " 6405531,\n",
       " 6386916]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(all_amounts, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediatly see that four sums clearly stands out. The fourth biggest debitor is almost twice as large as the fifth. The rest is kind of close to eachother. Let's focus on the top-4. We'll save them to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_debits = sorted(all_amounts, reverse=True)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36674240, 15880560, 12930381, 12276813]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_debits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.511025578439383"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_debits[0] / 5632636.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest debitor has charged the agency more than 6.5 times the average amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know these numbers are uniques (there aren't any duplicates in `big_debits`) we can now loop over the keys in `unique_soc_nums` to find the big debitors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspects = []\n",
    "for key in unique_soc_nums.keys():\n",
    "    data = unique_soc_nums[key]\n",
    "    if data['amount'] in big_debits:\n",
    "        suspect = {}\n",
    "        suspect['name'] = data['name']\n",
    "        suspect['soc_num'] = key\n",
    "        suspect['amount'] = data['amount']\n",
    "        suspects.append(suspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Lucas Lundgren', 'soc_num': '780810-5782', 'amount': 15880560},\n",
       " {'name': 'Per Nyström', 'soc_num': '570710-4152', 'amount': 36674240},\n",
       " {'name': 'Caroline Hellström', 'soc_num': '610213-9525', 'amount': 12930381},\n",
       " {'name': 'Georg Hermansson', 'soc_num': '811115-8358', 'amount': 12276813}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! **Per Nyström is – by far – the biggest debitor!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, here how we would've found the top-10 biggest debitors using the `pandas` module on our dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_nums</th>\n",
       "      <th>amount</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570710-4152</th>\n",
       "      <td>37</td>\n",
       "      <td>36674240</td>\n",
       "      <td>Per Nyström</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780810-5782</th>\n",
       "      <td>53</td>\n",
       "      <td>15880560</td>\n",
       "      <td>Lucas Lundgren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610213-9525</th>\n",
       "      <td>45</td>\n",
       "      <td>12930381</td>\n",
       "      <td>Caroline Hellström</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811115-8358</th>\n",
       "      <td>48</td>\n",
       "      <td>12276813</td>\n",
       "      <td>Georg Hermansson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580819-0639</th>\n",
       "      <td>58</td>\n",
       "      <td>7531604</td>\n",
       "      <td>Karolina Isaksson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800405-4607</th>\n",
       "      <td>64</td>\n",
       "      <td>6462500</td>\n",
       "      <td>Anneli Lindberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570322-7928</th>\n",
       "      <td>55</td>\n",
       "      <td>6448339</td>\n",
       "      <td>Linus Wallin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911027-0938</th>\n",
       "      <td>63</td>\n",
       "      <td>6439463</td>\n",
       "      <td>Per Berg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760831-3479</th>\n",
       "      <td>64</td>\n",
       "      <td>6405531</td>\n",
       "      <td>Maria Strömberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740821-1817</th>\n",
       "      <td>58</td>\n",
       "      <td>6386916</td>\n",
       "      <td>Anette Löfgren</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            invoice_nums    amount                name\n",
       "570710-4152           37  36674240         Per Nyström\n",
       "780810-5782           53  15880560      Lucas Lundgren\n",
       "610213-9525           45  12930381  Caroline Hellström\n",
       "811115-8358           48  12276813    Georg Hermansson\n",
       "580819-0639           58   7531604   Karolina Isaksson\n",
       "800405-4607           64   6462500     Anneli Lindberg\n",
       "570322-7928           55   6448339        Linus Wallin\n",
       "911027-0938           63   6439463            Per Berg\n",
       "760831-3479           64   6405531     Maria Strömberg\n",
       "740821-1817           58   6386916      Anette Löfgren"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(unique_soc_nums).T.sort_values('amount',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_One line of code!!_ Again, I really recommend learning pandas when you've got the chance!\n",
    "\n",
    "Moving on.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we've found the biggest debitors. Now to find out how much that have been charged per year. We can use the same techniques as above. Let's start by creating a dictionary with each year as a key, and then add all the invoices of that year as the key's values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2020-01-24',\n",
       " 'name': 'Fredrik Månsson',\n",
       " 'soc_num': '841012-8668',\n",
       " 'exp': 72846,\n",
       " 'file': '1483488000.pdf'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_costs = {}\n",
    "for match in all_matches:\n",
    "    year = match['date'][:4]\n",
    "    \n",
    "    yearly_costs.setdefault(year, 0)\n",
    "    yearly_costs[year] += match['exp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020': 15920663,\n",
       " '2016': 136460450,\n",
       " '2018': 145381809,\n",
       " '2019': 137303132,\n",
       " '2017': 128197591}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearly_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's just some code to clean it up a bit. It's not code covered in the course, so don't worry if you don't understand what does what (But if you're curious, google it and try to find out!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2020': 'SEK 15,920,663',\n",
       " '2016': 'SEK 136,460,450',\n",
       " '2018': 'SEK 145,381,809',\n",
       " '2019': 'SEK 137,303,132',\n",
       " '2017': 'SEK 128,197,591'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "\n",
    "dict(zip(yearly_costs.keys(),[f\"SEK {x:n}\" for x in yearly_costs.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so 2018 was the year with the biggest costs for the agency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, the bonus assignement!**\n",
    "\n",
    "Let's check to see if anyone employed at the agency has been breaking agency policy by selling the agency third party services. Let's start by opening the text file with all the employees' social security numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../course_material/employees.txt\",\"r\") as file:\n",
    "    employees = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'510115-8394,510128-8721,510311-3447,510422-4384,510624-9382,510805-8611,520206-3043,520213-8896,5202'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the employee-list is just a string with the social security numbers separated with commas. We can use the string method `.split()` with the argument `\",\"` to divide the string into a list of string values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['510115-8394',\n",
       " '510128-8721',\n",
       " '510311-3447',\n",
       " '510422-4384',\n",
       " '510624-9382',\n",
       " '510805-8611',\n",
       " '520206-3043',\n",
       " '520213-8896',\n",
       " '520215-8201',\n",
       " '520226-0172']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees = employees.split(\",\")\n",
    "employees[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do a for-loop over the employee-list, we can check to see if any of the employees are in the invoice data. If we just check the social security number as a key to the `unique_soc_nums` variable, we will get a `KeyError` on all numbers that aren't keys in that variable. But if we include try/except-clauses, we can get around that problem. Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "shady_employees = {}\n",
    "for employee in employees:\n",
    "    try:\n",
    "        shady_employees[employee] = unique_soc_nums[employee]\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(shady_employees.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9 people employed at the agency that are also acting as contacts, debiting the agency millions of Swedish Krona (SEK) through the company's invoices. Here's their details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'611230-9128': {'invoice_nums': 43,\n",
       "  'amount': 4279656,\n",
       "  'name': 'Gunnar Åberg'},\n",
       " '700307-6956': {'invoice_nums': 45,\n",
       "  'amount': 5627908,\n",
       "  'name': 'Kjell Månsson'},\n",
       " '730118-9448': {'invoice_nums': 39,\n",
       "  'amount': 3509020,\n",
       "  'name': 'Adam Olofsson'},\n",
       " '731215-0492': {'invoice_nums': 41, 'amount': 3900421, 'name': 'Linus Åberg'},\n",
       " '760715-9482': {'invoice_nums': 56,\n",
       "  'amount': 5242601,\n",
       "  'name': 'Olof Lundgren'},\n",
       " '781209-8978': {'invoice_nums': 50,\n",
       "  'amount': 5126015,\n",
       "  'name': 'Bengt Björklund'},\n",
       " '810305-7056': {'invoice_nums': 51,\n",
       "  'amount': 5198295,\n",
       "  'name': 'Christoffer Holm'},\n",
       " '820111-5266': {'invoice_nums': 46, 'amount': 4705236, 'name': 'Lars Björk'},\n",
       " '820911-7826': {'invoice_nums': 56, 'amount': 5404565, 'name': 'Per Larsson'}}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shady_employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'invoice_nums': 43, 'amount': 4279656, 'name': 'Gunnar Åberg'},\n",
       " {'invoice_nums': 45, 'amount': 5627908, 'name': 'Kjell Månsson'},\n",
       " {'invoice_nums': 39, 'amount': 3509020, 'name': 'Adam Olofsson'},\n",
       " {'invoice_nums': 41, 'amount': 3900421, 'name': 'Linus Åberg'},\n",
       " {'invoice_nums': 56, 'amount': 5242601, 'name': 'Olof Lundgren'},\n",
       " {'invoice_nums': 50, 'amount': 5126015, 'name': 'Bengt Björklund'},\n",
       " {'invoice_nums': 51, 'amount': 5198295, 'name': 'Christoffer Holm'},\n",
       " {'invoice_nums': 46, 'amount': 4705236, 'name': 'Lars Björk'},\n",
       " {'invoice_nums': 56, 'amount': 5404565, 'name': 'Per Larsson'}]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(shady_employees.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We're done with the project! I hope you found it useful :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4.5 Exercise – Scrape President Data and put in data structure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I show you a solution, remember to not be stressed out if you think that the following code is too complicated. Take it step by step. If there is a specific part of a line of code you don't understand, try it out and experiment until you realise what's going on. If you're feeling stuck, try out some other solution! There are many ways to solve this. Keep experimenting :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the table data, as is done in section 4.4.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table', class_=\"wikitable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = table.find_all('tr')[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without using the `re` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in all_rows:\n",
    "    cell_text = row.find_all('td')[1].text # returns the name cell's text attribute\n",
    "    splitted_text = cell_text.split('(')\n",
    "    data.append(splitted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data now consists of a list with lists (also called a nested list). Let's call each of these lists rows, since that corresponds with the table data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['George Washington', '1732–1799)[17]\\n'],\n",
       " ['John Adams', '1735–1826)[19]\\n'],\n",
       " ['Thomas Jefferson', '1743–1826)[21]\\n']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a list with just the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for row in data:\n",
    "    names.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['George Washington',\n",
       " 'John Adams',\n",
       " 'Thomas Jefferson',\n",
       " 'James Madison',\n",
       " 'James Monroe']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got the names. But the data regarding years of birth and death need to be cleaned. We want to extract the years from the second item on each row.\n",
    "\n",
    "The `.split()` method will be fine doing this as well. We'll split on the dash. The first item in the resulting list will be the year of birth. The second, the year of death:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1913', '1994)[66]\\n'],\n",
       " ['1913', '2006)[67]\\n'],\n",
       " ['b. 1924)[68]\\n'],\n",
       " ['1911', '2004)[69]\\n'],\n",
       " ['1924', '2018)[70]\\n'],\n",
       " ['b. 1946)[71]\\n'],\n",
       " ['b. 1946)[72]\\n'],\n",
       " ['b. 1961)[73]\\n'],\n",
       " ['b. 1946)[74]\\n'],\n",
       " ['b. 1942)[6]\\n']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_year_data = []\n",
    "for row in data:\n",
    "    data_to_be_cleaned = row[1]\n",
    "    splitted_data = data_to_be_cleaned.split('–')\n",
    "    all_year_data.append(splitted_data)\n",
    "all_year_data[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this splits the strings correctly. Now we can split in the second closing parenthesis `)` and then fetch the first item in list from the split. But what about the presidents that are still alive? All of those starts with the characters `b. `. Let's fix those first so that the second split doesn't screw them up.\n",
    "\n",
    "We will need to have an if-statement for those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1913', '1994)[66]\\n'],\n",
       " ['1913', '2006)[67]\\n'],\n",
       " ['1924)[68]\\n'],\n",
       " ['1911', '2004)[69]\\n'],\n",
       " ['1924', '2018)[70]\\n'],\n",
       " ['1946)[71]\\n'],\n",
       " ['1946)[72]\\n'],\n",
       " ['1961)[73]\\n'],\n",
       " ['1946)[74]\\n'],\n",
       " ['1942)[6]\\n']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_year_data = []\n",
    "for row in data:\n",
    "    data_to_be_cleaned = row[1]\n",
    "    splitted_data = data_to_be_cleaned.split('–')\n",
    "\n",
    "    # if the president is still alive, the first item in the 'splitted_data'\n",
    "    # variable will start with the characters 'b. ' (a 'b', a dot '.', and \n",
    "    # a blank space ' '), so let's check if there are any such characters \n",
    "    # in the first item in 'splitted_data'\n",
    "    if 'b. ' in splitted_data[0]:\n",
    "        # now, let's remove these unnecessary characters with the .replace() method\n",
    "        splitted_data[0] = splitted_data[0].replace('b. ', '')\n",
    "    all_year_data.append(splitted_data)\n",
    "all_year_data[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now split on the second parenthesis and only return the first item in the split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in all_year_data:\n",
    "    # split should always be on the last item on each row\n",
    "    row[-1] = row[-1].split(')')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1913', '1994'],\n",
       " ['1913', '2006'],\n",
       " ['1924'],\n",
       " ['1911', '2004'],\n",
       " ['1924', '2018'],\n",
       " ['1946'],\n",
       " ['1946'],\n",
       " ['1961'],\n",
       " ['1946'],\n",
       " ['1942']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_year_data[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boom!\n",
    "\n",
    "Ok, but we need to add an item to those rows with only one item (only the year of birth). Let's do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in all_year_data:\n",
    "    # we only want to change the rows where there is only one item\n",
    "    if len(row) == 1:\n",
    "        # here, we add a dash as to show that there is no year of death\n",
    "        row.append('-')\n",
    "    else:\n",
    "        # if there is not a single item in the row, continue the loop\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1913', '1994'],\n",
       " ['1913', '2006'],\n",
       " ['1924', '-'],\n",
       " ['1911', '2004'],\n",
       " ['1924', '2018'],\n",
       " ['1946', '-'],\n",
       " ['1946', '-'],\n",
       " ['1961', '-'],\n",
       " ['1946', '-'],\n",
       " ['1942', '-']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_year_data[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I want these seperated into two lists, one for the year of birth, and one for death:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_birth = []\n",
    "y_death = []\n",
    "for row in all_year_data:\n",
    "    y_birth.append(row[0])\n",
    "    y_death.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1732', '1735', '1743', '1751', '1758']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_birth[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1799', '1826', '1826', '1836', '1831']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_death[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to do one final loop to create the data structure. Here, I will use the enumerate function (if you you're unfamiliar with it, check out section 14.5 in chapter 14 in the basics course!) and loop over the `names` variable (containing the list of all the presidents' names). Since the enumerate function also produces an index variable for each sequence in the loop, we can use this index to fetch the corresponding data in the `y_birth` and `y_death` lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for index,name in enumerate(names):\n",
    "    d = {\n",
    "        'name': name,\n",
    "        'year of birth': y_birth[index],\n",
    "        'year of death': y_death[index]\n",
    "    }\n",
    "    results.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'George Washington',\n",
       "  'year of birth': '1732',\n",
       "  'year of death': '1799'},\n",
       " {'name': 'John Adams', 'year of birth': '1735', 'year of death': '1826'},\n",
       " {'name': 'Thomas Jefferson',\n",
       "  'year of birth': '1743',\n",
       "  'year of death': '1826'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Alteration Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.1 Exercise – filter the EU member states, part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_members = [{'Country': 'Austria', 'population': 8901064},\n",
    " {'Country': 'Estonia', 'population': 1328976},\n",
    " {'Country': 'Ireland', 'population': 4963839},\n",
    " {'Country': 'Slovakia', 'population': 5457873},\n",
    " {'Country': 'Cyprus', 'population': 888005},\n",
    " {'Country': 'Sweden', 'population': 10327589},\n",
    " {'Country': 'Netherlands', 'population': 17407585},\n",
    " {'Country': 'Latvia', 'population': 1907675},\n",
    " {'Country': 'Malta', 'population': 514564},\n",
    " {'Country': 'Slovenia', 'population': 2095861},\n",
    " {'Country': 'France', 'population': 67098824},\n",
    " {'Country': 'Denmark', 'population': 5822763},\n",
    " {'Country': 'Croatia', 'population': 4058165},\n",
    " {'Country': 'Italy', 'population': 60244639},\n",
    " {'Country': 'Hungary', 'population': 9769526},\n",
    " {'Country': 'Lithuania', 'population': 2794090},\n",
    " {'Country': 'Czech Republic', 'population': 10693939},\n",
    " {'Country': 'Poland', 'population': 37958138},\n",
    " {'Country': 'Romania', 'population': 19317984},\n",
    " {'Country': 'Bulgaria', 'population': 6951482},\n",
    " {'Country': 'Finland', 'population': 552529},\n",
    " {'Country': 'Portugal', 'population': 10295909},\n",
    " {'Country': 'Greece', 'population': 10709739},\n",
    " {'Country': 'Belgium', 'population': 11549888},\n",
    " {'Country': 'Spain', 'population': 47329981},\n",
    " {'Country': 'Germany', 'population': 83166711},\n",
    " {'Country': 'Luxembourg', 'population': 626108}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter the dictionaries by using the `filter()` function, we first need to create a function that filters a dictionary. Filtering requires the function to take dictionaries and return either `True` or `False`.\n",
    "\n",
    "So let's start with such a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pop(country_data):\n",
    "    return country_data['population'] < 10_000_000 # underscores in number values is only for readability, no practical functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this function's parameter has to be a dictionary. This is because in the code block of `check_pop()`, we use the key `\"population\"` in a comparison expression. Let's try it on an item in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_pop(eu_members[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first item in the list is this dictionary:\n",
    "\n",
    "`{'Country': 'Austria', 'population': 8901064}`\n",
    "\n",
    "...and Austria has a population less than 10 million. So our function seems to work! Let's use it together with the `filter()` function on the whole list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Country': 'Austria', 'population': 8901064},\n",
       " {'Country': 'Estonia', 'population': 1328976},\n",
       " {'Country': 'Ireland', 'population': 4963839},\n",
       " {'Country': 'Slovakia', 'population': 5457873},\n",
       " {'Country': 'Cyprus', 'population': 888005},\n",
       " {'Country': 'Latvia', 'population': 1907675},\n",
       " {'Country': 'Malta', 'population': 514564},\n",
       " {'Country': 'Slovenia', 'population': 2095861},\n",
       " {'Country': 'Denmark', 'population': 5822763},\n",
       " {'Country': 'Croatia', 'population': 4058165},\n",
       " {'Country': 'Hungary', 'population': 9769526},\n",
       " {'Country': 'Lithuania', 'population': 2794090},\n",
       " {'Country': 'Bulgaria', 'population': 6951482},\n",
       " {'Country': 'Finland', 'population': 552529},\n",
       " {'Country': 'Luxembourg', 'population': 626108}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(check_pop, eu_members))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we are! It worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.4.1 Exercise – filter the EU member states, part 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty straight forward! Let's first get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_members = [{'Country': 'Austria', 'population': 8901064},\n",
    " {'Country': 'Estonia', 'population': 1328976},\n",
    " {'Country': 'Ireland', 'population': 4963839},\n",
    " {'Country': 'Slovakia', 'population': 5457873},\n",
    " {'Country': 'Cyprus', 'population': 888005},\n",
    " {'Country': 'Sweden', 'population': 10327589},\n",
    " {'Country': 'Netherlands', 'population': 17407585},\n",
    " {'Country': 'Latvia', 'population': 1907675},\n",
    " {'Country': 'Malta', 'population': 514564},\n",
    " {'Country': 'Slovenia', 'population': 2095861},\n",
    " {'Country': 'France', 'population': 67098824},\n",
    " {'Country': 'Denmark', 'population': 5822763},\n",
    " {'Country': 'Croatia', 'population': 4058165},\n",
    " {'Country': 'Italy', 'population': 60244639},\n",
    " {'Country': 'Hungary', 'population': 9769526},\n",
    " {'Country': 'Lithuania', 'population': 2794090},\n",
    " {'Country': 'Czech Republic', 'population': 10693939},\n",
    " {'Country': 'Poland', 'population': 37958138},\n",
    " {'Country': 'Romania', 'population': 19317984},\n",
    " {'Country': 'Bulgaria', 'population': 6951482},\n",
    " {'Country': 'Finland', 'population': 552529},\n",
    " {'Country': 'Portugal', 'population': 10295909},\n",
    " {'Country': 'Greece', 'population': 10709739},\n",
    " {'Country': 'Belgium', 'population': 11549888},\n",
    " {'Country': 'Spain', 'population': 47329981},\n",
    " {'Country': 'Germany', 'population': 83166711},\n",
    " {'Country': 'Luxembourg', 'population': 626108}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use comparison expressions in list comprehensions, so we won't need any functions to help us in this exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Country': 'Austria', 'population': 8901064},\n",
       " {'Country': 'Estonia', 'population': 1328976},\n",
       " {'Country': 'Ireland', 'population': 4963839},\n",
       " {'Country': 'Slovakia', 'population': 5457873},\n",
       " {'Country': 'Cyprus', 'population': 888005},\n",
       " {'Country': 'Latvia', 'population': 1907675},\n",
       " {'Country': 'Malta', 'population': 514564},\n",
       " {'Country': 'Slovenia', 'population': 2095861},\n",
       " {'Country': 'Denmark', 'population': 5822763},\n",
       " {'Country': 'Croatia', 'population': 4058165},\n",
       " {'Country': 'Hungary', 'population': 9769526},\n",
       " {'Country': 'Lithuania', 'population': 2794090},\n",
       " {'Country': 'Bulgaria', 'population': 6951482},\n",
       " {'Country': 'Finland', 'population': 552529},\n",
       " {'Country': 'Luxembourg', 'population': 626108}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in eu_members if x['population'] < 10_000_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what we did was `x for x` – which means \"give me all items\" – but only if the `x[\"population\"] < 10_000_000`. That is, only if the items population count is lower than 10 million. Pretty neat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.2.5 Exercise – Series' Calculations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is easy to overthink. But it is actually quite straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([17, -100, -20, 69, 90, 74, -6, 82, 36, 52, 59, 92, -39, 31, -39])\n",
    "s2 = pd.Series([-6, -2, -74, 52, 5, -19, 8, -28,  3, 39, 42, -59, 60, 20, -49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = s1[s1 > 0]\n",
    "s2 = s2[s2 > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum12 = s1 + s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "3     121.0\n",
       "4      95.0\n",
       "5       NaN\n",
       "6       NaN\n",
       "7       NaN\n",
       "8      39.0\n",
       "9      91.0\n",
       "10    101.0\n",
       "11      NaN\n",
       "12      NaN\n",
       "13     51.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum12.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.7 Pandas project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"\n",
    "population_path = \"../course_material/world_bank_population_data.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, for some of you, you may be able to read the covid data url straight into the pandas `.read_csv()` method. But this is sometimes blocked by some computers (don't ask why). You can first try and uncomment this line of code, and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(covid_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If that doesn't work, we need to use the requests library and fetch the dataset as a string value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from url\n",
    "r = requests.get(covid_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can access all text from the url using the `.text` attribute. And since it is a csv file, we know that all rows in the dataset is seperated by the newline character `\\n`. Let's fetch the text attribute and split the string on all newline characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r.text.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`csv` stands for \"comma seperated values\", which means that all cells are seperated by commas. We can therefore loop over all rows in the dataset and split on commas – which will return cells per row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = []\n",
    "for row in data:\n",
    "    covid_data.append(row.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is now an acceptable data structure to use as a pandas Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(covid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1138</th>\n",
       "      <th>1139</th>\n",
       "      <th>1140</th>\n",
       "      <th>1141</th>\n",
       "      <th>1142</th>\n",
       "      <th>1143</th>\n",
       "      <th>1144</th>\n",
       "      <th>1145</th>\n",
       "      <th>1146</th>\n",
       "      <th>1147</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Province/State</td>\n",
       "      <td>Country/Region</td>\n",
       "      <td>Lat</td>\n",
       "      <td>Long</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1/24/20</td>\n",
       "      <td>1/25/20</td>\n",
       "      <td>1/26/20</td>\n",
       "      <td>1/27/20</td>\n",
       "      <td>...</td>\n",
       "      <td>3/1/23</td>\n",
       "      <td>3/2/23</td>\n",
       "      <td>3/3/23</td>\n",
       "      <td>3/4/23</td>\n",
       "      <td>3/5/23</td>\n",
       "      <td>3/6/23</td>\n",
       "      <td>3/7/23</td>\n",
       "      <td>3/8/23</td>\n",
       "      <td>3/9/23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.5063</td>\n",
       "      <td>1.5218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0               1         2          3        4        5     \\\n",
       "0  Province/State  Country/Region       Lat       Long  1/22/20  1/23/20   \n",
       "1                     Afghanistan  33.93911  67.709953        0        0   \n",
       "2                         Albania   41.1533    20.1683        0        0   \n",
       "3                         Algeria   28.0339     1.6596        0        0   \n",
       "4                         Andorra   42.5063     1.5218        0        0   \n",
       "\n",
       "      6        7        8        9     ...    1138    1139    1140    1141  \\\n",
       "0  1/24/20  1/25/20  1/26/20  1/27/20  ...  3/1/23  3/2/23  3/3/23  3/4/23   \n",
       "1        0        0        0        0  ...    7896    7896    7896    7896   \n",
       "2        0        0        0        0  ...    3598    3598    3598    3598   \n",
       "3        0        0        0        0  ...    6881    6881    6881    6881   \n",
       "4        0        0        0        0  ...     165     165     165     165   \n",
       "\n",
       "     1142    1143    1144    1145    1146  1147  \n",
       "0  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  None  \n",
       "1    7896    7896    7896    7896    7896  None  \n",
       "2    3598    3598    3598    3598    3598  None  \n",
       "3    6881    6881    6881    6881    6881  None  \n",
       "4     165     165     165     165     165  None  \n",
       "\n",
       "[5 rows x 1148 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row is messed up, however. The column headers are now the first row in the dataframe. Let's have a look at the first row, using the `.iloc` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Province/State\n",
       "1    Country/Region\n",
       "2               Lat\n",
       "3              Long\n",
       "4           1/22/20\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert that into a list and pass it to the `.columns` attribute. This will rename all columns to the same values wihtin the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.iloc[0,:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>3/1/23</th>\n",
       "      <th>3/2/23</th>\n",
       "      <th>3/3/23</th>\n",
       "      <th>3/4/23</th>\n",
       "      <th>3/5/23</th>\n",
       "      <th>3/6/23</th>\n",
       "      <th>3/7/23</th>\n",
       "      <th>3/8/23</th>\n",
       "      <th>3/9/23</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Province/State</td>\n",
       "      <td>Country/Region</td>\n",
       "      <td>Lat</td>\n",
       "      <td>Long</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1/24/20</td>\n",
       "      <td>1/25/20</td>\n",
       "      <td>1/26/20</td>\n",
       "      <td>1/27/20</td>\n",
       "      <td>...</td>\n",
       "      <td>3/1/23</td>\n",
       "      <td>3/2/23</td>\n",
       "      <td>3/3/23</td>\n",
       "      <td>3/4/23</td>\n",
       "      <td>3/5/23</td>\n",
       "      <td>3/6/23</td>\n",
       "      <td>3/7/23</td>\n",
       "      <td>3/8/23</td>\n",
       "      <td>3/9/23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Province/State  Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0  Province/State  Country/Region       Lat       Long  1/22/20  1/23/20   \n",
       "1                     Afghanistan  33.93911  67.709953        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  3/1/23  3/2/23  3/3/23  3/4/23  \\\n",
       "0  1/24/20  1/25/20  1/26/20  1/27/20  ...  3/1/23  3/2/23  3/3/23  3/4/23   \n",
       "1        0        0        0        0  ...    7896    7896    7896    7896   \n",
       "\n",
       "   3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  None  \n",
       "0  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  None  \n",
       "1    7896    7896    7896    7896    7896  None  \n",
       "\n",
       "[2 rows x 1148 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now exclude the first row from the data, since it is obsolete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>3/1/23</th>\n",
       "      <th>3/2/23</th>\n",
       "      <th>3/3/23</th>\n",
       "      <th>3/4/23</th>\n",
       "      <th>3/5/23</th>\n",
       "      <th>3/6/23</th>\n",
       "      <th>3/7/23</th>\n",
       "      <th>3/8/23</th>\n",
       "      <th>3/9/23</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long 1/22/20 1/23/20 1/24/20  \\\n",
       "1                   Afghanistan  33.93911  67.709953       0       0       0   \n",
       "2                       Albania   41.1533    20.1683       0       0       0   \n",
       "\n",
       "  1/25/20 1/26/20 1/27/20  ... 3/1/23 3/2/23 3/3/23 3/4/23 3/5/23 3/6/23  \\\n",
       "1       0       0       0  ...   7896   7896   7896   7896   7896   7896   \n",
       "2       0       0       0  ...   3598   3598   3598   3598   3598   3598   \n",
       "\n",
       "  3/7/23 3/8/23 3/9/23  None  \n",
       "1   7896   7896   7896  None  \n",
       "2   3598   3598   3598  None  \n",
       "\n",
       "[2 rows x 1148 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see that all data is formatted as excpected. We For example, we don't want our integer values to be strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3/6/23    object\n",
       "3/7/23    object\n",
       "3/8/23    object\n",
       "3/9/23    object\n",
       "None      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns are strings, let's convert them to numeric values with a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns[4:]:\n",
    "    # there are columns without a name, let's skip those in the loop\n",
    "    if not column:\n",
    "        continue\n",
    "    \n",
    "    df[column] = df[column].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Quick aside, the reason I am converting the values to floats, and not integers, is because there are `NaN` values in the dataset. And pandas cannot convert `NaN`s to integers, they are programmed as floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3/6/23    float64\n",
       "3/7/23    float64\n",
       "3/8/23    float64\n",
       "3/9/23    float64\n",
       "None       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we calculate deaths per 100 000 inhabitants, it is pointed out that we need to group our data on country, since there could be more than one row per country. Let's look at China:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>3/1/23</th>\n",
       "      <th>3/2/23</th>\n",
       "      <th>3/3/23</th>\n",
       "      <th>3/4/23</th>\n",
       "      <th>3/5/23</th>\n",
       "      <th>3/6/23</th>\n",
       "      <th>3/7/23</th>\n",
       "      <th>3/8/23</th>\n",
       "      <th>3/9/23</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>30.0572</td>\n",
       "      <td>107.874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>26.0789</td>\n",
       "      <td>117.9874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>China</td>\n",
       "      <td>35.7518</td>\n",
       "      <td>104.2861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Province/State Country/Region      Lat      Long  1/22/20  1/23/20  \\\n",
       "60          Anhui          China  31.8257  117.2264      0.0      0.0   \n",
       "61        Beijing          China  40.1824  116.4142      0.0      0.0   \n",
       "62      Chongqing          China  30.0572   107.874      0.0      0.0   \n",
       "63         Fujian          China  26.0789  117.9874      0.0      0.0   \n",
       "64          Gansu          China  35.7518  104.2861      0.0      0.0   \n",
       "\n",
       "    1/24/20  1/25/20  1/26/20  1/27/20  ...  3/1/23  3/2/23  3/3/23  3/4/23  \\\n",
       "60      0.0      0.0      0.0      0.0  ...     7.0     7.0     7.0     7.0   \n",
       "61      0.0      0.0      0.0      1.0  ...    20.0    20.0    20.0    20.0   \n",
       "62      0.0      0.0      0.0      0.0  ...    11.0    11.0    11.0    11.0   \n",
       "63      0.0      0.0      0.0      0.0  ...     2.0     2.0     2.0     2.0   \n",
       "64      0.0      0.0      0.0      0.0  ...     2.0     2.0     2.0     2.0   \n",
       "\n",
       "    3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  None  \n",
       "60     7.0     7.0     7.0     7.0     7.0  None  \n",
       "61    20.0    20.0    20.0    20.0    20.0  None  \n",
       "62    11.0    11.0    11.0    11.0    11.0  None  \n",
       "63     2.0     2.0     2.0     2.0     2.0  None  \n",
       "64     2.0     2.0     2.0     2.0     2.0  None  \n",
       "\n",
       "[5 rows x 1148 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Country/Region']=='China'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Chinese regions are included in the dataset. We need to summerize by country to get a total death by country. We'll do so with the method `.groupby()` with the `Country/Region` column as argument, and then chain the `.sum()` method to produce a summary per country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('Country/Region').sum().reset_index() # <- the .reset_index() is just to return a dataframe without multiindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the columns we don't need. The lat/long columns are unecessary, and also `Province/State`. According to the assignment, we need to calculate the covid death per 100 000 inhabitants as of 31st january 2022. So that is the only value column needed. The dataset dates are in an American format `MM/DD/YY`. Since the covid data is displayed as a cumulated summary per country, we only need that one column for 31st of January of 2022. That is, the column called `1/31/22`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Country/Region','1/31/22']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, cool! Only problem is I hate those column name (I really, _really_ don't like American date formats). Here's some new column names to make it a bit cleaner and a bit more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['name','deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ascension and Tristan da Cunha\"</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sint Eustatius and Saba\"</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Korea</td>\n",
       "      <td>6755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>7414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>3346.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name  deaths\n",
       "0   Ascension and Tristan da Cunha\"     0.0\n",
       "1          Sint Eustatius and Saba\"    27.0\n",
       "2                            \"Korea  6755.0\n",
       "3                       Afghanistan  7414.0\n",
       "4                           Albania  3346.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, the covid dataset is now cleaned. Let's fetch the population data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_excel(population_path,engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'code', '2020'], dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need the names and the population column (\"2020\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pop[['name','2020']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the `name` column to the same column name as within the covid data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.columns = ['name','population_2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pop.merge(df,on='name',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>population_2020</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>106766.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "      <td>677243299.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928341.0</td>\n",
       "      <td>7414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa Western and Central</td>\n",
       "      <td>458803476.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>32866268.0</td>\n",
       "      <td>1895.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  population_2020  deaths\n",
       "0                        Aruba         106766.0     NaN\n",
       "1  Africa Eastern and Southern      677243299.0     NaN\n",
       "2                  Afghanistan       38928341.0  7414.0\n",
       "3   Africa Western and Central      458803476.0     NaN\n",
       "4                       Angola       32866268.0  1895.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some names isn't the same in the two datasets. I'm not gonna bother with those now, I'll just remove them. But you should know that common practice is not to merge on names, rather merge on a key that you know are the same in the two datasets, like country iso codes for each country. But let's not bother here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>population_2020</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928341.0</td>\n",
       "      <td>7414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>32866268.0</td>\n",
       "      <td>1895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2837743.0</td>\n",
       "      <td>3346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>9890400.0</td>\n",
       "      <td>2243.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  population_2020  deaths\n",
       "2           Afghanistan       38928341.0  7414.0\n",
       "4                Angola       32866268.0  1895.0\n",
       "5               Albania        2837743.0  3346.0\n",
       "6               Andorra          77265.0   145.0\n",
       "8  United Arab Emirates        9890400.0  2243.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will calculate the deeaths per 100 000 inhabitants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/dn3z3xv17xddwrgpxsn4zgqr0000gp/T/ipykernel_31027/4229747749.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['dead_p_100k'] = (df['deaths'] / df['population_2020']) * 100_000\n"
     ]
    }
   ],
   "source": [
    "df['dead_p_100k'] = (df['deaths'] / df['population_2020']) * 100_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you also get som highlighted red text, that is just a pandas warning regarding naming conventions. It's not an error, so we can just ignore that. Let's create a column which displays rank based on deaths per inhabitants. We can do so with the `.rank()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/dn3z3xv17xddwrgpxsn4zgqr0000gp/T/ipykernel_31027/3731158715.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['rank'] = df['dead_p_100k'].rank(method='max',ascending=False)\n"
     ]
    }
   ],
   "source": [
    "df['rank'] = df['dead_p_100k'].rank(method='max',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see the top 10 countries in deaths per inhabitants, as of 31st of January 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>population_2020</th>\n",
       "      <th>deaths</th>\n",
       "      <th>dead_p_100k</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Peru</td>\n",
       "      <td>32971846.0</td>\n",
       "      <td>205834.0</td>\n",
       "      <td>624.271993</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>6927288.0</td>\n",
       "      <td>33318.0</td>\n",
       "      <td>480.967444</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>3280815.0</td>\n",
       "      <td>14447.0</td>\n",
       "      <td>440.347901</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Hungary</td>\n",
       "      <td>9749763.0</td>\n",
       "      <td>41405.0</td>\n",
       "      <td>424.676990</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>621718.0</td>\n",
       "      <td>2564.0</td>\n",
       "      <td>412.405624</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>2617820.0</td>\n",
       "      <td>10642.0</td>\n",
       "      <td>406.521457</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>2083380.0</td>\n",
       "      <td>8409.0</td>\n",
       "      <td>403.622959</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>3714000.0</td>\n",
       "      <td>14930.0</td>\n",
       "      <td>401.992461</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>4047200.0</td>\n",
       "      <td>13827.0</td>\n",
       "      <td>341.643605</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>33938.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>321.173905</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  population_2020    deaths  dead_p_100k  rank\n",
       "186                    Peru       32971846.0  205834.0   624.271993   1.0\n",
       "21                 Bulgaria        6927288.0   33318.0   480.967444   2.0\n",
       "24   Bosnia and Herzegovina        3280815.0   14447.0   440.347901   3.0\n",
       "101                 Hungary        9749763.0   41405.0   424.676990   4.0\n",
       "162              Montenegro         621718.0    2564.0   412.405624   5.0\n",
       "150                 Moldova        2617820.0   10642.0   406.521457   6.0\n",
       "157         North Macedonia        2083380.0    8409.0   403.622959   7.0\n",
       "82                  Georgia        3714000.0   14930.0   401.992461   8.0\n",
       "99                  Croatia        4047200.0   13827.0   341.643605   9.0\n",
       "212              San Marino          33938.0     109.0   321.173905  10.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('rank').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I live in Sweden, so to see Sweden we can filter on that country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>population_2020</th>\n",
       "      <th>deaths</th>\n",
       "      <th>dead_p_100k</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>10353442.0</td>\n",
       "      <td>15855.0</td>\n",
       "      <td>153.137478</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  population_2020   deaths  dead_p_100k  rank\n",
       "223  Sweden       10353442.0  15855.0   153.137478  48.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['name']=='Sweden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank 48 of the 170 countries within the dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
