{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Python – Learning useful python skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Files\" data-toc-modified-id=\"Files-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Paths\" data-toc-modified-id=\"Paths-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Paths</a></span><ul class=\"toc-item\"><li><span><a href=\"#Absolute-paths\" data-toc-modified-id=\"Absolute-paths-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Absolute paths</a></span></li><li><span><a href=\"#The-pathlib-module\" data-toc-modified-id=\"The-pathlib-module-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>The <code>pathlib</code> module</a></span><ul class=\"toc-item\"><li><span><a href=\"#Path-objects'-special-syntax\" data-toc-modified-id=\"Path-objects'-special-syntax-1.1.2.1\"><span class=\"toc-item-num\">1.1.2.1&nbsp;&nbsp;</span>Path objects' special syntax</a></span></li></ul></li><li><span><a href=\"#Relative-paths\" data-toc-modified-id=\"Relative-paths-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Relative paths</a></span></li></ul></li><li><span><a href=\"#Managing-files-and-folders\" data-toc-modified-id=\"Managing-files-and-folders-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Managing files and folders</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-files\" data-toc-modified-id=\"Reading-files-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Reading files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-binary-files\" data-toc-modified-id=\"Reading-binary-files-1.2.1.1\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>Reading binary files</a></span></li></ul></li><li><span><a href=\"#Creating-and-changing-files\" data-toc-modified-id=\"Creating-and-changing-files-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Creating and changing files</a></span></li><li><span><a href=\"#Automatically-close-files-with-with-open()-as-...!\" data-toc-modified-id=\"Automatically-close-files-with-with-open()-as-...!-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Automatically close files with <code>with open() as ...</code>!</a></span></li><li><span><a href=\"#Creating-directories\" data-toc-modified-id=\"Creating-directories-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Creating directories</a></span></li><li><span><a href=\"#Creating-files-with-the-pathlib-module\" data-toc-modified-id=\"Creating-files-with-the-pathlib-module-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Creating files with the <code>pathlib</code> module</a></span></li><li><span><a href=\"#Exercise-–-file-creator-function\" data-toc-modified-id=\"Exercise-–-file-creator-function-1.2.6\"><span class=\"toc-item-num\">1.2.6&nbsp;&nbsp;</span>Exercise – file creator function</a></span></li><li><span><a href=\"#Deleting-files-and-folders\" data-toc-modified-id=\"Deleting-files-and-folders-1.2.7\"><span class=\"toc-item-num\">1.2.7&nbsp;&nbsp;</span>Deleting files and folders</a></span></li><li><span><a href=\"#Copying-and-moving-files\" data-toc-modified-id=\"Copying-and-moving-files-1.2.8\"><span class=\"toc-item-num\">1.2.8&nbsp;&nbsp;</span>Copying and moving files</a></span></li><li><span><a href=\"#Looping-over-files\" data-toc-modified-id=\"Looping-over-files-1.2.9\"><span class=\"toc-item-num\">1.2.9&nbsp;&nbsp;</span>Looping over files</a></span></li></ul></li><li><span><a href=\"#Exercise-–-move-the-textfiles\" data-toc-modified-id=\"Exercise-–-move-the-textfiles-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Exercise – move the textfiles</a></span></li><li><span><a href=\"#Reading-pdf-documents\" data-toc-modified-id=\"Reading-pdf-documents-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Reading pdf documents</a></span></li><li><span><a href=\"#Exercise-–-pdf-to-text-function\" data-toc-modified-id=\"Exercise-–-pdf-to-text-function-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Exercise – pdf to text function</a></span></li></ul></li><li><span><a href=\"#Regular-Expressions\" data-toc-modified-id=\"Regular-Expressions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Regular Expressions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Finding-numbers\" data-toc-modified-id=\"Finding-numbers-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Finding numbers</a></span></li><li><span><a href=\"#Repetition-qualifiers\" data-toc-modified-id=\"Repetition-qualifiers-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Repetition qualifiers</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-star-*\" data-toc-modified-id=\"The-star-*-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>The star <code>*</code></a></span></li><li><span><a href=\"#The-plus-sign-+\" data-toc-modified-id=\"The-plus-sign-+-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>The plus sign <code>+</code></a></span></li><li><span><a href=\"#The-question-mark-?\" data-toc-modified-id=\"The-question-mark-?-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>The question mark <code>?</code></a></span></li><li><span><a href=\"#Curly-brackets-{m,n}\" data-toc-modified-id=\"Curly-brackets-{m,n}-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Curly brackets <code>{m,n}</code></a></span></li><li><span><a href=\"#Repition-qualifiers,-in-the-wild!\" data-toc-modified-id=\"Repition-qualifiers,-in-the-wild!-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>Repition qualifiers, in the wild!</a></span></li></ul></li><li><span><a href=\"#Finding-words-and-names\" data-toc-modified-id=\"Finding-words-and-names-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Finding words and names</a></span><ul class=\"toc-item\"><li><span><a href=\"#Custom-character-classes-with-square-brackets-[]\" data-toc-modified-id=\"Custom-character-classes-with-square-brackets-[]-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Custom character classes with square brackets <code>[]</code></a></span></li><li><span><a href=\"#The-&quot;word&quot;-character-\\w\" data-toc-modified-id=\"The-&quot;word&quot;-character-\\w-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>The \"word\" character <code>\\w</code></a></span></li><li><span><a href=\"#The-white-space-character-\\s\" data-toc-modified-id=\"The-white-space-character-\\s-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>The white space character <code>\\s</code></a></span></li><li><span><a href=\"#Finding-the-names\" data-toc-modified-id=\"Finding-the-names-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>Finding the names</a></span></li></ul></li><li><span><a href=\"#Exercise-–-matching-phone-numbers\" data-toc-modified-id=\"Exercise-–-matching-phone-numbers-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Exercise – matching phone numbers</a></span></li><li><span><a href=\"#Regex-Groups\" data-toc-modified-id=\"Regex-Groups-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Regex Groups</a></span></li><li><span><a href=\"#Exercise-–-can-you-find-the-number?\" data-toc-modified-id=\"Exercise-–-can-you-find-the-number?-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Exercise – can you find the number?</a></span></li><li><span><a href=\"#The-Escape-Character-\\\" data-toc-modified-id=\"The-Escape-Character-\\-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>The Escape Character <code>\\</code></a></span></li><li><span><a href=\"#The-Pipe-Character-|\" data-toc-modified-id=\"The-Pipe-Character-|-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>The Pipe Character <code>|</code></a></span></li><li><span><a href=\"#Exercise-–-who-has-landlines?\" data-toc-modified-id=\"Exercise-–-who-has-landlines?-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>Exercise – who has landlines?</a></span></li><li><span><a href=\"#Matching-in-portions,-or-matching-everything\" data-toc-modified-id=\"Matching-in-portions,-or-matching-everything-2.10\"><span class=\"toc-item-num\">2.10&nbsp;&nbsp;</span>Matching in portions, or matching everything</a></span><ul class=\"toc-item\"><li><span><a href=\"#Match-the-start-–-use-^\" data-toc-modified-id=\"Match-the-start-–-use-^-2.10.1\"><span class=\"toc-item-num\">2.10.1&nbsp;&nbsp;</span>Match the start – use <code>^</code></a></span></li><li><span><a href=\"#Match-the-end-–-use-$\" data-toc-modified-id=\"Match-the-end-–-use-$-2.10.2\"><span class=\"toc-item-num\">2.10.2&nbsp;&nbsp;</span>Match the end – use <code>$</code></a></span></li><li><span><a href=\"#Refining-our-regex-patterns\" data-toc-modified-id=\"Refining-our-regex-patterns-2.10.3\"><span class=\"toc-item-num\">2.10.3&nbsp;&nbsp;</span>Refining our regex patterns</a></span></li><li><span><a href=\"#Match-(almost)-everything-–-the-wildcard-.\" data-toc-modified-id=\"Match-(almost)-everything-–-the-wildcard-.-2.10.4\"><span class=\"toc-item-num\">2.10.4&nbsp;&nbsp;</span>Match (almost) everything – the wildcard <code>.</code></a></span></li><li><span><a href=\"#Matching-row-by-row-with-.*\" data-toc-modified-id=\"Matching-row-by-row-with-.*-2.10.5\"><span class=\"toc-item-num\">2.10.5&nbsp;&nbsp;</span>Matching row by row with <code>.*</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#(Optional)-Greedy-.*,-non-greedy-.*?\" data-toc-modified-id=\"(Optional)-Greedy-.*,-non-greedy-.*?-2.10.5.1\"><span class=\"toc-item-num\">2.10.5.1&nbsp;&nbsp;</span>(Optional) Greedy <code>.*</code>, non-greedy <code>.*?</code></a></span></li></ul></li></ul></li><li><span><a href=\"#Flags\" data-toc-modified-id=\"Flags-2.11\"><span class=\"toc-item-num\">2.11&nbsp;&nbsp;</span>Flags</a></span><ul class=\"toc-item\"><li><span><a href=\"#re.DOTALL\" data-toc-modified-id=\"re.DOTALL-2.11.1\"><span class=\"toc-item-num\">2.11.1&nbsp;&nbsp;</span><code>re.DOTALL</code></a></span></li><li><span><a href=\"#(Optional)-re.IGNORECASE\" data-toc-modified-id=\"(Optional)-re.IGNORECASE-2.11.2\"><span class=\"toc-item-num\">2.11.2&nbsp;&nbsp;</span>(Optional) <code>re.IGNORECASE</code></a></span></li></ul></li></ul></li><li><span><a href=\"#Project-–-The-Invoices\" data-toc-modified-id=\"Project-–-The-Invoices-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Project – The Invoices</a></span></li><li><span><a href=\"#Web-scraping\" data-toc-modified-id=\"Web-scraping-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Web scraping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Website's-foundation\" data-toc-modified-id=\"Website's-foundation-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Website's foundation</a></span></li><li><span><a href=\"#Inspecting-websites\" data-toc-modified-id=\"Inspecting-websites-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Inspecting websites</a></span></li></ul></li><li><span><a href=\"#The-requests-module\" data-toc-modified-id=\"The-requests-module-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>The <code>requests</code> module</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-response-object\" data-toc-modified-id=\"The-response-object-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>The response object</a></span></li><li><span><a href=\"#Affirming-the-response-object\" data-toc-modified-id=\"Affirming-the-response-object-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Affirming the response object</a></span></li><li><span><a href=\"#Accessing-content-–-the-binary-string\" data-toc-modified-id=\"Accessing-content-–-the-binary-string-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Accessing content – the binary string</a></span></li><li><span><a href=\"#Downloading-a-plaintext-file\" data-toc-modified-id=\"Downloading-a-plaintext-file-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;</span>Downloading a plaintext file</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exploring-the-text-data\" data-toc-modified-id=\"Exploring-the-text-data-4.2.4.1\"><span class=\"toc-item-num\">4.2.4.1&nbsp;&nbsp;</span>Exploring the text data</a></span></li></ul></li><li><span><a href=\"#Downloading-and-working-with-csv-files\" data-toc-modified-id=\"Downloading-and-working-with-csv-files-4.2.5\"><span class=\"toc-item-num\">4.2.5&nbsp;&nbsp;</span>Downloading and working with csv files</a></span><ul class=\"toc-item\"><li><span><a href=\"#(Optional)-Exploring-and-converting-csv-data\" data-toc-modified-id=\"(Optional)-Exploring-and-converting-csv-data-4.2.5.1\"><span class=\"toc-item-num\">4.2.5.1&nbsp;&nbsp;</span>(Optional) Exploring and converting csv data</a></span></li></ul></li><li><span><a href=\"#Downloading-and-working-with-json-files\" data-toc-modified-id=\"Downloading-and-working-with-json-files-4.2.6\"><span class=\"toc-item-num\">4.2.6&nbsp;&nbsp;</span>Downloading and working with json files</a></span></li></ul></li><li><span><a href=\"#Scraping-html-elements-–--using-BeautifulSoup\" data-toc-modified-id=\"Scraping-html-elements-–--using-BeautifulSoup-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Scraping html elements –  using <code>BeautifulSoup</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-scraping-loops\" data-toc-modified-id=\"Creating-scraping-loops-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Creating scraping loops</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've made it this far, congratulations! You have learned most of the basics in the Python programming language! The first two notebooks in this course focuses mainly on understanding the foundations of Python. This notebook is where we start learning more of how to use Python to do useful things. \n",
    "\n",
    "So what's useful? Consider the following: you work at some company. You have just been handed a USB stick with ten thousand pdf files. These files have a date in their names, such as `rec20200414.pdf` (i.e. April 14, 2020) . The files are photocopies of receipts. On each receipt there is a name of the employed person at your company that has created the file. \n",
    "\n",
    "Your task is to see:\n",
    "\n",
    "- Who are the employed that have created all the receipts?\n",
    "- How many receipts are created per employée?\n",
    "- How many receipts are there per employée, per month?\n",
    "\n",
    "Now, we _could_ do this by hand. Reading all files ourselves and typing the information by hand into an Excel spreadsheet. But this would, first, take weeks. Second, be incredably boring. And, third, probably (because the assignement's been so tedious and boring) be riddled with errors.\n",
    "\n",
    "However, this is actually a perfect example of a task that is easily solved with Python! Here's a task list of what we could do: \n",
    "- Create a list of all the files\n",
    "- Create a script that extract the name from a pdf receipt\n",
    "- Loop over all files \n",
    "\n",
    "And on each file in our loop:\n",
    "1. Run our script on each one of the pdf files\n",
    "2. Extract date from file name\n",
    "3. Save the name and the date into a data structure\n",
    "\n",
    "In this course, you will learn to do all these tasks! \n",
    "\n",
    "Let's take it step by step and start with learning about filepaths. Then how to create, remove and alter files on our computer using python. We will also learn the basics of regular expressions (text recognition). Then, you will do a project that is similar to the task list above. And finally, as a bonus, some web scraping basics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files on your computer have these three componants: a name (this notebook, for instance, is called `continuation_course`), a file extension (Jupyter Notebooks have the extension `.ipynb`, plaintext files `.txt`, Microsoft Word has `.doc`, Excel files have `.xlsx`, etc etc…), and a path – the file's location on your harddrive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files have a **path**. This lets us know where it is located on the computer's hard drive. All folders – also called **directories** – also have paths. There are two kinds of paths: **relative** and **absolute**. We'll start with the absolute, and continue with the relative further down. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absolute paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An absolute path is a file's location in relation to your hard drive's root folder. The root folder – or **root directory** –  is the top level of your hard drive. All files and folders are inside this directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use Windows, you probably recognise your root directory when you see it. It's the `C:\\` when you check your hard drive folders. See this picture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](../course_material/windows_root.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Mac/Linux, the root directory is just named `/`.\n",
    "\n",
    "Another important difference is the **directory separator**, the slash. On Windows, this is a backslash `\\`, while on Mac/Linux, it's just a regular slash `/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook you're running, is located somewhere on your computer's hard drive. This location can be found when checking the file's absolute path. Or to be more precise: we can check where this notebook \"lives\" within your root directory! We could use the `os` module to check the absolute path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/johekm/Documents/lectures/learning_python/continuation_course'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for me, this notebook has this path: `'/Users/johekm/Documents/lectures/learning_python/continuation_course'`. It lives in the folder `continuation_course`, which is in the folder `learning_python`, which is in `lectures`, which is in my `Documents` folder, and so forth all the way to the root directory. \n",
    "\n",
    "This notebook's name is `continuation_course.ipynb`, which means that its absolute path is:\n",
    "\n",
    "`'/Users/johekm/Documents/lectures/learning_python/continuation_course/continuation_course.ipynb'`\n",
    "\n",
    "If this was a Windows laptop, it would look something like:\n",
    "\n",
    "`'C:\\Users\\johekm\\Documents\\lectures\\learning_python\\continuation_course\\continuation_course.ipynb'`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All absolute paths have the root directory to the left. That is, **absolute paths always starts with the root directory**. The directory or the file we're looking for is furthest to the right in the path. So in above examples, we point towards the file `continuation_course.ipynb`, since it is to the right in the path. \n",
    "\n",
    "We can also use the `os.path.isabs()` method on our path. It takes a string value and sees if it's a absolute path on our computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isabs('/Users/johekm/Documents/lectures/learning_python/continuation_course/continuation_course.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `os` module takes string values as arguments. It also returns paths as string values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we can use the `.join()` method on our directory separator character (`/` on Mac/Linux, `\\` on Windows), to get strings with paths! So on on my current running absolute path I could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = ['','Users','johekm','Documents','lectures','learning_python','continuation_course','continuation_course.ipynb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Users',\n",
       " 'johekm',\n",
       " 'Documents',\n",
       " 'lectures',\n",
       " 'learning_python',\n",
       " 'continuation_course',\n",
       " 'continuation_course.ipynb']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/'.join(my_path) # see section 9.9.2 in the basics course if you want a refreasher!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/johekm/Documents/lectures/learning_python/continuation_course/continuation_course.ipynb'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isabs(my_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.listdir()` method to get a list of all files in a directory. We just pass a path to the method as an argument, and it returns a list. Let's try it on the `course_material` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/Users/johekm/Documents/lectures/learning_python/course_material'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mutable_scope.png',\n",
       " 'excelfile.xlsx',\n",
       " '.DS_Store',\n",
       " 'while_loop.png',\n",
       " 'scopes.png',\n",
       " 'employees.txt',\n",
       " 'eu_report.txt',\n",
       " 'readme',\n",
       " 'windows_root.png',\n",
       " 'invoice.pdf',\n",
       " 'immutable_1.png',\n",
       " 'interrupt.png',\n",
       " 'immutable_3.png',\n",
       " 'speach.txt',\n",
       " 'immutable_2.png',\n",
       " 'scb.json',\n",
       " 'if_statement.png',\n",
       " 'hello.txt',\n",
       " 'mutable.png',\n",
       " 'report.pdf',\n",
       " 'mutable_2.png',\n",
       " 'phone_list.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(my_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `pathlib` module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common practice to use string values when working with file paths. But as you can see from the example above, paths as string values will not work on Windows if written for Mac (and vice versa), since the path syntax is different.\n",
    "\n",
    "So instead, we're gonna use the `pathlib` module. This works on all operating systems since the Python interpreter converts all paths into whatever syntax your computer uses! Let's import the `Path` class from the `pathlib` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Path` class has a method called `.cwd()` (\"current working directory\") that returns the absolute path of your current \"position\" on your harddrive. Let's have a look at the current working path using this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/johekm/Documents/lectures/learning_python/continuation_course')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the value returned isn't a string. It is a path object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib.PosixPath"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This path object actually differs depending on what operating system you're using. For me, using mac, it is a `PosixPath` object. If you're using Windows, it should be a `WindowsPath` object. But the name is not important. Just know a path object is a way to help us construct paths in a very convenient way! \n",
    "\n",
    "We can pass any string to the Path class to convert it into a path object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('Johan')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"Johan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `os` module can read path objects, so we can use them to check if this path object is an absolute path: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isabs(Path(\"Johan\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Johan\" isn't an absolute path, but our current working directory is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isabs(Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.home()` method returns the home directory on the computer. For me, this is `/Users/johekm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/johekm')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.home()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can always use the `.exists()` method to see if a path exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"/Users/johekm/Documents/lectures/learning_python/course_material\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"/Users/johekm/Documents/lectures/learning_python/BANANAS\").exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Path objects' special syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path objects can use operators as their own syntax. This means that I can use the `.home()` method and then construct a path I now will work on whatever operating system you're now running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/johekm/Documents/lectures/learning_python/continuation_course')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.home() / \"Documents\" / \"lectures\" / \"learning_python\" / \"continuation_course\"\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hang on, what the hell happend?? Why did we just use the division operator together with strings and somehow just magically created a path??\n",
    "\n",
    "If a line of Python code includes a path object, the `/` will not be read as a division operator by the interpreter, it will be read as a path seperator! It will then reconstruct this entire line into one path object. Above code is the same as typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/johekm/Documents/lectures/learning_python/continuation_course')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.home() / Path(\"Documents\") / Path(\"lectures\") / Path(\"learning_python\") / Path(\"continuation_course\")\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/johekm/Documents/lectures/learning_python/continuation_course')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.home() / Path(\"Documents/lectures/learning_python/continuation_course\")\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or just:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/johekm/Documents/lectures/learning_python/continuation_course')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.home() / \"Documents/lectures/learning_python/continuation_course\"\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A relative path always starts in the current working directory. We use relative paths to find files and directories in relation to where we are currently situated – where our python code currently runs – on our hard drive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're using relative paths, we often want to see what is \"above\" the current working directory. This is called the **parent directory**. Using relative paths, we can type the `..` to access the parent folder! Double dots `..` in a path means \"check one directory level above the current one\", or \"check the current working directory's parent directory\". \n",
    "\n",
    "Uncomment this following code cell and run it, then check to see if the listed files are as you expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue using `..` with directory separators to go even further up the directory tree. If you placed this course folder in the \"Documents\" directory on you computer, you should see the contents in your \"Documents\" folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also type a single dot `.`, which indicates _this_ folder. The one we're in. Uncomment to check if it's what you expect it to be on your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section above, we listed all files and directories in the folder `course_material`, using the `.listdir()` method. Let's do so again, but with a relative path instead of an absolute one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mutable_scope.png',\n",
       " 'excelfile.xlsx',\n",
       " '.DS_Store',\n",
       " 'while_loop.png',\n",
       " 'scopes.png',\n",
       " 'employees.txt',\n",
       " 'eu_report.txt',\n",
       " 'readme',\n",
       " 'windows_root.png',\n",
       " 'invoice.pdf',\n",
       " 'immutable_1.png',\n",
       " 'interrupt.png',\n",
       " 'immutable_3.png',\n",
       " 'speach.txt',\n",
       " 'immutable_2.png',\n",
       " 'scb.json',\n",
       " 'if_statement.png',\n",
       " 'hello.txt',\n",
       " 'mutable.png',\n",
       " 'report.pdf',\n",
       " 'mutable_2.png',\n",
       " 'phone_list.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../course_material')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go a bit deeper, there is a folder within `course_material` named `readme`. Let's list its content using a relative path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['material.png',\n",
       " '.DS_Store',\n",
       " 'navigator.png',\n",
       " 'duplicate.png',\n",
       " 'searchbar.png',\n",
       " 'course_start.png',\n",
       " 'jupyter.png',\n",
       " 'create_nb.png',\n",
       " 'documents.png',\n",
       " 'launchpad.png']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../course_material/readme/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for both you and me, this relative path is the same. But if we would use an absolute path, it wouldn't be. This is one of the reasons why you'd want to use relative paths from time to time. Also, because it is shorter to type and, therefore, more convenient. It is also, at least to me, easier to read and understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the absolute path to the same \"readme\" directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/Users/johekm/Documents/lectures/learning_python/\") / \"course_material\" / \"readme\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['material.png',\n",
       " '.DS_Store',\n",
       " 'navigator.png',\n",
       " 'duplicate.png',\n",
       " 'searchbar.png',\n",
       " 'course_start.png',\n",
       " 'jupyter.png',\n",
       " 'create_nb.png',\n",
       " 'documents.png',\n",
       " 'launchpad.png']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing files and folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've had a look at paths, we can use them to create, open, append and erase files! \n",
    "\n",
    "Files can be binary files or plaintext files. Binary files consists of a complicated soup of code patterns that is unreadable for humans. Most files you use at your office are probably binary files: such as excel files, pdf documents, etc etc. \n",
    "\n",
    "Here, we're going to start with plaintext files. Plaintext means that there are nothing but just raw text in the file. There isn't any other information than the actual text characters within the file. Text files (with the extension `.txt`) is also plaintext.\n",
    "\n",
    "Let's look for a plaintext file! If we check the file contents in the `course_material` folder, we can see that there are two plaintext files therein. Let's use the `.listdir()` method of the `os` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mutable_scope.png',\n",
       " 'excelfile.xlsx',\n",
       " '.DS_Store',\n",
       " 'while_loop.png',\n",
       " 'scopes.png',\n",
       " 'readme',\n",
       " 'windows_root.png',\n",
       " 'immutable_1.png',\n",
       " 'interrupt.png',\n",
       " 'immutable_3.png',\n",
       " 'speach.txt',\n",
       " 'immutable_2.png',\n",
       " 'if_statement.png',\n",
       " 'hello.txt',\n",
       " 'mutable.png',\n",
       " 'mutable_2.png']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../course_material/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see two text files! \"speach.txt\" and \"hello.txt\". Let's start with the latter and read its content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can open files with the built-in `open()` function. It has two important arguments. First, a _filepath_ that points to the file we want to open (including the filename). Second, we pass a string that determines _how_ to open the file. Default is to open in \"read mode\", and is set with the argument `\"r\"`. This opens the file, but hinders us from changing its content. \n",
    "\n",
    "Let's open the file \"hello.txt\" in the `course_material` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../course_material/hello.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `open()` function returns a file object that we save into the `file` variable! Let's have a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='../course_material/hello.txt' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that the object is opened in read mode, and that it's encoded in unicode, UTF-8 (what this is, specifically, isn't covered in the course). We can use the `.read()` method to have a look at the file content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world!\\n\\nSo happy to see that you guys made it to the continuation course.\\nThis is where we start having fun!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.read()` method returns all the file's text as one string. As you can see, the file includes newline characters `\\n`. The method `.readlines()` also opens the file's contents, but here, all the file's lines are items organised in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello world!\\n',\n",
       " '\\n',\n",
       " 'So happy to see that you guys made it to the continuation course.\\n',\n",
       " 'This is where we start having fun!']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"../course_material/hello.txt\",\"r\")\n",
    "file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're done with the file and want to close it, we use the `.close()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we can't access the file object any longer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-f3fc120c03c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading binary files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also read binary files, but binary content will look like gibberish to a human eye. To read a binary file, we need to pass the argument `\"rb\"` (\"read binary\") instead of `\"r\"` as the second argument of the open function. Let's have a look at an excel file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile = open('../course_material/excelfile.xlsx',\"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not open the entire file, just the first 200 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'PK\\x03\\x04\\x14\\x00\\x06\\x00\\x08\\x00\\x00\\x00!\\x00\\x0c\\xeb\\xe3\\xff[\\x01\\x00\\x00\\x88\\x04\\x00\\x00\\x13\\x00\\x08\\x02[Content_Types].xml \\xa2\\x04\\x02(\\xa0\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excelFile.read()[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and changing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass the string `\"w\"` as an argument to open in write mode, which lets us change the file's content. If the file our path points to doesn't exist, and we open in write mode, _we will create a file_. Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"test.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we didn't give the `open()` function an absolute path, it took the path and looked for a file named `test.txt` in the current working directory. Since no such file existed, it created one. Have a look in the course folder, there should now be a new text file named \"test\"!\n",
    "\n",
    "So, if we open a file in write mode, and no such file exists, we will create a new file. But what happens if we try to open a file that doesn't exist in read mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'xyz.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-419d60724ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xyz.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'xyz.txt'"
     ]
    }
   ],
   "source": [
    "open(\"xyz.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an error!\n",
    "\n",
    "Ok, so we have created a file, and simultanously opened this file in write mode. Let's check the file object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='test.txt' mode='w' encoding='UTF-8'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the object is in write mode, we can add content to the file! Let's start by creating a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is some very exciting and new content going on here!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our file object has a method called `.write()` that takes whatever content we want to add to the file as an argument. This will then be written to the file object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method returns an integer, in this case 57. It is the length of the content we just added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now added our content, let's close the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now check the text file, you'll see that our text string was added! Yay!\n",
    "\n",
    "**CAUTION!** If you now open the file in write mode again, you'll see that its content has been erased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"test.txt\",\"w\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"test.txt\",\"r\")\n",
    "file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to add content to our file, we can open it in \"append mode\", using the argument `\"a\"`. Let's add our text again, and then open the file in append mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"test.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(text)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"test.txt\",\"a\") # append mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \"\\nSome new exciting text that we've added!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.write(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the files content to see if our new text was added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test.txt', \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is some very exciting and new content going on here!\n",
      "Some new exciting text that we've added!\n"
     ]
    }
   ],
   "source": [
    "print(file.read())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatically close files with `with open() as ...`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed while using the `open()` function and file objects, it's easy to forget to close them. This can create problems since if we don't close the file, the computer will keep you file open during the rest of your program's running time. This uses memory resources and can create bugs in your code. Therefore, it is best practice to _always_ close file objects after you've used them.\n",
    "\n",
    "There is a very common pattern to open files in Python that automatically closes files for you. It is, hence, the favoured way to open files by most Python programmers. It's called the context manager pattern and uses the `with`- statement. \n",
    "\n",
    "Let's start by opening a file with the context manager pattern, then I'll explain what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is some very exciting and new content going on here!\n",
      "Some new exciting text that we've added!\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.txt\", \"r\") as read_file:\n",
    "    print(read_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! First a long (maybe a bit confusing) explanation of how this :\n",
    "\n",
    "When the `with` keyword is used, it is called a `with`-statement. The `with` keyword is always followed by an expression of some kind. This expression is evaluated first, and the `with` statement then automatically assigns that evaluation of the variable name following the `as` keyword. In this case, the `read_file` variable. So the functionality generally looks like this:\n",
    "\n",
    "```\n",
    "with expression [as variable]:\n",
    "    with-block\n",
    "```\n",
    "\n",
    "When the with-block of code is executed, all variables are \"exited\". This means that the file object created in the `with`-statement is automatically closed. \n",
    "\n",
    "___\n",
    "\n",
    "So, even if you didn't really understand this explanation, just know that you should use this pattern: \n",
    "\n",
    "**When writing/reading/appending files, always use the context manager pattern with a `with`-statement.** It will save you alot of headaches in the future!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Creating directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `os` module, we can also create new directories. The `.mkdir()` takes a path as an argument and creates a new folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"fruits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This _relative path_ created a new directory in the current working directory. You can check to see by yourself in the course folder, or we can use the `pathlib` module to check if this directory exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"fruits\").is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that this method will raise an error if the folder we try to create already exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'fruits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-ec62e3a505dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fruits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'fruits'"
     ]
    }
   ],
   "source": [
    "os.mkdir(\"fruits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating files with the `pathlib` module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard procedure to create and alter files is with the `open()` function. Interestingly, the `pathlib` module has this function built in, which makes creating files a bit smoother.\n",
    "\n",
    "Let's start by creating a path object. We want this path object to include the name of the file we're gonna create. So the path will be the path to where the new file should live, _and_ the name of this new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd() / \"fruits\" / \"new_file.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/johekm/Documents/lectures/learning_python/continuation_course/fruits/new_file.txt')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path object actually has the `open()` function as a method! You can also use this method in a `with`-statement. Let's create a new textfile in the `fruits` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with path.open(\"w\") as file:\n",
    "    text = \"This is a new file created using the pathlib module!\"\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the same path object to again open the file. But in read mode this time to see if it worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file created using the pathlib module!\n"
     ]
    }
   ],
   "source": [
    "with path.open(\"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yey! It worked! There actually is a faster way to reading the file. Our path object has the `.read_text()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a new file created using the pathlib module!'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we got the file's content opened and returned using only 1 line of code! Let's try it on another file, this time without saving the path to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is some very exciting and new content going on here!\\nSome new exciting text that we've added!\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"test.txt\").read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty neat, right?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise – file creator function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise I want you to create a function that creates a text file (with the `.txt` file extension). It should take two arguments: First an absolute path (including the new file's name). Second, a string that should be the contents of the new file. \n",
    "\n",
    "\n",
    "Your function should check to see if the passed path exists, and if not, it should warn the user and return `None`. Bonus points if your function also checks if a text file with the passed name already exists at the location the path points to, and in that case just adds the passed string to the file on a new line.\n",
    "\n",
    "The solution can be found in the solutions notebook. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting files and folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick warning before we learn how to delete files and folders. When doing so in Python code, **the files we erase won't be moved to the trash bin of your computer. They will be permenantly erased.** So be careful with what you type so you don't accidently remove something you want to keep :)\n",
    "\n",
    "There are a number of ways of erasing files and folders. First, we have the `.remove()` method of the `os` module. Let's first create a file that we can delete with this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"test.txt\",\"w\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the file was created as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"test.txt\").is_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's delete it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"test.txt\").is_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gone!\n",
    "\n",
    "We can also use the `pathlib` module to remove files. The `Path` class has the method `.unlink()` that works similarly to `os.remove()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"test.txt\",\"w\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"test.txt\").is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"test.txt\").unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"test.txt\").is_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gone!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to remove directories, we can do so with both the `os` and the `pathlib` modules. Here, I'll just show you the pathlib method. Let's first create a directory (but only if this directory doesn't exist):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path('apples').is_dir():\n",
    "    Path('apples').mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we checked to see if there is a directory called \"apples\" in this current working directory. If not, create it! Let's see if it worked as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path('apples').is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's remove it using the `.rmdir()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('apples').rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path('apples').is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gone! Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in section 1.2.2, we created a text file and put it in the folder \"fruits\". Let's check to see if it's still there. If not, let's create a new directory and file with this following code!\n",
    "\n",
    "(Try to go through this code, do you understand what is going on? I've added comments to help you out!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"fruits\") # relative path to the directory fruits\n",
    "\n",
    "if not path.is_dir():\n",
    "    # if the folder \"fruits\" doesn't exists, this code block executes\n",
    "    \n",
    "    path.mkdir() # create the \"fruits\" folder\n",
    "    \n",
    "    path = path / \"new_file.txt\" # append filename to path\n",
    "    \n",
    "    path.open(\"w\") # create file!\n",
    "    \n",
    "else:\n",
    "    # if \"fruits\" exists, check to see if there is a text file within called \"new_file.txt\"\n",
    "    path = path / \"new_file.txt\"\n",
    "    \n",
    "    if not path.is_file():\n",
    "        # if no file, create it:\n",
    "        path.open(\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"fruits/new_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's remove the \"fruits\" directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 66] Directory not empty: 'fruits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-a30cfa566068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fruits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36mrmdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 66] Directory not empty: 'fruits'"
     ]
    }
   ],
   "source": [
    "Path(\"fruits\").rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoopsie! This method doesn't work when there is content within the directory. It _only_ works on empty directories. Let's try the `os` module's method instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 66] Directory not empty: 'fruits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-a6785ed59a32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fruits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: [Errno 66] Directory not empty: 'fruits'"
     ]
    }
   ],
   "source": [
    "os.rmdir(\"fruits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh? Same problem there >:("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that to remove this \"fruits\" folder, we annoyingly have to remove the file (or files) within it first. \n",
    "\n",
    "Fortunatly, there is a way to just remove an entire tree of folders and files. We'll just have to import and use the `shutil` module. It has the method `.rmtree()` that can help us out.\n",
    "\n",
    "**CAUTION!!!** Since this method **removes all directories and all files in a passed path**. It _doesn't move it to the trash bin of your computer_, it just erases it for good. Be VERY careful that you don't pass a path to something important. Use with care! \n",
    "\n",
    "Let's import it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"fruits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(\"fruits/new_file.txt\")\n",
    "path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gone!\n",
    "\n",
    "As you can see, the entire directory and its contents have been deleted. Again, be careful with this method!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copying and moving files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `shutil` module for copying and moving files, using its `.copy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new file and then a new directory. We'll try to move the file into the directory, using Python code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this if-statement is just to be sure there isn't a 'fruits' folder already\n",
    "if not os.path.isdir(\"fruits\"):\n",
    "    os.mkdir('fruits') # creating a new folder called \"fruits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"new_file.txt\",\"w\") # creating a new file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the we can see our new file and folder in the course directory, uncomment and check for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir() # no path means that it will list the content in the current working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's move our file into the \"fruits\" folder, using the `.copy()` method of the `shutil` module. The copy method takes two arguments: one path to the file object we want to copy, and one path pointing to where we want to copy the file to. Let's create two such path objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_path = Path(\"new_file.txt\")\n",
    "destination_path = \"fruits\" / origin_path # path object syntax, remember? Check section 1.1.2.1 if not :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('fruits/new_file.txt')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(origin_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.copy()` method returns the destination path as a default, so don't let that confuse you! Now let's check to see if it worked. Either check for yourself in the course folder on you computer, or by running this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_file.txt']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"fruits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While copying and moving our file, we can also rename it by writing a new name in the destination path argument. Let me show you what I mean: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_path = Path(\"new_file.txt\")\n",
    "destination_path = \"fruits\" / Path(\"new_file_new_name.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('fruits/new_file_new_name.txt')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(origin_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_file.txt', 'new_file_new_name.txt']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"fruits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See! We took the file \"new_file.txt\" and copied it to the folder \"fruits\", renaming it to \"new_file_new_name.txt\" in the process. Pretty handy!\n",
    "\n",
    "Now let's delete the fruits directory, with its content, and our test file \"new_file.txt\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"fruits\") # removes the \"fruits\" fodler and all its content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the file, we can use the `.unlink()` method on our file's path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('new_file.txt')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_path.unlink() # removes the \"new_file.txt\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"fruits\").is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gone! Well done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping over files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to manage files – creating, altering, deleting and moving them. And you actually now know enough to loop over files in directories to find what you're looking for! But let's do it together.\n",
    "\n",
    "We'll start by using the `.listsir()` method of the `os` module to see the contents in the `course_material` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mutable_scope.png',\n",
       " 'excelfile.xlsx',\n",
       " '.DS_Store',\n",
       " 'while_loop.png',\n",
       " 'scopes.png',\n",
       " 'employees.txt',\n",
       " 'eu_report.txt',\n",
       " 'readme',\n",
       " 'windows_root.png',\n",
       " 'invoice.pdf',\n",
       " 'immutable_1.png',\n",
       " 'interrupt.png',\n",
       " 'immutable_3.png',\n",
       " 'speach.txt',\n",
       " 'immutable_2.png',\n",
       " 'scb.json',\n",
       " 'if_statement.png',\n",
       " 'hello.txt',\n",
       " 'mutable.png',\n",
       " 'report.pdf',\n",
       " 'mutable_2.png',\n",
       " 'phone_list.txt']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(\"../course_material/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get _all_ files' and directories' names when using this method. But what if we only want the plaintext files? That is, the files with the file extension `.txt`? We can use a loop!\n",
    "\n",
    "As you may have noticed, all list items that are returned from `.listdir()` are string values. This means that we can use _string methods_ on each item in a for-loop. \n",
    "\n",
    "Since we're looking for the file extension `.txt`, and since file extensions always are at the end of filenames, this is a perfect situation to use the string method `.endswith()`. It does exactly what you think it does!\n",
    "\n",
    "So let's create a for loop! But first, we're gonna need the path to where the files are located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../course_material/\") # path to files\n",
    "file_list = os.listdir(path) # list of files, based on path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mutable_scope.png',\n",
       " 'excelfile.xlsx',\n",
       " '.DS_Store',\n",
       " 'while_loop.png',\n",
       " 'scopes.png',\n",
       " 'employees.txt',\n",
       " 'eu_report.txt',\n",
       " 'readme',\n",
       " 'windows_root.png',\n",
       " 'invoice.pdf',\n",
       " 'immutable_1.png',\n",
       " 'interrupt.png',\n",
       " 'immutable_3.png',\n",
       " 'speach.txt',\n",
       " 'immutable_2.png',\n",
       " 'scb.json',\n",
       " 'if_statement.png',\n",
       " 'hello.txt',\n",
       " 'mutable.png',\n",
       " 'report.pdf',\n",
       " 'mutable_2.png',\n",
       " 'phone_list.txt']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the for-loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employees.txt\n",
      "eu_report.txt\n",
      "speach.txt\n",
      "hello.txt\n",
      "phone_list.txt\n"
     ]
    }
   ],
   "source": [
    "# loop over each file name in \"file_list\"\n",
    "for file in file_list:\n",
    "    if file.endswith(\".txt\"):\n",
    "        # if the filename ends with \".txt\", this will be executed\n",
    "        print(file)\n",
    "    else:\n",
    "        # if not, this will be executed\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hang on! Slowly now – what happend here?\n",
    "\n",
    "First, we created a path, pointing to the \"course_material\" directory and saved this path to the variable `path`. We then used the `.listdir()` method (passing our path variable as an argument) to get a list of the files in the folder. Then, we saved this list into a variable named `file_list`. \n",
    "\n",
    "We created a for-loop that looped over all filenames in `file_list`. In each sequence of the loop, the if statement `if file.endswith(\".txt\")` returns `True` if the present file's extension is `.txt`. If true, the filename will be printed, otherwise, the else clause will be executed – only containing a continue statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to save these text files names? We just create a new list variable to append to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = []\n",
    "\n",
    "for file in file_list:\n",
    "    if file.endswith(\".txt\"):\n",
    "        text_files.append(file)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['employees.txt', 'eu_report.txt', 'speach.txt', 'hello.txt', 'phone_list.txt']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an incredibly powerful technique. Imagine you have hundreds of files in one folder that needs some minor adjustment, and then be moved to another directory. This is the basic technique you'll be using!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise – move the textfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, I want you to create a function that moves all text files in one directory to another. But first, you're gonna run this code cell below. Don't worry about the code itself, its just to create the files we want for this exercise. I've added comments to the code for those curious:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "from random import randint, seed\n",
    "\n",
    "seed(30)\n",
    "\n",
    "# First, create tree of directories\n",
    "path = Path('exercise')\n",
    "if os.path.isdir(path):\n",
    "    shutil.rmtree(path)\n",
    "    os.mkdir(path)\n",
    "    os.mkdir(path / 'old_location')\n",
    "    os.mkdir(path / 'new_location')\n",
    "else:\n",
    "    os.mkdir(path)\n",
    "    os.mkdir(path / 'old_location')\n",
    "    os.mkdir(path / 'new_location')\n",
    "\n",
    "# This following code randomly creates 500 files\n",
    "file_path = Path('exercise/old_location')\n",
    "for i in range(500):\n",
    "    # random number to decide file extension of present sequence\n",
    "    num = randint(0,1)\n",
    "    # if 'num' equals 0 -> plaintext, otherwise pythonfile\n",
    "    file_ext = \".txt\" if num == 0 else \".py\"\n",
    "    \n",
    "    # Here to decide file content\n",
    "    if file_ext == '.txt':\n",
    "        text = \"This is a plaintext file!\"\n",
    "    else:\n",
    "        text = \"# this is a python file\"\n",
    "        \n",
    "    # finally, writing and closing the file\n",
    "    file = open(file_path / f\"file_{randint(500,10000)}{file_ext}\",\"w\")\n",
    "    file.write(text)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There! We just created 500 files for this exercise! They are located in the  newly created 'exercise' directory – in this current working directory. Here's the exact path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('exercise/old_location')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at 10 of the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file_3656.py',\n",
       " 'file_3534.txt',\n",
       " 'file_8252.py',\n",
       " 'file_2819.txt',\n",
       " 'file_9233.txt',\n",
       " 'file_661.txt',\n",
       " 'file_7049.py',\n",
       " 'file_9409.txt',\n",
       " 'file_7525.py',\n",
       " 'file_1519.txt']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(file_path)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the actual exercise. I want you to move copies of all the plaintext files in the \"old_location\" directory to the \"new_location\" directory (also within the \"exercise\" folder). This should be done with a function that takes two arguments: the path where the files are located, and the path to where the files shall be moved.\n",
    "\n",
    "Bonus points: add a third parameter to your function – the present date. This date shall be added to all the files' filename while moving them to the folder \"new_location\". Also, try to find out how many text files there are. Are there more than python files?\n",
    "\n",
    "The solution can be found in the solutions notebook. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading pdf documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In section 1.2.1.1, we briefly touched the subject of binary files. If we open them with the `open()` function, their content just look like nonsens. PDF documents are binary files, and if we want to be able to work with their content, we're going to need software that helps us translate its binary code into something we can read. \n",
    "\n",
    "Fortunatly, there are a number of options available for us! Unfortunatly, they are all either third party modules, or a bit complicated to download and install. So, here, we will install a third party module that is pretty good at reading pdf-files: `PyPDF2`. \n",
    "\n",
    "Hopefully, you have installed Anaconda as was recommended. Then, you should be able to run this code cell below. It installs the module in your Anaconda set-up. Just uncomment (remove the `#` character) and run the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge pypdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to import the `PyPDF2` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an error of some kind, try googling how to install third party modules in Anaconda. Add your operative system in the search. Usually, you can find useful answers in search results from the webpage `stackoverflow.com`. If you can't find a solution, or can't be bothered finding one at the moment, just read along!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an annoying fact: **PDF documents are an absolute god awful mess!** \n",
    "\n",
    "Many times when you read a pdf document to extract text, there will be some kind of problems with the resulting text. Text characters getting mixed up, paragraphs that get mixed together, tables that can't be read etc etc… \n",
    "\n",
    "The basic reason for this is actually quite intuative: there are as many pdf layouts as there are pdf files. Everyone makes their own layout with their own fonts, colors, logos, pictures etc. That said, the `PyPDF2` module is pretty good! It works well enough to try out in most situations. There are better alternatives, but they're too complicated to go through in this course.\n",
    "\n",
    "So, let's read a pdf using `PyPDF2`! First we open the file using the `open()` function, but in \"rb\" mode (\"read binary\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../course_material/report.pdf\",\"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyPDF2 module has the class `PdfFileReader`. We can pass our file object to this class and it will return a pdf file object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = PyPDF2.PdfFileReader(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you got a warning, don't worry about it!)\n",
    "\n",
    "The pdf file object now has a number of useful methods. We can for example check number of pages, using the `.getNumPages()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_file.getNumPages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.getPage()` method on our pdf file object. It will return a new page object if we specify a particular page as an argument to the method. The pages are zero indexed, so first page is always 0. Let's call the method on the second page (index 1) and save it to a new page object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pdf_file.getPage(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `.extractText()` on our page object to get the page's text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the year the board held six board meetings, including a statutory \n",
      "meeting in conjunction with the AGM. As in previous years, there was a \n",
      "very high level of attendance by board members. The CEO, CFO and \n",
      "chief accountant also attend all the meetings. Generally, one or two func\n",
      "tions/departments are invited to each meeting to give a status presenta\n",
      "tion concerning what their particular function is working on; for example, \n",
      "every six months the head of sustainability provides an update on \n"
     ]
    }
   ],
   "source": [
    "print(page.extractText()[:500]) # first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get all pages text into one single text string, we need to loop over all pages in the pdf file object. Let's first create an empty string to add text to in our loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use the `.getNumPages()` method to get the total number of sequences for our loop. Then create one page object per loop to extract text from and add it to our `content` variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pdf_file.getNumPages()):\n",
    "    \n",
    "    # get page object:\n",
    "    page = pdf_file.getPage(i)\n",
    "    \n",
    "    # extract text from page object and concatinate to our 'content' variable:\n",
    "    content += page.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55344"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's _one_ way to extract text from a pdf file! If you want to learn a better way, try to install and understand how to use the `pdftotext` software. This is, unfortunatly, not covered in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise – pdf to text function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `PyPDF2` module, build a function that converts a pdf file to a plaintext file. It should take two arguments. The first is a path to the pdf file that the user wants to convert to text. The second is a path to where the resulting plaintext file should be saved. Here's an example of what the paths should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a relative path pointing to the file 'example.pdf' in the current working directory\n",
    "pdf_path = Path(\"example.pdf\")\n",
    "results_path = Path(\"pdf_content.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you could use absolute paths as well. My absolute path would then be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/johekm/Documents/lectures/learning_python/continuation_course')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = Path.cwd() / \"example.pdf\"\n",
    "results_path = Path.cwd() / \"pdf_content.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your function should look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_converter(pdf, results):\n",
    "    # your code goes here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note the `pass` keyword. It is just a placeholder statement that is used in functions when you can't be bothered to fill the function with code, but the code should still run without errors. Without this **pass statement**, the above cell would produce an error. [See this page if you want more information](https://stackoverflow.com/questions/13886168/how-to-use-the-pass-statement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when you run the function, it should look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_function(pdf_path, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which then converts the pdf into a text string and saves it in a plaintext file at where the `results_path` points to.\n",
    "\n",
    " My solution can be found in the solutions notebook. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you're working in a word document, and you want to find some specific words within it, like your own name. What do you do? Most of you are probably familiar with the <kbd>⌃ Control</kbd>+<kbd>F</kbd> command on your keyboard. This is convenient way to find a _specific_ word or number in your document. \n",
    "\n",
    "But what if what you're looking for isn't specific? More thematic? What if you're looking for a pattern rather than a word or number? Let's say you're searching for a special set of numbers, but you don't know exactly what numbers there are. Or that you're not only interested in your own name, but all names in the document. This is all perfect examples of when to use **regular expressions** (also called **regex**, or **regexp**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regular expression is a pattern of written characters in a text string. It is a kind of code. We can use this code string patterns to find matches in texts. \n",
    "\n",
    "The simplest form of regex is basic text characters and numerical digits. The character `P` could be used as a regex to find all the P's in a given text. So could the digit `9` be used to find all number 9's. But regular expressions can also be extremly advanced and complicated.\n",
    "\n",
    "Let's get into some basic syntax. We pass our regular expression patterns to methods within the `re` module. So let's start by importing the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a bunch of court documents, and we want to see who all the people involved in the case are. All relevant actors in the court cases are registred with their social security number, so we can know who they are by getting their number. But the documents are 6000 pages long. Extracting the numbers by hand would take forever. Instead, we could use a regular expression!\n",
    "\n",
    "In Sweden (where I come from), social security numbers are maybe best translated to \"person number\". They are standardised. They always have this pattern: your date of birth – YY/MM/DD – followed by four personal digits. Here is a (made up) Swedish social security number as an example: 820312-0133. The last digit signifies if you are male (odd numbers) or female (even numbers). \n",
    "\n",
    "So, six number digits, followed by a dash `-`, and then four more digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regular expressions, the syntax for a digit is `\\d`. This will match on any number digit in a text. And to match this number character in a text, we use the `re` module. First we type out the pattern we're interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\\d\\d\\d\\d\\d\\d-\\d\\d\\d\\d\" # six digits, followed by a dash '-', followed by four digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass this pattern to the `.compile()` method. This returns a regular expression object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_regex = re.compile(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a variable with a string value we can test our pattern on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a string containing a phone number (08-655 15 00), and a social security number (820312-0133).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our regex object has a method that lets us search for our pattern in a text string – the `.search()` method. If it doesn't find a match, it will return `None`. If it finds a match, it will return a match object. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(89, 100), match='820312-0133'>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_regex.search(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It found a match! We can see what it matched on in the object's specifications. But let's save it into a match object variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = num_regex.search(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the `.group()` method on our match object to return the actual string value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'820312-0133'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.search()` method can also be called straight from the `re` module, bypassing the use of the `.compile()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'820312-0133'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo = re.search(pattern, text) # no need for .compile()!\n",
    "mo.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(In this chapter, I will not use the `.compile()` method since, for example, the `.search()` method automatically compiles the regex for us. But you should know that it exists, since it is included in most other courses covering regexes)_\n",
    "\n",
    "The `.search()` method looks through the string and returns a match object _as soon as it finds a match_. This means that it only returns the first match of the pattern. Let me show you what I mean by only searching for `\\d` – any numerical digit – within the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = re.search(\"\\d\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a string containing a phone number (08-655 15 00), and a social security number (820312-0133).'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search method started looking for the pattern `\\d` from left going right over our string. It found its first match at the digit \"0\", and then returned the match object. So, this means that there are a whole bunch of digits that we don't catch using the search method. \n",
    "\n",
    "So, if we're looking for more than one match, we need to use another method. Thankfully, there is one called `.findall()` that returns a list of all our pattern's matches in the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.findall(\"\\d\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '8',\n",
       " '6',\n",
       " '5',\n",
       " '5',\n",
       " '1',\n",
       " '5',\n",
       " '0',\n",
       " '0',\n",
       " '8',\n",
       " '2',\n",
       " '0',\n",
       " '3',\n",
       " '1',\n",
       " '2',\n",
       " '0',\n",
       " '1',\n",
       " '3',\n",
       " '3']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we return to our previous pattern, we can use `.findall()` if we want to be sure to match on all social security numbers in the string. Let's change the string so that it contains two social security numbers, and then find all matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a string containing a social security number (620821-1542), \\\n",
    "and another social security number (820312-0133).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['620821-1542', '820312-0133']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = re.findall(pattern,text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repetition qualifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern we wrote to find Swedish social security numbers is neither pretty, nor readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\\d\\d\\d\\d\\d\\d-\\d\\d\\d\\d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, we _can_ make it more readable! In regular expressions, there are symbols that signals to the interpreter that we want a specific character a certain number of time. They are called **repetition qualifiers** (`*`, `+`, `?` and `{m,n}`) and they are always put right after the character we want them to affect.\n",
    "\n",
    "Below, I will go through them one by one. But please note that I will use the `.findall()` method on all examples. This is only because it saves a tiny bit of effort to type out, no other special reason :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The star `*`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The star `*` qualifier means that the affected character is included and repeated in the expression zero or more times. Let me show you what I mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"ab*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pattern will match on \"a\", \"ab\", or \"abbbbbbbb\". The star `*` is right after the \"b\". Let's try it on a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"abc\") # match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"ac\") # match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'ab']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"aabc\") # match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'a', 'a', 'abbbbbbbb']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"aaaaabbbbbbbbc\") # matches on each individual 'a', and finally on 'a' followed by 'b's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"bc\") # no match, since there needs to be an 'a' followed by zero or more 'b's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The plus sign `+`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `+` qualifier signals that we want the affected character matched _at least once_, but also, as many times as possible. So, in short, the character should be included once or more! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"ab+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"abc\") # match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"ac\") # no match since 'b' needs to be included once or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"aabc\") # match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbbbbbbb']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"aaaaabbbbbbbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The question mark `?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `?` qualifier means that the character should be included zero or once, but never more than once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"ab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"abc\") # match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"ac\") # match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'ab']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"aabc\") # match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'a', 'a', 'ab']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"aaaaabbbbbbbbc\") # match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"abbc\") # match!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curly brackets `{m,n}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the curly brackets `{}` within our expression's pattern. Within the brackets we pass one, or two numbers separated by a comma, specifying how many times the character should be included. If just one number is within the curly brackets, this number specifies exactly how many times the character should be repeated in our matches. So, if we type `b{4}`, this means the character \"b\" _exactly_ four times to give a match. Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"ab{4}\" # one \"a\", followed by exactly four b's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"abc\") # no match, only one 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"ac\") # no match, no 'b's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"aabc\") # no match, only one 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbbb']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"aaaaabbbbbbbbc\") # match! One 'a' together with 4 'b's returned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we give two numbers to the curly brackets, this signals a span of the affected character. So `b{2,5}` means it will a return a match of at least two 'b's, and at the most five:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"ab{2,5}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abb']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"aabbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbbbb']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,\"aaaaabbbbbbbbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repition qualifiers, in the wild!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using repition qualifiers, we can make our pattern on social security numbers way more convenient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\\d{6}-\\d{4}\" # six digits, followed by dash '-', followed by four digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a string containing a social security number (620821-1542), and another social security number (820312-0133).\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a string containing a social security number (620821-1542), and another social security number (820312-0133).\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['620821-1542', '820312-0133']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of an improvement, don't you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding words and names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The special character for numerical digits is `\\d`, as been described in the previous section. If we want to match on all characters that is _not_ numerical digits, we can use `\\D`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"86613298713900f8123010401\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo = re.search(p,text)\n",
    "mo.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to describe `\\D` is as the anti-`\\d` character!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we want just alphabetical letters, this isn't very convenient, since it will give us everthing that's not a digit. Take this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello World! How's it going? This is a string with a phone number (08-782 10 12), and its urgent!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H', 'e', 'l', 'l', 'o', ' ', 'W', 'o', 'r', 'l', 'd', '!', ' ', 'H', 'o']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)[:15] # showing first 15 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom character classes with square brackets `[]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we _only_ want letters, the `\\D` pattern also returns special characters such as blank space, exclamation marks etc etc, this is no good. There is however another way, we can specify that we want a set of characters, using the square brackets `[]`. We just place the characters we want returned within the brackets.\n",
    "\n",
    "Let's try to get all vowels in the text string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[eyuioa]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Not being an English native speaker, I didn't realise that \"y\" is both a vowel and not a vowel in the English language. Well, I'll just leave it in there since it is a vowel in my native tongue..)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'o', 'o', 'o', 'i', 'o', 'i', 'i', 'i', 'a', 'i', 'i', 'a', 'o', 'e']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using square brackets, we can also specify a span of alphabetical characters. All characters in the English language qould then be `[A-Z]` for upper casing, and `[a-z]` for lower. `[A-Za-z]` for both upper and lower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[A-Za-z]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the first 15 matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H', 'e', 'l', 'l', 'o', 'W', 'o', 'r', 'l', 'd', 'H', 'o', 'w', 's', 'i']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a span of characters also works with numerical digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[0-5]\" # matching 0, 1, 2, 3, 4, and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '2', '1', '0', '1', '2']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we want the entire words? Well we could just use the repition qualifier `+`, indicating we want all cases where the string is constructed of one or more of alphabetical letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[A-Za-z]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'World',\n",
       " 'How',\n",
       " 's',\n",
       " 'it',\n",
       " 'going',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'string',\n",
       " 'with',\n",
       " 'a',\n",
       " 'phone',\n",
       " 'number',\n",
       " 'and',\n",
       " 'its',\n",
       " 'urgent']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we specify match options within square brackets `[]`, we can also specify what _not_ to include using the `^` character. For example, `[^b]` will match all characters, except the lower cased letter \"b\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[^b]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"abc1&€\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'c', '1', '&', '€']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The \"word\" character `\\w`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to have all words together with all number digits? We COULD type `[A-Za-z0-9]`, but that's a bit overcomplicated. Luckilly, we can use the special character `\\w`. Here is the exact definition from the `re` module's [documentation](https://docs.python.org/3/library/re.html#regular-expression-syntax): \n",
    ">Matches [Unicode word characters](https://en.wikipedia.org/wiki/List_of_Unicode_characters); this includes most characters that can be part of a word in any language, as well as numbers and the underscore.\n",
    "\n",
    "(Blue link is not from source)\n",
    "\n",
    "Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\w+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'World',\n",
       " 'How',\n",
       " 's',\n",
       " 'it',\n",
       " 'going',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'string',\n",
       " 'with',\n",
       " 'a',\n",
       " 'phone',\n",
       " 'number',\n",
       " '08',\n",
       " '782',\n",
       " '10',\n",
       " '12',\n",
       " 'and',\n",
       " 'its',\n",
       " 'urgent']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a capital \"W\" – `\\W` – will match on all non-word letters in the text. It is the \"anti-word\" character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', '! ', \"'\", ' ', ' ', '? ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' (', '-']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"\\W+\"\n",
    "re.findall(p,text)[:15] # returns all spaces, quotations, exclamation marks etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The white space character `\\s`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we want to find words that is surrounded by loads of whitespace, but we're not sure what type of whitespace there is. The `\\s` character matches on all types of white space (newlines, tab spaces, blank space etc…):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n",
      "Here's two phone numbers:\n",
      "\t- 08-782 10 12\n",
      "\t- 0729-42 32 11\n",
      "That's all. Or, I think it is.\n",
      "It wasn't, there's also this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Hello World!\n",
    "Here's two phone numbers:\n",
    "\\t- 08-782 10 12\n",
    "\\t- 0729-42 32 11\n",
    "That's all. Or, I think it is.\n",
    "It wasn't, there's also this.\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', '\\n', ' ', ' ', ' ', '\\n', '\\t', ' ', ' ', ' ', '\\n', '\\t', ' ', ' ']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"\\s\"\n",
    "re.findall(p,text)[:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what if we wanted to **find a name** within a text? Most names start with a capital letter, followed by lower case ones. We can use norm and write a regex pattern based on it. Take this text string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is Johan Ekman, not Schmohan Schmekman!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[A-Z][a-z]+ [A-Z][a-z]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Johan Ekman', 'Schmohan Schmekman']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would actually get the same result if we used the special \"word\" character `\\w`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Johan Ekman', 'Schmohan Schmekman']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"[A-Z]\\w+ [A-Z]\\w+\"\n",
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also include the `\\s` character, to be sure to catch names that occur on shifting lines in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"My name is Johan Ekman, not Schmohan\n",
    "Schmekman!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Johan Ekman', 'Schmohan\\nSchmekman']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"[A-Z]\\w+\\s[A-Z]\\w+\"\n",
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatly, names are not always written with both first name and surname. Sometimes, as is often the case in news articles, there will just be a surname – like \"Mr. Ekman\". How to account for all such situations? And let's say we _only_ want surnames, how to proceed? We use regex groups! More on that in 2.5 below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise – matching phone numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, I want you to try to get all phone numbers in this list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../course_material/phone_list.txt\",\"r\")\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant, Phone number\n",
      "Boivie Jurgen, 0703-1901XX\n",
      "Bram,  Mats, 0707-2321XX\n",
      "Carlsson,  Lars, 0735-4474XX\n",
      "Christiansen,  Jan, 0730-2868XX\n",
      "Ekblom,  Torbjorn, 018-5115XX\n",
      "Ekstedt,  Stig, 0706-4084XX\n",
      "Englund,  Jan, 0703-6826XX\n",
      "Grine,  Mats, 0735-6226XX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swedish cellphone numbers always begin with \"07\". In the variabel `text`, how many numbers are cellphone numbers? Try to find using only regular expressions. The solution can be found in the solutions notebook. \n",
    "\n",
    "[A fantastic site to test regexes is regex101](https://regex101.com/). Just choose \"python\" in the left side menu and try out regular expressions on any text you want. You can use it to try regexes out and experiment with them.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take this string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is Johan Ekman. What's your name?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we only want to get the surnames in a given text. How do we then write our regex? We could search for all words that start with an upper cased letter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'Johan', 'Ekman', 'What']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"[A-Z][a-z]+\"\n",
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as you can see, this catches \"My\" and \"What\", as well as my first name. So that won't do. If we type the same pattern as the section above, we get both first names and surnames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Johan Ekman']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"[A-Z][a-z]+ [A-Z][a-z]+\"\n",
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly the way to go, since it returns the actual name. But if we _only_ want the surname? We can use regex groups! This is a way to separate certain parts of our regex pattern. Often, we want to write a longer expression to be able to match a specific text pattern, but we're only interested in a part of that text pattern – like a surname! \n",
    "\n",
    "Regex groups are specified with parenthesis `()`, enclosing the part we want to separate. So let's enclose the second \"word\" in our regex pattern, the surname:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[A-Z][a-z]+ ([A-Z][a-z]+)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, I won't use the `.findall()` method. We will use the `.search()` method and save the result to a match object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = re.search(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call the `.group()` method, giving it an integer as an argument, to get all the grouped part of our match object! The integer specifies which group we want returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ekman'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group(1) # returning group by passing the integer 1 to the method call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All match objects have, by default, at least one match group. That is even if we havn't specified any groups. The entire pattern's match is always the first group. If we pass 0 to the method call, we will always get the entire match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Johan Ekman'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually specify as many group as we'd like. Say we want both first names and surnames in different groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"([A-Z]([a-z]+)) ([A-Z][a-z]+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = re.search(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The groups are indexed in the order we type them into our expressions, from left to right. So our first group will be the first name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Johan'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, a part of the first name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ohan'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, the surname:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ekman'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as always, the default group (index 0), will be the entire match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Johan Ekman'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The groups are indexed after where each groups first bracket `(` is placed in the regex pattern!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use groups in our regex and then call the `.findall()` method, the findall method will automatically return all groups. So if we specify no group it will return all matches to the expression as a whole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[A-Z][a-z]+ [A-Z][a-z]+\" # no groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Johan Ekman sais hi to Jimmy Lewandowski\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Johan Ekman', 'Jimmy Lewandowski']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we specify one group, the method will only match on the specified group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"([A-Z][a-z]+) [A-Z][a-z]+\" # one group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Johan', 'Jimmy']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we specify two or more groups, all the groups we'd specified will be returned as a list of tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"([A-Z][a-z]+) ([A-Z][a-z]+)\" # two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Johan', 'Ekman'), ('Jimmy', 'Lewandowski')]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise – can you find the number?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will try to use your regex skills to find a number. The text is a transcript of a political rally that Donald Trump held earlier in 2020. At one point in his speach, President Trump talks about a specific number of \"refugees\". But how many exactly? \n",
    "\n",
    "_By only using regular expressions_, I want you to find how many refugees he mentions. The exact quote is \"[number] refugees\". So, a number - blank space - \"refugees\".\n",
    "\n",
    "Also, can you write your expression such as it would match any number of refugees (in accordance with the same number format used in the speach)?\n",
    "    \n",
    "Hints: the answer is not \"000\". Remember to use groups, and that the star character `*` signifies zero or more occurances of a pattern. Also, there are more than one solution to this exercise, be creative and try your best! \n",
    "\n",
    "Remember, you can use [the regex101 site](https://regex101.com/) to test how your regular expressions work. It's a great aid!\n",
    "    \n",
    "My solution is found in the solutions notebook. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the speach\n",
    "text = open(\"../course_material/speach.txt\",\"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you very much. Thank you. Thank you. What a crowd. Wow. Look at that, boy. What a crowd. Thank you. Thank you very much. Thank you. We just set a record in this building, folks, so that’s good n'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Escape Character `\\`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed a potential problem: If we're using parenthesis when grouping our expressions, how do we match literal parenthesis? \n",
    "\n",
    "If you recall section 3.2.3.2 in the basic course, there is a way in python to escape special characters in strings by using the escape character – the backslash `\\` (on a mac, you type the backslash by hitting <kbd>⇧ Shift</kbd>+<kbd>⌥ Option</kbd>+<kbd>7</kbd> on your keyboard). This works the same way in our regular expression. Since parenthesis have special meaning within a regex (specifying groups), we have to \"escape them\" using the backslash. Take this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My phone number is (08) 755 14 12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to match the area code of the phone number above. We'd need to include parenthesis in our regex. We can do this by escaping them in our expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\(\\d+\\)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We \"escape\" characters by typing the escape character just before the characters we want escaped. So `\\(` tells our computer \"this parenthesis isn't a grouping of our regex, it is an actual parenthesis character that I want you to look for\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(08)'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo = re.search(p,text)\n",
    "mo.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want our expression to exclude the parenthesis in the returned text, we can do so by grouping the digits wihtin our regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\((\\d+)\\)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo = re.search(p,text)\n",
    "mo.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(08)'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group(0) # returns entire match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is, of course, also possible on all the other special regex characters we learned about earlier, like the repition qualifiers `*`, `+` and `?`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\*\\+\\?\" # this matches the literal characters '*', '+' and '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"*+?\"\n",
    "mo = re.search(p, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*+?'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pipe Character `|`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to our examples of finding names in texts. \n",
    "\n",
    "Earlier, I mentioned the problem that names can sometimes be both first name and surname, and sometimes there will be some kind of formal pleasantry (like \"Ms\", \"Mrs\" or \"Mr\") in front of the surname. How do we write a regex that take these different possibilities into account?\n",
    "\n",
    "Regular expressions have a special character that signals to the computer that either of the expressions on its left and on its right are acceptable for matching. This character is called the pipe character: `|`. (On a mac, you type this character by hitting <kbd>⌥ Option</kbd>+<kbd>7</kbd> on your keyboard.)\n",
    "\n",
    "Before we try to match on surnames, let's try a more simple exampel. What if we'd like to match on directions, and want our expression to match on either \"north\", \"east\", \"south\", and \"west\", we could try this regular expression using `|`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"(north|east|south|west)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Take the road north 2 km, then when you see the red barn, turn east.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['north', 'east']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another classic example is if you want to match on Batman related stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"(bat(man|woman|mobile|copter|chopper))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"batman took the batmobile to his batcopter, since his batchopper was busted (thanks to batwoman)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batman', 'man'),\n",
       " ('batmobile', 'mobile'),\n",
       " ('batcopter', 'copter'),\n",
       " ('batchopper', 'chopper'),\n",
       " ('batwoman', 'woman')]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, back to our struggle to match on surnames. How can we then use the pipe character to help us get the surnames in this following text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello dear Mr Roberts! I don't know if you remember me. \\\n",
    "My name is Ms Hendricks. This is Johan Ekman.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find all names in this text! We will need to use groups as well. I will first show you the entire expression, then we'll go through it step by step together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"(Mr|Ms|[A-Z][a-z]+)\\s*([A-Z][a-z]+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr', 'Roberts'), ('Ms', 'Hendricks'), ('Johan', 'Ekman')]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the first group in the expression: `(Mr|Ms|[A-Z][a-z]+)`. Here, we tell the computer to first look for all occurances where there is either \"Mr\" or \"Ms\". OR a word that starts with a capitol letter – this is the `[A-Z][a-z]+` part. Any capitol letter in the range of \"A\" to \"Z\", followed by any letter in the range \"a\" to \"z\" that should occur at least once – as is indicated by the `+` special character. But it is the pipe character `|` that tells the computer that eithor of the three options are acceptable. Please also note that we group them all together, telling the computer that it is only the alternatives within the groups that should be considered while matching.\n",
    "\n",
    "Then there is the rest of the expression: `\\s*([A-Z][a-z]+)`. First, the `\\s*`: There may be either a blank space or a newline between the name, or the \"Mr\"/\"Ms\", and the surname. The `\\s` character catches both blank spaces and newlines. The star `*` just signals \"zero or more times\". Then, there is the surname: `([A-Z][a-z]+)`. \n",
    "\n",
    "That's it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise – who has landlines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll return to the list of phone numbers. Here, using regular expressions, I want you to find the persons that _doesn't_ have a cellphone number in the list. You're looking for the people that have a landline – that is a phone number that doesn't start with \"07…\". Who are they?\n",
    "\n",
    "You should know that all Swedish phone numbers start with a \"0\". No matter if it's a landline connection or a cellphone number. Also, for those of you who isn't familiar with Swedish naming conventions, the list has each persons surname first. So, in the name \"Bolsvik Jurgen\", \"Bolsvik\" is the surname :)\n",
    "\n",
    "Here's the phone number list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../course_material/phone_list.txt\",\"r\")\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant, Phone number\n",
      "Bolsvik Jurgen, 0703-1901XX\n",
      "Brumm,  Mats, 0707-2321XX\n",
      "Carlsson,  Yngve, 0735-4474XX\n",
      "Svensson,  Jan, 0730-2868XX\n",
      "Ekstrom,  Torbjorn, 018-5115XX\n",
      "Ekgren,  Stig, 0706-4084XX\n",
      "Engdahl,  Jan, 0703-6826XX\n",
      "Gripe,  Mats, 0735-6226XX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:249])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, remember that you can use [the regex101 website](https://regex101.com/) to help you out while learning. (I promise I don't get paid to repeat this, its just great while learning regular expressions)\n",
    "\n",
    "There are many ways to do this, but you will find my solution in the solutions notebook. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching in portions, or matching everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we want to just match a specific part of a string. Let's say you built a scraper that collects all names and phone numbers from a website. The scraper gives you a python list where each item is a string containing the information you want. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there's one problem! You're only interested in the name and the phone number. But inbetween, there is a small text where each person is presented. Here's an example of what a string value item in your list looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bear Grylls. Extremely interested in nature. Can climb really high (3,500 meters, at least) and can handle being thirsty. 555-421-4321'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Bear Grylls. Extremely interested in nature. \\\n",
    "Can climb really high (3,500 meters, at least) \\\n",
    "and can handle being thirsty. 555-421-4321\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presentation text is personal, so it varies considerably throughout the list. Therefore, it is very hard to accommodate in a regex.\n",
    "\n",
    "Luckily for us, there's a way to tell the computer so only check for our pattern in the beginning of each string, using the `^` sign. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match the start – use `^`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a regular expression begins with a caret sign `^`, it means that the pattern will only match on the beginning of a string. Take this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"^\\d+-\\d+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A phone number: 08-1234231.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces no hits, since the string _doesn't begin with numeric digits_. It will match this, however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"08-1234231 is a phone number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['08-1234231']"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we return to our example with the scraper. Since we know all strings begin with a name, we can use `^` to match with the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_p = \"^[A-Z][a-z]+\\s*[A-Z][a-z]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Bear Grylls. Extremely interested in nature. \\\n",
    "Can climb really high (3,500 meters, at least) \\\n",
    "and can handle being thirsty. 555-421-4321\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bear Grylls'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(name_p, text).group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The caret sign means that **the whole regex** will _only_ be applied to the beginning of the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match the end – use `$`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the dollar sign `$` to indicate that the regex pattern should be applied to the end of the string. Place the `$` at the end of your regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A phone number: 08-1234231\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\d+-\\d+$\" # dollar sign at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08-1234231'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(p, text).group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have everything we need to finish our little scraper. Let's create a pattern that catches the phone numbers at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_p = \"\\d+-\\d+-\\d+$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Bear Grylls. Extremely interested in nature. \\\n",
    "Can climb really high (3,500 meters, at least) \\\n",
    "and can handle being thirsty. 555-421-4321\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'555-421-4321'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(phone_p, text).group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refining our regex patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually make our scrapers regex's a bit more tidy. Maybe you noticed that the first part of our `phone_p`, the pattern `\\d+-`, was repeated? Have a look: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_p = \"\\d+-\\d+-\\d+$\" # '\\d+-' is typed twice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This duplication is unnecessary. Let's group `\\d+-` and place a `+` after it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_p = \"(\\d+-)+\\d+$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So instead of `\\d+-\\d+-`, we have type `(\\d+-)+`. This means that it will look for the pattern `(\\d+-)` _at least once_. Let's do the same refinement on the regex we made for finding the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_p = \"^([A-Z][a-z]+\\s*)+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, instead of typing `[A-Z][a-z]+` twice, we just put the first part of the expression in a group!\n",
    "\n",
    "Finally, let's put the regex patterns in a function which returns both the results at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_name_number(string):\n",
    "    phone_p = \"(\\d+-)+\\d+$\"\n",
    "    name_p = \"^([A-Z][a-z]+\\s*)+\"\n",
    "    \n",
    "    phone = re.search(phone_p,string).group()\n",
    "    name = re.search(name_p,string).group()\n",
    "    \n",
    "    # Typing return statements with more than one variable\n",
    "    # seperated by a comma returns the values as a tuple:\n",
    "    return name, phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Bear Grylls. Extremely interested in nature. \\\n",
    "Can climb really high (3,500 meters, at least) \\\n",
    "and can handle being thirsty. 555-421-4321\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Bear Grylls', '555-421-4321')"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_name_number(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! \n",
    "\n",
    "Let's return to the problem we started this section with. We had a list with string values as its items. Each string started with a name, and ended with a phone number. With the function `find_name_number()` we just created, we could call this function on each item in the list, and then save the result in a new list, containing _only_ name and phone number!\n",
    "\n",
    "Let's try it on our example text once more, but in a for-loop, so you can see what I mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_list = \"Bear Grylls. Extremely interested in nature. \\\n",
    "Can climb really high (3,500 meters, at least) \\\n",
    "and can handle being thirsty. 555-421-4321\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_list = [scraped_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scraped_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list now only contains one item. But imagine it includes hundreds of people. Let's create a list on which we can append our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we loop over `scraped_list`, and uses our function on every list item. The returned string values are appended to our `results` list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "for string in scraped_list:\n",
    "    # the function returns a tuple, which we save in this variable\n",
    "    items = find_name_number(string)\n",
    "    \n",
    "    # then, we append this tuple to our results-list:\n",
    "    results.append(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bear Grylls', '555-421-4321')]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, in this example, this is just a list with one single item. But hopefully, you can appreciate how powerful this code is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match (almost) everything – the wildcard `.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one rather important character class we havn't used yet – the dot `.` character. It matches all characters. Take this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"abc012!#)&€)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', '0', '1', '2', '!', '#', ')', '&', '€', ')']"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, more accuratly, it matches any character **except for the newline character `\\n`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"a\\n€\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', '€']"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot character is very handy since it is quite common with situations where we don't know which character that might occur. Take this following example:\n",
    "\n",
    "Let's say we have a string containing a presentation, and a list of phone numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = \"\"\"\n",
    "\n",
    "These phone numbers are all available if you need to find any member to talk to:\n",
    "\n",
    "555-321-1234,\n",
    "(555)543-9876,\n",
    "555 246 8763,\n",
    "555.082.0021,\n",
    "555-321 1234,\n",
    "555x222x9987\n",
    "\n",
    "Bla bla bla etc etc etc…\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annoyingly, the numbers come from costumers who write them down themselves. And they don't use the same pattern in how to write their number. As you can see, it's a mess. In this made up example, it is easy to see which characters we need to include in our regex, but imagine the list being thousands of rows. \n",
    "\n",
    "This is a great time to use the dot `.`! Take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"\\d+.\\d+.\\d+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['555-321-1234',\n",
       " '555)543-9876',\n",
       " '555 246 8763',\n",
       " '555.082.0021',\n",
       " '555-321 1234',\n",
       " '555x222x9987']"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After each on of the first two numerical characters `\\d+`, there is a dot `.`. This means that the regex will search for one or more digits, followed by one character that can be anything, followed by one or more digit, followed by one character that can be anything. Then, lastly, one or more digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching row by row with `.*`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's reuse the previous example of our phone list. Only this time, it turns out that it is an even worse list than we first thought. \n",
    "\n",
    "Apparently, the phone numbers are first written by hand, then they are read by a computer and automatically inserted in this text string. But this means that some characters are off. Some zeros have becomed O's instead, number 7 have in some instances become T's etc etc. Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = \"\"\"\n",
    "\n",
    "These phone numbers are all available if you need to find any member to talk to:\n",
    "\n",
    "5S5-321-l234,\n",
    "(555)543-9B76,\n",
    "555 24S 876E,\n",
    "S55.O8R.0O21,\n",
    "555-B21 123A,\n",
    "555x22Rx9987\n",
    "\n",
    "Bla bla bla etc etc etc…\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still want all phone numbers though. How do we do it? \n",
    "\n",
    "In the previous section, I described how the wildcard dot character `.` matches every character. _Every character but newline._ This means that if we use the dot together with a star – `.*` – it will match any character (but newline) zero or more times. \n",
    "\n",
    "This, in effect, means \"match all rows\". Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \".*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " 'These phone numbers are all available if you need to find any member to talk to:',\n",
       " '',\n",
       " '',\n",
       " '5S5-321-l234,',\n",
       " '',\n",
       " '(555)543-9B76,',\n",
       " '']"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, numbers)[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All numbers begin with fives, but some have changed into the letter \"S\". But we can still match on these opening fives and S's. Then, we can use the dot star `.*`, which means \"give us the rest of this text row\". Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"[5S]+.*\" # '5' or 'S' once or more, followed by whatever – until newline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5S5-321-l234,',\n",
       " '555)543-9B76,',\n",
       " '555 24S 876E,',\n",
       " 'S55.O8R.0O21,',\n",
       " '555-B21 123A,',\n",
       " '555x22Rx9987']"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pattern can also be used to tell the computer: \"give me everything between these two patterns\". Have a look at this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"phone numbers: 0704- 123 45 67, 08-123 45 12, 013-32 42 11. names: Johan, Kate, Hanna, Fredrick, Carl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we _only_ want the phone numbers, but can't be bothered to type a regex that cataches all of them. A lazy way to do it is to use dot star:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"phone numbers:(.*)names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 0704- 123 45 67, 08-123 45 12, 013-32 42 11. '"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(p, text).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Optional) Greedy `.*`, non-greedy `.*?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reuse the example in the previous section. But this time, we also have surnames in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"phone numbers: 0704- 123 45 67, 08-123 45 12, 013-32 42 11. \\\n",
    "names: Johan, Kate, Hanna, Fredrick, Carl. surnames: Ekman, Smith, Svenson, Carlsson, Brandt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what happens then with our regex?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"phone numbers:(.*)names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 0704- 123 45 67, 08-123 45 12, 013-32 42 11. names: Johan, Kate, Hanna, Fredrick, Carl. sur'"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(p, text).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot star character pattern is **greedy**. It will read through the entire string, first it will find the \"phone numbers:\" part of the string. Then, it will look for the \"names\" part. But it will look for the _last time that this occurs in the string_. It won't stop at the first \"names\" it finds. If there's another match, it will grab everything up to that one last match. It is _greedy_ – it takes all it can! \n",
    "\n",
    "In the example above, it first finds the \"names\" that preceds the first names. But then it finds the \"names\" part in \"surnames\", so it ignores the first string \"names\". Therefore, it returns everthing between \"phone numbers:\" and \"surnames\".\n",
    "\n",
    "To stop this behaviour, and to make the dot star **non-greedy**, we can add a question mark: `.*?`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"phone numbers:(.*?)names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 0704- 123 45 67, 08-123 45 12, 013-32 42 11. '"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(p, text).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A non-greedy dot star will stop at the first occurance of the pattern following `.*?` provided in the regex. In our example, this means it stops at the first \"names\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags are a way to adapt your regular expressions to specific circumstances. Here's two examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `re.DOTALL`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reuse the text from the last section, but this time, let's say that the text includes newlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "phone numbers:\n",
    "0704- 123 45 67,\n",
    "08-123 45 12,\n",
    "013-32 42 11,\n",
    "names: \n",
    "Johan,\n",
    "Kate,\n",
    "Hanna,\n",
    "Fredrick,\n",
    "Carl\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nphone numbers:\\n0704- 123 45 67,\\n08-123 45 12,\\n013-32 42 11,\\nnames: \\nJohan,\\nKate,\\nHanna,\\nFredrick,\\nCarl\\n'"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dot `.` matches everything _except newline_, this poses a problem for us if we want to use dot star:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"phone numbers:(.*)names:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-398-f986b7a050b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "re.search(p, text).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is because the regex matches \"phone numbers:\" and then looks for \"names:\". But since it immediatly finds sees a newline, it doesn't match.\n",
    "\n",
    "Fortunatly, there is a way to make dot star also match newlines. We can use a flag: `re.DOTALL`. We just pass this as a third argument to the search method, and it will now let dots also match newlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = re.search(p, text, re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0704- 123 45 67,\n",
      "08-123 45 12,\n",
      "013-32 42 11,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mo.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex flags** are maybe best described as \"settings\" to our regular expressions. There are a handful of them, and I won't cover them all here. But you can find them all [here, in the re module's documentation](https://docs.python.org/3/library/re.html#re.A).\n",
    "\n",
    "Here's one more example of a flag:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) `re.IGNORECASE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This flag simply tells the interpreter to ignore upper and lower casings of letters when looking for our regular expression. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"JoHaN EkMaN \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"(([a-z]+ )+)\" # looks for the a group of the letter range 'a' to 'z' together with blank space, at least once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't find any match since the text example is a mix of upper and lower cased letters. The regular expression is just looking for a letter range 'a' to 'z' in lower letters. To be sure it will match anyways, we can use the flag `re.IGNORECASE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JoHaN EkMaN ', 'EkMaN ')]"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(p, text, re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project – The Invoices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, you will be doing a project. Below, there is code that will create thousands of PDF files in a folder called \"project\" in the current working directory. The files are (made up) invoices to a public agency. \n",
    "\n",
    "It is your job, using python code, to go through all the files and gather some specific information:\n",
    "\n",
    "- The total cost if you sum up all the invoices' charges\n",
    "- There are dates on the invoices – find the total yearly cost of all the invoices\n",
    "- There are people's names and (Swedish) social security numbers on the invoices – looking through all invoices, who has charged the agency the most? Do any employee or employees stand out? They should have around the same charged amount\n",
    "\n",
    "Bonus: there is a text file in the 'course_material' folder, called 'employees.txt'. Within it there are a long list of social security numbers of people working at the agency. We also want to see if there's any foul play. **Are there any employed people charging the agency in the invoices?** If there are, this is a clear violation of the agency's policy – perhaps even corruption! You are tasked to go through all the invoices and see if any of the contacs within match with the employees in the 'employees.txt' list.\n",
    "\n",
    "This project will test your overall python skills. Just use what you've learned throughout the basic and the continuation course. But also, google things when you feel stuck! There are thousands and thousands of questions and answers that might be of help at [stackoverflow.com](https://stackoverflow.com/questions). \n",
    "\n",
    "I also encourage you to try things that _hasn't been in the course yet_. Look into modules that you suspect might be helpful. Check their documentation. This is a routine that is great to put in practice early on!\n",
    "\n",
    "My solution to this project can be found in the solutions notebook. It is a solution that doesn't introduce any new concepts other than has been covered so far in this course. \n",
    "\n",
    "However, I strongly encourage you to try by yourself first! Check out my solution if you get stuck :)\n",
    "\n",
    "Good luck!\n",
    "\n",
    "**IMPORTANT!!**\n",
    "\n",
    "You will need the third party module `reportlab` to be able to generate the files needed to do this exercise. If you've installed Anaconda as was recommended, uncomment and run the following code cell to install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c anaconda reportlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(If you haven't installed Anaconda as was recommended, install `reportlab` in such a way that you can use the module in this notebook)_\n",
    "\n",
    "**Now, run this following code cell.** It generates 5000 pdf files, taking up 20 MB storage on your hard drive. The code will take less than a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file no 5000 of 5000 files...\n",
      "All files generated without failure! Success!\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import locale\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from random import randint, seed\n",
    "from pathlib import Path\n",
    "\n",
    "from reportlab.pdfgen.canvas import Canvas\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.units import cm\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "seed(100)\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "\n",
    "def random_datetimes_or_dates(start, end, n=None):\n",
    "    np.random.seed(100)\n",
    "    (divide_by, unit) = (24*60*60*10**9, 'D')\n",
    "\n",
    "    start_u = start.value // divide_by\n",
    "    end_u = end.value // divide_by\n",
    "    if not n:\n",
    "        n = (end - start).value // divide_by\n",
    "\n",
    "    return pd.to_datetime(np.random.randint(start_u,\n",
    "                                            end_u, n),\n",
    "                          unit=unit).astype('str')\n",
    "\n",
    "def create_dranges(start, end, n=None):\n",
    "    start = pd.to_datetime(start)\n",
    "    end = pd.to_datetime(end)\n",
    "    return random_datetimes_or_dates(start,end,n)\n",
    "\n",
    "def last_four_digits(person):\n",
    "    digits = f\"{randint(0,9)}\"\n",
    "\n",
    "def create_birthdates(number):\n",
    "    dranges = create_dranges(\"1951-01-01\",\"1995-12-31\")\n",
    "    \n",
    "    np.random.seed(100)\n",
    "    dranges = pd.Series(dranges[np.random.randint(1,len(dranges),number)])\n",
    "    return dranges.apply(lambda x: x[2:]).str.replace('-','')\n",
    "\n",
    "def last_four(num=100):\n",
    "    np.random.seed(100)\n",
    "    nums = pd.Series(np.random.randint(0,999,num).astype('str'))\n",
    "    nums = nums.apply(lambda x: '00' + x if len(x) < 2 else x)\n",
    "    nums = nums.apply(lambda x: '0' + x if len(x) == 2 else x)\n",
    "    return nums\n",
    "\n",
    "def last_digit(num=100):\n",
    "    seed(100)\n",
    "    even = [random.randrange(2, 9, 2) for _ in range(int(num/2))]\n",
    "    odd = [random.randrange(1, 10, 2) for _ in range(int(num/2))]\n",
    "    return even + odd\n",
    "\n",
    "def soc_sec_nums(num=100):\n",
    "    dates = create_birthdates(num)\n",
    "    last_digits = last_four()\n",
    "    soc_nums = []\n",
    "    for count,date in enumerate(dates):\n",
    "        soc_nums.append(f\"{date}-{last_digits[count]}\")\n",
    "    return soc_nums\n",
    "\n",
    "def pass_item(items):\n",
    "    for item in items:\n",
    "        yield item\n",
    "\n",
    "def build_people():\n",
    "    np.random.seed(100)\n",
    "    \n",
    "    with open(\"../course_material/scb.json\",\"r\") as f:\n",
    "        names = json.load(f)\n",
    "    \n",
    "    first_names = names[\"men\"]+names[\"women\"]\n",
    "    snames = names[\"surnames\"]\n",
    "    \n",
    "    idx_sname = pass_item(np.random.randint(0,100,100))\n",
    "    idx_mname = pass_item(np.random.randint(0,50,50))\n",
    "    idx_fname = pass_item(np.random.randint(50,100,50))\n",
    "    \n",
    "    soc_nums = soc_sec_nums()\n",
    "    last_num = pass_item(last_digit())\n",
    "    all_names = []\n",
    "    for count,name in enumerate(first_names):\n",
    "        item = {}\n",
    "        item['soc_num'] = soc_nums[count] + str(next(last_num))\n",
    "        if count < 50:\n",
    "            item['sex'] = \"m\" \n",
    "            item['name'] = (f\"{first_names[next(idx_mname)]} \\\n",
    "{snames[next(idx_sname)]}\")\n",
    "        else:\n",
    "            item['sex'] = \"f\"\n",
    "            item['name'] = (f\"{first_names[next(idx_fname)]} \\\n",
    "{snames[next(idx_sname)]}\")\n",
    "        all_names.append(item)\n",
    "    return all_names\n",
    "\n",
    "def invoice_sums(n):\n",
    "    np.random.seed(100)\n",
    "    return np.random.randint(200,200_000,n).astype(str)\n",
    "\n",
    "def generate_invoice_info(num_invoices=5000):\n",
    "    \n",
    "    info = {}\n",
    "    \n",
    "    # TODO – generate invoice dates\n",
    "    dates = create_dranges(\"2016-01-01\",\"2020-02-01\",num_invoices)\n",
    "    info[\"dates\"] = [f\"\\t\\t\\t\\tInvoice date: {x}\" for x in dates]\n",
    "\n",
    "    # TODO – generate invoice sums\n",
    "    charges = invoice_sums(num_invoices)\n",
    "    info[\"sums\"] = [f\"Total expenditure:\\t\\tSEK {int(x):n}\" for x in charges]\n",
    "\n",
    "    # Invoice contact\n",
    "    names = build_people()\n",
    "    info[\"names\"] = [f\"Our contact:\\t\\t\\t{x['name']} ({x['soc_num']})\" for x in names]\n",
    "    \n",
    "    return info\n",
    "\n",
    "def generate_invoice_text(date, charge, name):\n",
    "    text = f\"\"\"\n",
    "{date}\n",
    "\n",
    "Invoice for services in accordance with #T542AA1, Chap 3\n",
    "--------------------------------------------------------\n",
    "\n",
    "\n",
    "{exp}\n",
    "\n",
    "------\n",
    "{name}\n",
    "\n",
    "\"\"\"\n",
    "    # newline in pdf line breaks\n",
    "    return text.replace(\"\\n\", \"<br />\")\n",
    "\n",
    "np.random.seed(100)\n",
    "# number of generated invoices\n",
    "invoice_number = 5000\n",
    "\n",
    "# generate invoice content\n",
    "data = generate_invoice_info(invoice_number)\n",
    "\n",
    "# this list of ints is to seed invoice names \n",
    "contacts = np.random.randint(0,len(data['names']),invoice_number)\n",
    "\n",
    "end = datetime.datetime.strptime('2020-02-01',\"%Y-%m-%d\")\n",
    "start = end - datetime.timedelta(invoice_number-1)\n",
    "\n",
    "# file name generator (based on dates)\n",
    "filenames = pass_item(pd.date_range(start,end))\n",
    "\n",
    "path = Path(\"project\")\n",
    "# if no directory, create one\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "for count,date in enumerate(data['dates']):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Writing file no {count+1} of 5000 files...\")\n",
    "    \n",
    "    exp = data[\"sums\"][count]\n",
    "    name = data[\"names\"][contacts[count]]\n",
    "    \n",
    "    # pdf name generator\n",
    "    fname = int(next(filenames).value) // 10**9\n",
    "    \n",
    "    # pdf layout\n",
    "    doc = SimpleDocTemplate(f\"{path.name}/{fname}.pdf\",pagesize=A4,\n",
    "                        rightMargin=2*cm,leftMargin=2*cm,\n",
    "                        topMargin=2*cm,bottomMargin=2*cm)\n",
    "    \n",
    "    if contacts[count] in [12,32,41,73]:\n",
    "        # this statement decides corrupt invoices' sums\n",
    "        if contacts[count] == 32:\n",
    "            multipl = 10\n",
    "        else:\n",
    "            multipl = 3\n",
    "        num = re.search(\"(\\d+,)*\\d+\", exp).group()\n",
    "        num = int(num.replace(\",\",\"\")) * multipl\n",
    "        exp = re.sub(\"(\\d+,)*\\d+\", f\"{num:n}\", exp)\n",
    "    \n",
    "    text = generate_invoice_text(date, exp, name)\n",
    "    \n",
    "    # build pdf\n",
    "    doc.build([Paragraph(text, getSampleStyleSheet()['Normal']),])\n",
    "    \n",
    "print(\"All files generated without failure! Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we're going to cover the basics of web scraping. We will not go through more advanced web scraping techniques, such as using Selenium. Here, we will learn how to access web pages' element trees and scrape information of it. \n",
    "\n",
    "You should know, such scraping has some prerequistes. In the introduction, I will briefly show how to research a web page's element tree, and introduce some basic concepts. There are also some helpful links to get you some more background. Just reading through these links will help you a lot. If you're completely new to these subjects, I recommend having the links open in other tabs in your web browser to be referenced as you read through this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Website's foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All web pages you frequent are the result of code. There is what's called **the frontend** of web pages. This is the visual representation of a website and is (usually) the results of three code languages. Here's a very (very) basic and rough explination:\n",
    "\n",
    "***\n",
    "**The website's building blocks – HTML**\n",
    "\n",
    "The basic building blocks of a web page is created in Hyper Text Markup Language, or HTML. It defines what \"blocks\" of content that should exist on the webpage. These blocks are called HTML-elements.\n",
    "***\n",
    "\n",
    "**The website's style and estetic – CSS**\n",
    "\n",
    "Using CSS code, websites target the html elements and changes their look and how they are ordered in relation to one another. For example, HTML code can create three text paragraphs. CSS can style them by having the same font, and organise them by ordering them horizontally instead of below one another.\n",
    "***\n",
    "\n",
    "**The website's logic – JavaScript**\n",
    "\n",
    "Modern websites's content isn't static. They often change appearance, have content move as you scroll, or have content that isn't available in some circumstances. They are dynamic. And this dynamic usually depend on some kind of logic.\n",
    "***\n",
    "\n",
    "A very basic example is when you click a link to content not appropriate for children. A textbox usually appear asking you to put in your date of birth. If you're above a certain age, the webpage will let you access its content. If not, you'll be told you're too young to access the webpage. This is a logic that (probably) is built with JavaScript. JavaScript is a programming language that developers use to apply logic to websites.\n",
    "\n",
    "_(There's also **the backend** of websites. This is the logic built to get the correct data to you as a user. Usually this is written in a programming language such as PHP)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a website's html code: this wikipedia page with [all olympic medals of all time](https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table). We can do this by right clicking anywhere on the website and choosing \"Inspect\" (Google Chrome) or \"Inspect element\" (Firefox) in the dropdown menu that appears. [Here's a guide on how to do this on various web browsers.](https://www.lifewire.com/get-inspect-element-tool-for-browser-756549) Right click on the text paragraph up top on the article and choose \"Inspect Element\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../course_material/scraping/inspect_1.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will then open **the developer tools window**. If you've never seen this window before, it may come across as the controls of a space shuttle. But don't fret! It isn't that complicated, at least the stuff we're interested in. \n",
    "\n",
    "In the developer tools window, if you're in Google Chrome, open the \"Elements\" tab, or \"Inspector\" if you're using Firefox. In the guide linked above, you can see what it's called in various browsers. The first arrow (1) points to the elements inspector tab:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../course_material/scraping/inspect_2.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second arrow (2) points to various html-elements that exists on the webpage. The one marked in blue is the element that was right clicked on (the visuals varies across different browsers, but the functionality is basically the same). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you scroll through the list, you can see the entire page's structure. There are small grey arrow heads to the left of most of the elements. This indicates a tree of objects. If you click an arrow, it will unfold the tree, and you can see all elements beneath the one you clicked: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../course_material/scraping/inspect_4.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, pressing the arrow to the left of the paragraph element `<p>` (1). A tree of html-elements beneath that paragraph then unfolded (2). Unfolding the tree shows us all elements beneath the paragraph (3). These elements beneath are the **child elements**, they are **the children** of the paragraph element `<p>`. Likewise, `<p>` is **the parent element** of the elements directly beneath it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, you will learn how to use Python to scrape the data that are attached to these html-elements. But first, let's learn how to download files from the internet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `requests` module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! So let's start with a very simple way to use code and access a web page's content. One of the most basic interactions you can do with a web page is download a file. The module `requests` is perfect for this – it makes it easy to quickly access a web page's content. Let's start with accessing a plaintext file.\n",
    "\n",
    "[On this page](http://www.textfiles.com/etext/FICTION/), we can download hundreds of classical books in plaintext format! Let's have a look at Jules Verne's book [_Around the World in 80 Days_](http://www.textfiles.com/etext/FICTION/80day10.txt). But first, we will import the `requests` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The response object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plaintext file is at this url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.textfiles.com/etext/FICTION/80day10.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to scrape the contents of the url, we need to create a response object. Why is it called \"response\"? Well, each time you access a web page through a browser, the browser calls the web page's server – it sends _a request_ – asking for content. The server then _responds_ to your browser's request, and provides content.\n",
    "\n",
    "When we use the `requests` module, we bypass the intermediary web browser by using the method `.get()`. This method sends a request directly to the server. If the url exists, it returns a response object, which we'll save into a variable. Let's name it `res`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affirming the response object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a response object, we can use the `.raise_for_status()` method. This method raises an exception if the url you passed the `.get()` method doesn't work. If there is no issue with the url, `.raise_for_status()` will return `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, no issues with the url. But if we give it a url that doesn't exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(\"http://www.textfiles.com/etext/FICTION/aölasöd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: http://www.textfiles.com/etext/FICTION/a%C3%B6las%C3%B6d",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cd6be6b74546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/learning_python-GVvhfwh6/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: http://www.textfiles.com/etext/FICTION/a%C3%B6las%C3%B6d"
     ]
    }
   ],
   "source": [
    "res.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is common practice to always type this code so that you're sure that the code connected with the url successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "res.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing content – the binary string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response object has an attribute called `content`. This is the entire web page's content retrieved as a binary string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Around the World in 80 Days, by Jules Verne\\r\\n\\r\\n\\r\\nAROUND THE WORLD IN EIGHTY DAYS\\r\\n\\r\\nChapter I\\r\\n\\r\\nIN WHICH PHILEAS FOGG AND PASSEPARTOUT ACCEPT EACH OTHER,\\r\\nTHE ONE AS MASTER, THE OTHER AS MAN\\r\\n\\r\\n\\r\\nMr.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We havn't covered binary strings so far in the course, and I won't cover it now in great detail. Binary strings are text strings of plain binary data. You can always create your own by typing a lower cased \"b\" in front of a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'This is a string'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b\"This is a string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b\"This is a string\" == \"This is a string\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decode binary strings to ordinary strings using the `.decode()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_string = b\"This is a string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a string'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_string.decode(\"utf-8\") # here we converting to unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding of strings is not part of this course. But it is _how to convert text to binary data, or vice versa._ There are hundreds of encodings that helps our computers to transform different languages characters into binary code. The first, and (perhaps) most famous being ASCII, or `\"ascii\"` as an encoding argument in Python. If you're interested in more, [read this!](https://realpython.com/python-encodings-guide/#enter-unicode) In fact, that whole article is great for understanding more about this subject.\n",
    "\n",
    "Here, we'll just go with the unicode encoding argument \"urf-8\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might all seem a bit confusing. But just know that there are something called binary strings. They are usually used when computers need to convert text data from one computer language to another. Such as when we want content from a server on the web returned to us as a string we can use in Python.\n",
    "\n",
    "Let's save the site's content to a variable and decode it into a normal string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = content.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375033"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading a plaintext file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve the text file again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.textfiles.com/etext/FICTION/80day10.txt\"\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "content = res.content.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and check the content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around the World in 80 Days, by Jules Verne\r\n",
      "\r\n",
      "\r\n",
      "AROUND THE WORLD IN EIGHTY DAYS\r\n",
      "\r\n",
      "Chapter I\r\n",
      "\r\n",
      "IN WHICH PHILEAS FOGG AND PASSEPARTOUT ACCEPT EACH OTHER,\r\n",
      "THE ONE AS MASTER, THE OTHER AS MAN\r\n",
      "\r\n",
      "\r\n",
      "Mr. Phileas Fogg lived, in 1872, at No. 7, Saville Row, Burlington\r\n",
      "Gardens, the house in which Sheridan died in 1814.  He was one of\r\n",
      "the most noticeable members of the Reform Club, though he seemed\r\n",
      "always to avoid attracting attention; an enigmatical personage,\r\n",
      "about whom little was known, except that he was a polished man\r\n",
      "of the world.\n"
     ]
    }
   ],
   "source": [
    "print(content[:540])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the content is simply a plaintext file. No more. It actually sais so in the url we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.textfiles.com/etext/FICTION/80day10.txt'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"http://www.textfiles.com/etext/FICTION/80day10.txt\" # .txt :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that there are no other content than the file's content in our response object. Let's try another page to show you what I mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<HTML>\\n<BODY BGCOLOR=\"#000000\" TEXT=\"#FFFFFF\" LINK=\"#FFFFFF\" ALINK=\"#FFFFFF\"\\n      VLINK=\"#FFFFFF\">\\n\\n<CENTER>\\n<IMG SRC=\"images/etext.jpg\"><P>\\n<P>\\n<TABLE WIDTH=90%>\\n<TR>\\n<TD WIDTH=50% VALIGN=TOP>\\n<BLOCKQUOTE>\\n<FONT SIZE=+1><B><A STYLE=\"text-decoration'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"http://www.textfiles.com/etext/\").content[:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the requests `.get()` method retrieves all content on a site, it usually returns the web page's html tree, with all its html-elements. But since this is a plaintextfile, we dont't have to bother with that. We can straight away download the contents to a file on our hard drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"around_the_world_in_80_days.txt\", \"w\")\n",
    "file.write(content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the `open()` function has the argument \"wb\" – \"write binary\" – we don't need to convert the binary string to a normal string. We can just write the file straight from the response object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"around_the_world_in_80_days.txt\", \"wb\")\n",
    "file.write(res.content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the same :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we decoded the content into a normal Python text string, we can use regular expressions and explore the text! For example, how many times does the name \"Phileas Fogg\" occur in the book? Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"Phileas Fogg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(pattern, content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about just his surname \"Fogg\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"Fogg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(pattern, content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh! So way more. My guess is that, since it is an old book, his name is usually written together with \"Mr\". Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"Mr\\.* Fogg\" # searching for a literal dot '.' here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(pattern, content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems about right. What is the word that usually preceds \"Fogg\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"(\\w+)\\W*\\s*Fogg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "preceding_word = re.findall(pattern, content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `set()` function to get all unique values in a list. Let's check out all words that preceds \"Fogg\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Captain',\n",
       " 'Kong',\n",
       " 'Monsieur',\n",
       " 'Mr',\n",
       " 'Phileas',\n",
       " 'The',\n",
       " 'and',\n",
       " 'arrest',\n",
       " 'courageous',\n",
       " 'crew',\n",
       " 'face',\n",
       " 'had',\n",
       " 'her',\n",
       " 'if',\n",
       " 'intractable',\n",
       " 'joy',\n",
       " 'letting',\n",
       " 'lose',\n",
       " 'not',\n",
       " 'of',\n",
       " 'pursuing',\n",
       " 'retorted',\n",
       " 'safety',\n",
       " 'said',\n",
       " 'that',\n",
       " 'the',\n",
       " 'to',\n",
       " 'tranquil',\n",
       " 'under'}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(preceding_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun to explore, even though it is pretty useless information :)\n",
    "\n",
    "But hopefully, you now feel a bit introduced on how to scrape text files from the internet and then exploring their content using code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this and run if you want to delete the text file:\n",
    "#from pathlib import Path\n",
    "#Path(\"around_the_world_in_80_days.txt\").unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and working with csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! Downloading litterature is all fine and dandy. But what about downloading data files? Here, I will show you how to use the requests library to obtain two such types of files – the json and the csv.\n",
    "\n",
    "Let's start with **the csv file**. \"csv\" stands for \"comma separated values\". It is essentially files with rows and columns of data, where each row is separated by a newline character `\\n`, and each column by a comma `,`. Here's a url to a csv file with of covid data from Johns Hopkins University:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/10-29-2020.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's get it using the requests library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'FIPS,Admin2,Province_State,Country_Region,Last_Update,Lat,Long_,Confirmed,Deaths,Recovered,Active,Combined_Key,Incidence_Rate,Case-Fatality_Ratio\\n,,,Afghanistan,2020-10-30 04:24:49,33.93911,67.709953,41268,1532,34239,5497,Afghanistan,106.01016878679728,3.7123194727149365\\n,,,Albania,2020-10-30 04:24:49,41.1533,20.1683,20315,499,11007,8809,Albania,705.9211897977623,2.4563130691607187\\n,,,Algeria,2020-10-30 04:24:49,28.0339,1.6596,57332,1949,39635,15748,Algeria,130.74261426347374,3.399497662736343\\n,'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556837"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we now have all data in i gigantic binary string. Let's save it into a csv-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open(\"covid_data.csv\",\"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556837"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.write(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the `csv` module to parse the data! Let's import the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv module has the method `.reader()` that takes a csv file object as an argument. The method then parses the data into rows, where each row is a list of string elements found in the data file. The result is returned as a new \"reader\" object. Let me show you what I mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = open(\"covid_data.csv\",\"r\")\n",
    "csv_reader = csv.reader(csv_file,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_csv.reader at 0x1304a3120>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reader object contains all rows in the csv file. The first row is the header with the column names, the rest is the rows of data. To have all the rows returned, we can use the `list()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['FIPS',\n",
       "  'Admin2',\n",
       "  'Province_State',\n",
       "  'Country_Region',\n",
       "  'Last_Update',\n",
       "  'Lat',\n",
       "  'Long_',\n",
       "  'Confirmed',\n",
       "  'Deaths',\n",
       "  'Recovered',\n",
       "  'Active',\n",
       "  'Combined_Key',\n",
       "  'Incidence_Rate',\n",
       "  'Case-Fatality_Ratio'],\n",
       " ['',\n",
       "  '',\n",
       "  '',\n",
       "  'Afghanistan',\n",
       "  '2020-10-30 04:24:49',\n",
       "  '33.93911',\n",
       "  '67.709953',\n",
       "  '41268',\n",
       "  '1532',\n",
       "  '34239',\n",
       "  '5497',\n",
       "  'Afghanistan',\n",
       "  '106.01016878679728',\n",
       "  '3.7123194727149365']]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(csv_reader)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Optional) Exploring and converting csv data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, how do we transform this data into a data structure we can explore? Well, we could convert it to a unicode encoded string value, and then use string methods to create a data structure we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/10-29-2020.csv\"\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.content.decode('utf-8') # converting data into python string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we don't have the data saved to a csv file, and want the csv module to read the data straight from our response's content, we need to split the string on all newlines. Otherwise, it will confuse what's what in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.split(\"\\n\")\n",
    "csv_reader = csv.reader(data, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(csv_reader) # converting the reader object to a list with all rows as items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first item in the list seem to be the header. Let's save it to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FIPS',\n",
       " 'Admin2',\n",
       " 'Province_State',\n",
       " 'Country_Region',\n",
       " 'Last_Update',\n",
       " 'Lat',\n",
       " 'Long_',\n",
       " 'Confirmed',\n",
       " 'Deaths',\n",
       " 'Recovered',\n",
       " 'Active',\n",
       " 'Combined_Key',\n",
       " 'Incidence_Rate',\n",
       " 'Case-Fatality_Ratio']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header # This is all column names in the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, loop over all rows and match each row of data with our header to then pair with row values. We'll save these as dictionaries and then append them to a `results` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [] # place holder to fill with row data\n",
    "\n",
    "# skipping first item in the list, since that's the \"header\":\n",
    "for row in data[1:]:\n",
    "    row_dict = dict(zip(header, row)) # Connect each row's data with the header as keys\n",
    "    results.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FIPS': '',\n",
       " 'Admin2': '',\n",
       " 'Province_State': '',\n",
       " 'Country_Region': 'Afghanistan',\n",
       " 'Last_Update': '2020-10-30 04:24:49',\n",
       " 'Lat': '33.93911',\n",
       " 'Long_': '67.709953',\n",
       " 'Confirmed': '41268',\n",
       " 'Deaths': '1532',\n",
       " 'Recovered': '34239',\n",
       " 'Active': '5497',\n",
       " 'Combined_Key': 'Afghanistan',\n",
       " 'Incidence_Rate': '106.01016878679728',\n",
       " 'Case-Fatality_Ratio': '3.7123194727149365'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to recap what we just did:\n",
    "\n",
    "1. converted the response object's content into a string\n",
    "2. splited the string on all newline `\\n` characters to get a list of all rows of data\n",
    "3. in a loop, we splited each row on all commas in the to get each row's columns\n",
    "\n",
    "Lastly, we created a zip object by passing the header data and the sequence's data to the `zip()` function, then passed the zip object to the `dict()` function, creating a dictonary. Let's do on its own so you can see exactly what's happend, we start with the `header` variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is one tidy data structure! I havn't introduced you to the `pandas` module yet, but I will now show you how to use pandas to save the data as a excel file. First import pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(It is common practice to import pandas as a synonym `pd`, the reason being that there are so many methods used from the module while working with it, that it is more readable to use the short `pd`)_\n",
    "\n",
    "`pandas` transforms data into `series` objects. They are basically lists. If we have more than one series organised together, this is called a pandas dataframe. To create a dataframe object, we use the `DataFrame` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.DataFrame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing our data structure to the dataframe class will create a new dataframe object. Let's do so and then save it to a variable called `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datframes have the `.head()` method that shows us the first 5 rows in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Incidence_Rate</th>\n",
       "      <th>Case-Fatality_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-10-30 04:24:49</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>41268</td>\n",
       "      <td>1532</td>\n",
       "      <td>34239</td>\n",
       "      <td>5497</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>106.01016878679728</td>\n",
       "      <td>3.7123194727149365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Albania</td>\n",
       "      <td>2020-10-30 04:24:49</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>20315</td>\n",
       "      <td>499</td>\n",
       "      <td>11007</td>\n",
       "      <td>8809</td>\n",
       "      <td>Albania</td>\n",
       "      <td>705.9211897977623</td>\n",
       "      <td>2.4563130691607187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Algeria</td>\n",
       "      <td>2020-10-30 04:24:49</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>57332</td>\n",
       "      <td>1949</td>\n",
       "      <td>39635</td>\n",
       "      <td>15748</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>130.74261426347374</td>\n",
       "      <td>3.399497662736343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2020-10-30 04:24:49</td>\n",
       "      <td>42.5063</td>\n",
       "      <td>1.5218</td>\n",
       "      <td>4567</td>\n",
       "      <td>73</td>\n",
       "      <td>3260</td>\n",
       "      <td>1234</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>5910.8263767553235</td>\n",
       "      <td>1.5984234727392161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Angola</td>\n",
       "      <td>2020-10-30 04:24:49</td>\n",
       "      <td>-11.2027</td>\n",
       "      <td>17.8739</td>\n",
       "      <td>10269</td>\n",
       "      <td>275</td>\n",
       "      <td>3736</td>\n",
       "      <td>6258</td>\n",
       "      <td>Angola</td>\n",
       "      <td>31.244800900424714</td>\n",
       "      <td>2.677962800662187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FIPS Admin2 Province_State Country_Region          Last_Update       Lat  \\\n",
       "0                               Afghanistan  2020-10-30 04:24:49  33.93911   \n",
       "1                                   Albania  2020-10-30 04:24:49   41.1533   \n",
       "2                                   Algeria  2020-10-30 04:24:49   28.0339   \n",
       "3                                   Andorra  2020-10-30 04:24:49   42.5063   \n",
       "4                                    Angola  2020-10-30 04:24:49  -11.2027   \n",
       "\n",
       "       Long_ Confirmed Deaths Recovered Active Combined_Key  \\\n",
       "0  67.709953     41268   1532     34239   5497  Afghanistan   \n",
       "1    20.1683     20315    499     11007   8809      Albania   \n",
       "2     1.6596     57332   1949     39635  15748      Algeria   \n",
       "3     1.5218      4567     73      3260   1234      Andorra   \n",
       "4    17.8739     10269    275      3736   6258       Angola   \n",
       "\n",
       "       Incidence_Rate Case-Fatality_Ratio  \n",
       "0  106.01016878679728  3.7123194727149365  \n",
       "1   705.9211897977623  2.4563130691607187  \n",
       "2  130.74261426347374   3.399497662736343  \n",
       "3  5910.8263767553235  1.5984234727392161  \n",
       "4  31.244800900424714   2.677962800662187  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't go through the pandas library in detail here, I just wanted to show you how it can be used to save data to excel files. Dataframe objects have the `.to_excel()` method. If we call this on our dataframe, it will save the data into an excelfile at the provided path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"covid_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a very powerful library. Using `pandas`, we don't need the `csv` module at all. We can actually just pass the url straight into the `.read_csv()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/10-29-2020.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Incidence_Rate</th>\n",
       "      <th>Case-Fatality_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-10-30 04:24:49</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>41268</td>\n",
       "      <td>1532</td>\n",
       "      <td>34239</td>\n",
       "      <td>5497.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>106.010169</td>\n",
       "      <td>3.712319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2020-10-30 04:24:49</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>20315</td>\n",
       "      <td>499</td>\n",
       "      <td>11007</td>\n",
       "      <td>8809.0</td>\n",
       "      <td>Albania</td>\n",
       "      <td>705.921190</td>\n",
       "      <td>2.456313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>2020-10-30 04:24:49</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>57332</td>\n",
       "      <td>1949</td>\n",
       "      <td>39635</td>\n",
       "      <td>15748.0</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>130.742614</td>\n",
       "      <td>3.399498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>2020-10-30 04:24:49</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>4567</td>\n",
       "      <td>73</td>\n",
       "      <td>3260</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>5910.826377</td>\n",
       "      <td>1.598423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>2020-10-30 04:24:49</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>10269</td>\n",
       "      <td>275</td>\n",
       "      <td>3736</td>\n",
       "      <td>6258.0</td>\n",
       "      <td>Angola</td>\n",
       "      <td>31.244801</td>\n",
       "      <td>2.677963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS Admin2 Province_State Country_Region          Last_Update       Lat  \\\n",
       "0   NaN    NaN            NaN    Afghanistan  2020-10-30 04:24:49  33.93911   \n",
       "1   NaN    NaN            NaN        Albania  2020-10-30 04:24:49  41.15330   \n",
       "2   NaN    NaN            NaN        Algeria  2020-10-30 04:24:49  28.03390   \n",
       "3   NaN    NaN            NaN        Andorra  2020-10-30 04:24:49  42.50630   \n",
       "4   NaN    NaN            NaN         Angola  2020-10-30 04:24:49 -11.20270   \n",
       "\n",
       "       Long_  Confirmed  Deaths  Recovered   Active Combined_Key  \\\n",
       "0  67.709953      41268    1532      34239   5497.0  Afghanistan   \n",
       "1  20.168300      20315     499      11007   8809.0      Albania   \n",
       "2   1.659600      57332    1949      39635  15748.0      Algeria   \n",
       "3   1.521800       4567      73       3260   1234.0      Andorra   \n",
       "4  17.873900      10269     275       3736   6258.0       Angola   \n",
       "\n",
       "   Incidence_Rate  Case-Fatality_Ratio  \n",
       "0      106.010169             3.712319  \n",
       "1      705.921190             2.456313  \n",
       "2      130.742614             3.399498  \n",
       "3     5910.826377             1.598423  \n",
       "4       31.244801             2.677963  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, save it as a csv file on our hard drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('covid_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and working with json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another data file that you will encounter many times on the internet is the JSON file. It stands for JavaScript Object Notation, since it is how data is stored in the JavaScript language. Json files are in their essence (just like csv files) just plaintext files, but ordered in a specific way. JavaScript and Python's data structures are pretty similar, and that's why when you see a json file, it looks like a dictionary – or a list of dictionaries. \n",
    "\n",
    "Here's an example of a json file to show you how much they look like Python's data structures. Here's Sweden's population 2016-2019 in a json string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = \"\"\"\n",
    "[{\"country\": \"Sweden\",\"year\": 2016,\"value\": 9995153.0},\n",
    "{\"country\": \"Sweden\",\"year\": 2017,\"value\": 10120242.0},\n",
    "{\"country\": \"Sweden\",\"year\": 2018,\"value\": 10230185.0},\n",
    "{\"country\": \"Sweden\",\"year\": 2019,\"value\": 10327589.0}]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{\"country\": \"Sweden\",\"year\": 2016,\"value\": 9995153.0},\n",
      "{\"country\": \"Sweden\",\"year\": 2017,\"value\": 10120242.0},\n",
      "{\"country\": \"Sweden\",\"year\": 2018,\"value\": 10230185.0},\n",
      "{\"country\": \"Sweden\",\"year\": 2019,\"value\": 10327589.0}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json files data structures are identical to Python's, only that they are string values. So we need to convert them from json data into Python data structures. This is easiest with the `json` module – a module within the standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `.loads()` lets us convert a json string into a Python data object. Just pass the string to the method as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Sweden', 'year': 2016, 'value': 9995153.0},\n",
       " {'country': 'Sweden', 'year': 2017, 'value': 10120242.0},\n",
       " {'country': 'Sweden', 'year': 2018, 'value': 10230185.0},\n",
       " {'country': 'Sweden', 'year': 2019, 'value': 10327589.0}]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a json file from the internet! [Here is a json file](https://opendata.ecdc.europa.eu/covid19/casedistribution/json/) with covid data, [provided by the ECDC](https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide) (European Centre for Desease Prevention and Control):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://opendata.ecdc.europa.eu/covid19/casedistribution/json/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "res.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response object's content is a gigantic binary string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\r\\n   \"records\" : [\\r\\n      {\\r\\n         \"dateRep\" : \"02/11/2020\",\\r\\n         \"day\" : \"02\",\\r\\n         \"month\" : \"11\",\\r\\n         \"year\" : \"2020\",\\r\\n         \"cases\" : 132,\\r\\n         \"deaths\" : 5,\\r\\n         \"countriesAndTerritories\" : \"Afghanistan\",\\r\\n         \"geoId\" : \"AF\",\\r\\n         \"countryterritoryCode\" : \"AFG\",\\r\\n         \"popData2019\" : 38041757,\\r\\n         \"continentExp\" : \"Asia\",\\r\\n         \"Cumulative_number_for_14_days_of_COVID-19_cases_per_100000\" : \"3.76691329\"\\r\\n      },\\r\\n      {\\r\\n         \"d'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the data to a Python data structure using the `json.dumps()` method. But first, we need to convert the content to a regular Python string value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.content.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The json was successfully converted into a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data is stored as the value of the key \"records\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['records'])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dateRep': '02/11/2020',\n",
       "  'day': '02',\n",
       "  'month': '11',\n",
       "  'year': '2020',\n",
       "  'cases': 132,\n",
       "  'deaths': 5,\n",
       "  'countriesAndTerritories': 'Afghanistan',\n",
       "  'geoId': 'AF',\n",
       "  'countryterritoryCode': 'AFG',\n",
       "  'popData2019': 38041757,\n",
       "  'continentExp': 'Asia',\n",
       "  'Cumulative_number_for_14_days_of_COVID-19_cases_per_100000': '3.76691329'},\n",
       " {'dateRep': '01/11/2020',\n",
       "  'day': '01',\n",
       "  'month': '11',\n",
       "  'year': '2020',\n",
       "  'cases': 76,\n",
       "  'deaths': 0,\n",
       "  'countriesAndTerritories': 'Afghanistan',\n",
       "  'geoId': 'AF',\n",
       "  'countryterritoryCode': 'AFG',\n",
       "  'popData2019': 38041757,\n",
       "  'continentExp': 'Asia',\n",
       "  'Cumulative_number_for_14_days_of_COVID-19_cases_per_100000': '3.57501889'}]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"records\"][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping html elements –  using `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now you've practised downloading files using the `requests` library. As mentioned in previous section, requests is a brilliant way to quickly get access to a web page's content. However, it is not very practical if the content isn't a ordered data file. \n",
    "\n",
    "To show you what I mean, let's have a look at [a web page](https://www.socialstyrelsen.se/om-socialstyrelsen/pressrum/) with the Socialstyrelsen's (Sweden's National Board of Health and Welfare) press contacts. It is the agency responsible for questions of health and medical prodcedures. Here's the web page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.socialstyrelsen.se/om-socialstyrelsen/pressrum/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the requests library and get a response object of the web page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, have a look at the web page's content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\r\\n\\r\\n\\r\\n<!DOCTYPE html>\\r\\n<html lang=\"sv\">\\r\\n<head>\\r\\n\\r\\n        <!-- Google Tag Manager -->\\r\\n        <script>\\r\\n            var dataLayer = dataLayer || [];\\r\\n            (function (w, d, s, l, i) {\\r\\n                w[l] = w[l] || [];\\r\\n                w[l].push({\\r\\n                    \\'gtm.start\\':\\r\\n                        new Date().getTime(),\\r\\n                    event: \\'gtm.js\\'\\r\\n                });\\r\\n                var f = d.getElementsByTagName(s)[0],\\r\\n\\r\\n                    j = d.createElement(s),\\r\\n '"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a messy soup of html code mashed into a binary string. This is not particularly ordered data to scrape web content from.\n",
    "\n",
    "Let's say we want all phone numbers scraped from this web page. We _could_ just use the requests response object. Converting it to a regular string, import the `re` module, create a regular expression, and apply this regex on the entire web page's content. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page = res.content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pattern = \"(075-[\\d|\\s]+)\" # do you understand the regex? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['075-247 30 05', '075-247 30 05', '075-247 30 00', '075-247 30 00']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(num_pattern,web_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't mean we _should_ scrape data this way. One, perhaps obvious reason is that this fetches _all_ patterns that match our regex on the web page. If you look at bottom of the web page, you'll see that Socialstyrelsen has its phone number to the reception to the right. Our regex matched on the as well. \n",
    "\n",
    "My point is that this isn't a precise way to scrape information from a web page. If only there was a way to get all that messy soup of html code into a python object that we could work with..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is! It's called beautifulsoup! Or, rather, it's a module called `bs4` – bs standing four \"Beautiful soup\", 4 for version 4. The module is not part of the standard library, but it _is_ included in the Anaconda package. So, if you've installed Anaconda as recommended, you should just be able to import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(If you're not using the Ananconda package, download and install the `bs4` module such that you can use it in this notebook)_\n",
    "\n",
    "The response object that was returned using requests has the entire web page's html code. The `BeautifulSoup` class within the `bs4` module can help us parse the html-string into a special Python \"soup\" object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `soup` variable now has methods that can help us sort through all the messy html code of websites! We can, as an example, search for elements with a specific class.\n",
    "\n",
    "But to be able to do so, we must know what to look for. This is when we **inspect using the developer tools** we learned about in section 4.1.2. In our example, we want to find the press contact info. Looking at the site, we see that this information is in a box with the headline \"Kontakt\". Let's right click the box and see which element this is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../course_material/scraping/html_1.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you right clicked, you may have clicked on one of the children of the one I have selected in the pic above. But as you can see, the box with contact info is a `<div>` element with the class attribute \"contact\". We can search for this class in our soup object, using the `.find()` method. It searches for element types, but have the parameter `class_` where we can specify the element type's class attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "div = soup.find(\"div\", class_=\"contact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"contact\">\n",
       "<div class=\"row\"><div class=\"block contactpersonblock col-lg-12 col-md-12 col-sm-12 col-xs-12 displaymode-full\">\n",
       "<div class=\"contact-person\">\n",
       "<h2>Kontakt</h2>\n",
       "<div class=\"contact-person__name\">\n",
       "\n",
       "            Presstjänsten\n",
       "        </div>\n",
       "<div class=\"contact-person__email\">\n",
       "<span>E-post:  </span>\n",
       "<a class=\"no-border-link\" href=\"mailto:media@socialstyrelsen.se\">media@socialstyrelsen.se</a>\n",
       "</div>\n",
       "<div class=\"contact-person__phone\">\n",
       "<span>Telefonnummer:  </span>\n",
       "<a class=\"no-border-link\" href=\"tel:0752473005\">075-247 30 05</a>\n",
       "</div>\n",
       "</div></div></div>\n",
       "</div>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This html tree tells us that there are child elements of this div containing the information we want. The class \"contact-person__phone\" is what we're after. Let's get that one instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = soup.find(\"div\", class_=\"contact-person__phone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the text of our element by calling the `.text` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTelefonnummer:  \\n075-247 30 05\\n'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it! We scraped the phone number we wanted! Now, let's try something a little more complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating scraping loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, in this section, we want to gather up all websites' urls of California's health care centres. They can be found on the California Departement of Health Care Services' website. [Here](https://www.dhcs.ca.gov/services/medi-cal/Pages/CountyOffices.aspx), to be exact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dhcs.ca.gov/services/medi-cal/Pages/CountyOffices.aspx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the health care offices are located at county level, and their contact info – together with a link to their website – can be found in lists. But they are located at three different web pages at the site. These pages can be found on the link above. So, how to proceed?\n",
    "\n",
    "First, let's scrape the urls to the three web pages that contain all county information. Let's save them in a list. The hyperlink elment, the `<a>` tag, is what we're looking for. Hyperlinks have a attribute `href` which specifies the url of the page the link goes to. Inspecting the site using developer tools, we see that the links are within this element:\n",
    "\n",
    "<img src=\"../course_material/scraping/html_2.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "So, we want to scrape the links beneath the `<ul>` tag (\"ul\" is an \"unordered list\" element). The `<ul>` has the class \"dfwp-list\". Let's get a response object, and then filter the html code using `BeautifulSoup`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "res.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = soup.find(\"ul\", class_=\"dfwp-list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soup objects has a method called `.find_all()`. It searches the html tree for all element tags we provide. Let's use it to get all `<a>`-tagged elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/services/medi-cal/Pages/CountyOffices3.aspx\" target=\"\" title=\"\">County Listings: A - L</a>,\n",
       " <a href=\"/services/medi-cal/Pages/CountyOffices4.aspx\" target=\"\" title=\"\">County Listings: M - R</a>,\n",
       " <a href=\"/services/medi-cal/Pages/CountyOffices5.aspx\" target=\"\" title=\"\">County Listings: S - Z</a>]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! As you can see, the `<a>` tags have `href` attributes with the url links we need! Lets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = element.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All soup objects have the method `.get()` which lets us extract attribute information from an element. We pass the attribute we want as an argument. We need to loop over the links and extract the href-attributes. But while we're at it we can fix another problem:\n",
    "\n",
    "As you can see, the links are not complete urls. They start with `/services/...`, and the url to the website is `https://www.dhcs.ca.gov...`. Therefore, while looping over the links, let's also add this core url to the links' start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/services/medi-cal/Pages/CountyOffices3.aspx'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[0].get(\"href\") # this is how we extract a specific attribute from elements, returns a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the beginning of all links:\n",
    "main_url = \"https://www.dhcs.ca.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count,link in enumerate(links):\n",
    "    # First, extract href text:\n",
    "    href = link.get(\"href\")\n",
    "    # change the list items into string values with the complete urls\n",
    "    links[count] = main_url + href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.dhcs.ca.gov/services/medi-cal/Pages/CountyOffices3.aspx',\n",
       " 'https://www.dhcs.ca.gov/services/medi-cal/Pages/CountyOffices4.aspx',\n",
       " 'https://www.dhcs.ca.gov/services/medi-cal/Pages/CountyOffices5.aspx']"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see that all links work. We can do this looping over the links, creating response objects of them, and then using the `requests` method `.raise_for_status()`. If nothing happens, we've been successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a few seconds:\n",
    "for link in links:\n",
    "    res = requests.get(link)\n",
    "    res.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! No exceptions were raised. The urls seem to work.\n",
    "\n",
    "Now, we need to have a look at the links themselves. All the lists with the contact info of the health care centres is within a html table `<table>`. And all these html-tables in all three url-links all have the class \"ms-rteTable-default\". Here's a pic:\n",
    "\n",
    "\n",
    "\n",
    "Let's try to find it in the first link:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(links[0])\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.content)\n",
    "\n",
    "table = soup.find(\"table\", class_=\"ms-rteTable-default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can find all hyperlinks in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_links = table.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(county_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://alamedasocialservices.org/public/index.cfm\n",
      "http://alpinecountyca.gov/Index.aspx?NID=191\n",
      "http://www.co.amador.ca.us/departments/health-human-services\n",
      "http://www.buttecounty.net/dess/ConnectDESS.aspx\n",
      "http://hhsa.calaverasgov.us/Public-Assistance/Eligibility/Medi-Cal\n"
     ]
    }
   ],
   "source": [
    "# printing top 5 links:\n",
    "for hyperlink in county_links[:5]:\n",
    "    print(hyperlink.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = []\n",
    "\n",
    "for link in county_links:\n",
    "    all_links.append(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! It worked! But, to make the data a bit more workable, let's save the link together with the county name. This is also found in the table element, but it is within a table div `<td>` and has the class \"ms-rteTableEvenCol-default\". Let's get a list of all of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_names = soup.find_all(\"td\", class_=\"ms-rteTableEvenCol-default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(county_names[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"ms-rteTableEvenCol-default\" colspan=\"1\" rowspan=\"1\" style=\"width:50%;\">​<strong>County Name</strong></td>,\n",
       " <td class=\"ms-rteTableEvenCol-default\" rowspan=\"1\" style=\"width:50%;\">​Alameda County</td>,\n",
       " <td class=\"ms-rteTableEvenCol-default\" rowspan=\"1\" style=\"width:50%;\">​Alpine County</td>]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_names[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! Does it work with the other tables on the other links?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(links[1])\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.content)\n",
    "\n",
    "county_names = soup.find_all(\"td\", class_=\"ms-rteTableEvenCol-default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(county_names[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, it doesn't. That's because the class's name is \"ms-rteTableFirstCol-default\" in the second and third tables. We need to include a if statement that will change the class name if the `soup.find_all()` method doesn't return anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_names = soup.find_all(\"td\", class_=\"ms-rteTableEvenCol-default\")\n",
    "if not county_names:\n",
    "    county_names = soup.find_all(\"td\", class_=\"ms-rteTableFirstCol-default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(county_names[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked! Let's return to the first table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(links[0])\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.content)\n",
    "\n",
    "county_names = soup.find_all(\"td\", class_=\"ms-rteTableEvenCol-default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first `<td>` is a table header, so we can skip that one. The other ones seem correct! We can get the text by using the `.text` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\u200bAlameda County'"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_names[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All text in the table starts with a special unicode character – `'\\u200b'`. This is a [\"zero length whitespace character\"](https://www.fileformat.info/info/unicode/char/200b/index.htm). Let's use the string method `.replace()` to remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alameda County'"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_names[1].text.replace(\"\\u200b\", \"\") # replace \"\\u200b\" with \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may also be another unicode character – the `\"\\xa0\"` character (non-breaking space) – in some strings. We'll have to remove that as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alameda County'"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can chain our string methods like this to do it all in one line:\n",
    "county_names[1].text.replace(\"\\u200b\", \"\").replace('\\xa0', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want all county names in a list to be able to use together with the links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "\n",
    "# skipping first td element, since that's the header:\n",
    "for td_element in county_names[1:]:\n",
    "    name = td_element.text.replace(\"\\u200b\", \"\").replace('\\xa0', '')\n",
    "    names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alameda County', 'Alpine County', 'Amador County']"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We can now loop over the lists and create a dictionary with both county name and url! Since the length of the two lists are the same, we can do this in one go if we use the `enumerate()` function in our loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for count,name in enumerate(names):\n",
    "    county_data = {}\n",
    "    county_data['county'] = name\n",
    "    county_data['url'] = all_links[count]\n",
    "    results.append(county_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'county': 'Alameda County',\n",
       "  'url': 'https://alamedasocialservices.org/public/index.cfm'},\n",
       " {'county': 'Alpine County',\n",
       "  'url': 'http://alpinecountyca.gov/Index.aspx?NID=191'},\n",
       " {'county': 'Amador County',\n",
       "  'url': 'http://www.co.amador.ca.us/departments/health-human-services'}]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:3] # top three items in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All seems to have worked as expected! Now, finally, we need to do this on all three links. To make this smoother, let's put all the code above into functions that we can use in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_county_links(soup):\n",
    "    # find the table:\n",
    "    table = soup.find(\"table\", class_=\"ms-rteTable-default\")\n",
    "    \n",
    "    # find all hyperlinks within table:\n",
    "    county_links = table.find_all(\"a\")\n",
    "    \n",
    "    # loop over all hyperlinks and saving the href attribute:\n",
    "    all_links = []\n",
    "    for link in county_links:\n",
    "        # this if-statement is because some counties may not have a hyperlink\n",
    "        if link.get(\"href\"):\n",
    "            all_links.append(link.get(\"href\"))\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # return result\n",
    "    return all_links\n",
    "\n",
    "def get_county_names(soup):\n",
    "    # find all the <td> elements with the class name:\n",
    "    county_names = soup.find_all(\"td\", class_=\"ms-rteTableEvenCol-default\")\n",
    "    if not county_names:\n",
    "        county_names = soup.find_all(\"td\", class_=\"ms-rteTableFirstCol-default\")\n",
    "\n",
    "    # loop over all <td> elements, saving their text\n",
    "    names = []\n",
    "    # skipping first td element, since that's the header:\n",
    "    for td_element in county_names[1:]:\n",
    "        # also, removing weird unicode characted \"\\u200b\":\n",
    "        name = td_element.text.replace(\"\\u200b\", \"\").replace('\\xa0', '')\n",
    "        names.append(name)\n",
    "    \n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(links[2])\n",
    "res.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.dha.saccounty.net/',\n",
       " 'http://hhsa.cosb.us/divisions/public-assistance/medi-cal/',\n",
       " 'http://hs.sbcounty.gov/tad/Pages/Apply-for-Medi-Cal.aspx']"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_county_links(soup)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['San Benito County', 'San Bernardino County', 'San Diego County']"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_county_names(soup)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! It worked! Now, just need to put the loop in a function as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names_and_links(soup):\n",
    "    county_names = get_county_names(soup)\n",
    "    county_links = get_county_links(soup)\n",
    "    \n",
    "    results = []\n",
    "    for count,name in enumerate(county_names):\n",
    "        data = {}\n",
    "        data['county'] = name\n",
    "        data['url'] = county_links[count]\n",
    "        results.append(data)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'county': 'San Benito County', 'url': 'http://www.dha.saccounty.net/'},\n",
       " {'county': 'San Bernardino County',\n",
       "  'url': 'http://hhsa.cosb.us/divisions/public-assistance/medi-cal/'},\n",
       " {'county': 'San Diego County',\n",
       "  'url': 'http://hs.sbcounty.gov/tad/Pages/Apply-for-Medi-Cal.aspx'},\n",
       " {'county': 'City & County of San Francisco',\n",
       "  'url': 'https://www.sandiegocounty.gov/hhsa/programs/ssp/medi-cal_program/index.html'},\n",
       " {'county': 'San Joaquin County',\n",
       "  'url': 'https://www.sfhsa.org/services/health-food/medi-cal'}]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_names_and_links(soup)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to the three url's with the links to the tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.dhcs.ca.gov/services/medi-cal/Pages/CountyOffices3.aspx',\n",
       " 'https://www.dhcs.ca.gov/services/medi-cal/Pages/CountyOffices4.aspx',\n",
       " 'https://www.dhcs.ca.gov/services/medi-cal/Pages/CountyOffices5.aspx']"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop over these three links, create a soup object and use our `get_names_and_links()` function on it. Let's do so and save the resulting data into a complete data structure of all health care offices names and website links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_county_data = []\n",
    "for link in links:\n",
    "    res = requests.get(link)\n",
    "    res.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(res.content)\n",
    "    \n",
    "    county_data = get_names_and_links(soup)\n",
    "    \n",
    "    all_county_data += county_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_county_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'county': 'Alameda County',\n",
       "  'url': 'https://alamedasocialservices.org/public/index.cfm'},\n",
       " {'county': 'Alpine County',\n",
       "  'url': 'http://alpinecountyca.gov/Index.aspx?NID=191'},\n",
       " {'county': 'Amador County',\n",
       "  'url': 'http://www.co.amador.ca.us/departments/health-human-services'}]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_county_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! We scraped all county names, and all the counties' website urls! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
